{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from Data import *\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import  pack_padded_sequence, pad_packed_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_name = 'Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt'\n",
    "loss_file = \"Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout)_loss.npz\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = 0\n",
    "tp = 1\n",
    "pg = 2\n",
    "p = 3\n",
    "\n",
    "def split_data(data):\n",
    "    split_data = []\n",
    "    for string in data:\n",
    "        split_space = string.split()\n",
    "        for i, word in enumerate(split_space):\n",
    "            split_data.append(word)\n",
    "    return split_data\n",
    "\n",
    "def y_train_make(n):\n",
    "    np_sp = np.array([sp])\n",
    "    np_tp = np.array([tp])\n",
    "    np_pg = np.array([pg])\n",
    "    np_p = np.array([p])\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np_sp)\n",
    "        y.append(np_tp)\n",
    "        y.append(np_pg)\n",
    "        y.append(np_p)\n",
    "    return np.array(y)\n",
    "\n",
    "def src_trg_split(data):\n",
    "    src = []\n",
    "    trg = []\n",
    "    for i in range(0, len(data), 2):\n",
    "        src.append(data[i])\n",
    "        trg.append(data[i+1])\n",
    "    return np.array(src), np.array(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = np.squeeze(pd.read_csv('train.txt', header=None))\n",
    "\n",
    "y_train = y_train_make(len(train_data))\n",
    "\n",
    "def to_one_hot(label):\n",
    "    one_hot =  np.zeros((len(label), 4))\n",
    "    one_hot[np.arange(len(label)), label[:, 0]] = 1\n",
    "    return one_hot\n",
    "    \n",
    "y_train = to_one_hot(y_train)\n",
    "train_data = split_data(train_data)\n",
    "train_loader = DataTransformer(train_data, y_train, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.squeeze(pd.read_csv('test.txt', header=None))\n",
    "test_data = split_data(test_data)\n",
    "test_data = np.array(test_data)\n",
    "src, trg = src_trg_split(test_data)\n",
    "test_src = []\n",
    "test_trg = []\n",
    "\n",
    "for word in src:\n",
    "    test_src.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\n",
    "for word in trg:\n",
    "    test_trg.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\"\"\"\n",
    "sp -> p\n",
    "sp -> pg\n",
    "sp -> tp\n",
    "sp -> tp\n",
    "p  -> tp\n",
    "sp -> pg\n",
    "p  -> sp\n",
    "pg -> sp\n",
    "pg -> p\n",
    "pg -> tp\n",
    "\"\"\"\n",
    "test_c_src = np.array([sp, sp, sp, sp, p, sp, p, pg, pg, pg]).reshape(-1, 1)\n",
    "test_c_trg = np.array([p, pg, tp, tp, tp, pg, sp, sp, p, tp]).reshape(-1, 1)\n",
    "test_c_src = Variable(torch.LongTensor(to_one_hot(test_c_src))).to(device)\n",
    "test_c_trg = Variable(torch.LongTensor(to_one_hot(test_c_trg))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():    \n",
    "        src_c = test_src\n",
    "        trg_c = test_trg\n",
    "        optimizer.zero_grad()            \n",
    "        output = model(src, trg, src_c, trg_c, 0) #turn off teacher forcing\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"=========show testing result=========\")\n",
    "            for i in range(output.shape[-1]):\n",
    "                show_result(trg, output, i)\n",
    "                print()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "def show_result(target, output, index):\n",
    "    print(\"Ground true: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        tmp = trg[index, i]\n",
    "        if tmp == 1:\n",
    "            break\n",
    "        elif tmp == 0:\n",
    "            continue\n",
    "        print(chr(trg[index, i]-7+ord('a')), end=\"\")\n",
    "    \n",
    "    print(\" Predict: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        print(chr(np.argmax(o[index, i, 3:])-4+ord('a')), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, output_size, lat_dim):\n",
    "        \"\"\"Define layers for a vanilla rnn encoder\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.fc = nn.Linear(self.embedding_size+4, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, output_size)\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(output_size, lat_dim)\n",
    "        self.hidden2logv = nn.Linear(output_size, lat_dim)\n",
    "        \n",
    "        self.cell2mean = nn.Linear(output_size, lat_dim)\n",
    "        self.cell2logv = nn.Linear(output_size, lat_dim)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, label, hidden=None, cell=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lengths)\n",
    "        label = label.view(1, label.shape[0], label.shape[1])\n",
    "        hidden = torch.cat([hidden, label], dim=2)\n",
    "        hidden = self.fc(hidden)\n",
    "        cell = hidden\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed, (hidden, cell))\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        hidden_means = self.hidden2mean(hidden)\n",
    "        hidden_logv = self.hidden2logv(hidden)\n",
    "        \n",
    "        cell_means = self.cell2mean(cell)\n",
    "        cell_logv = self.cell2logv(cell)\n",
    "        \n",
    "        return outputs, hidden_means, hidden_logv, cell_means, cell_logv\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros([1, batch_size, self.embedding_size]) # (D * num_layers, batch_size, H_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, lat_dim, max_length, teacher_forcing_ratio, sos_id, use_cuda):\n",
    "        \"\"\"Define layers for a vanilla rnn decoder\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.word_dropout_rate = 0\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.latent2hidden = nn.Linear(lat_dim+4, hidden_size)\n",
    "        self.latent2cell = nn.Linear(lat_dim+4, hidden_size)\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)  # work with NLLLoss = CrossEntropyLoss\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.sos_id = sos_id\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward_step(self, inputs, hidden, cell):\n",
    "        # inputs: (time_steps=1, batch_size)\n",
    "        batch_size = inputs.size(1)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded.view(1, batch_size, self.hidden_size)  # S = T(1) x B x N\n",
    "        rnn_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))  # S = T(1) x B x H\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze the time dimension\n",
    "        output = self.log_softmax(self.out(rnn_output))  # S = B x O\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def forward(self, context_vector, decoder_cell, targets):\n",
    "\n",
    "        # Prepare variable for decoder on time_step_0\n",
    "        target_vars, target_lengths = targets\n",
    "        batch_size = context_vector.size(1)\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "\n",
    "        # Pass the context vector\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            max_target_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "            \n",
    "        if self.word_dropout_rate:\n",
    "            prob = torch.rand(decoder_input.size()).to(device)\n",
    "            prob[(decoder_input.data - train_loader.vocab.char2idx[\"SOS\"]) * (decoder_input.data - train_loader.vocab.char2idx['PAD']) == 0] = 1\n",
    "            decoder_input[prob < self.word_dropout_rate] = train_loader.vocab.char2idx['UNK']\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(max_target_length):\n",
    "            decoder_outputs_on_t, decoder_hidden, decoder_cell = self.forward_step(decoder_input, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_vars[t].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input = self._decode_to_index(decoder_outputs_on_t)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, decoder_cell\n",
    "\n",
    "    def evaluate(self, context_vector, decoder_cell):\n",
    "        batch_size = context_vector.size(1) # get the batch size\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            self.max_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(self.max_length):\n",
    "            decoder_outputs_on_t, decoder_hidden, decoder_cell = self.forward_step(decoder_input, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            decoder_input = self._decode_to_index(decoder_outputs_on_t)  # select the former output as input\n",
    "\n",
    "        return self._decode_to_indices(decoder_outputs)\n",
    "\n",
    "    def _decode_to_index(self, decoder_output):\n",
    "        \"\"\"\n",
    "        evaluate on the logits, get the index of top1\n",
    "        :param decoder_output: S = B x V or T x V\n",
    "        \"\"\"\n",
    "        value, index = torch.topk(decoder_output, 1)\n",
    "        index = index.transpose(0, 1)  # S = 1 x B, 1 is the index of top1 class\n",
    "        if self.use_cuda:\n",
    "            index = index.cuda()\n",
    "        return index\n",
    "\n",
    "    def _decode_to_indices(self, decoder_outputs):\n",
    "        \"\"\"\n",
    "        Evaluate on the decoder outputs(logits), find the top 1 indices.\n",
    "        Please confirm that the model is on evaluation mode if dropout/batch_norm layers have been added\n",
    "        :param decoder_outputs: the output sequence from decoder, shape = T x B x V \n",
    "        \"\"\"\n",
    "        decoded_indices = []\n",
    "        batch_size = decoder_outputs.size(1)\n",
    "        decoder_outputs = decoder_outputs.transpose(0, 1)  # S = B x T x V\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            top_ids = self._decode_to_index(decoder_outputs[b])\n",
    "            decoded_indices.append(top_ids.data[0].cpu().numpy())\n",
    "        return decoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs, targets, label):\n",
    "        # variables\n",
    "        input_vars, input_lengths = inputs\n",
    "        batch_size = input_vars.shape[1]\n",
    "        encoder_hidden = self.encoder.initHidden(batch_size).to(device)\n",
    "        encoder_cell = self.encoder.initHidden(batch_size).to(device)\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "            self.encoder.forward(input_vars, input_lengths, label, hidden=encoder_hidden, cell=encoder_cell)  \n",
    "\n",
    "        # reparaterization trick\n",
    "        encoder_hidden = self.reparaterization_trick(hidden_means, hidden_logv)\n",
    "        encoder_cell = self.reparaterization_trick(cell_means, cell_logv)\n",
    "        encoder_hidden = torch.cat([encoder_hidden, label.view(1, label.shape[0], label.shape[1])], dim=2)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        encoder_cell = torch.cat([encoder_cell, label.view(1, label.shape[0], label.shape[1])], dim=2)\n",
    "        encoder_cell = self.decoder.latent2cell(encoder_cell)\n",
    "\n",
    "        # decoder\n",
    "        decoder_outputs, decoder_hidden, decoder_cell = self.decoder.forward(context_vector=encoder_hidden, \n",
    "                                                               decoder_cell=encoder_cell, targets=targets)\n",
    "        \n",
    "        return decoder_outputs, decoder_hidden, hidden_means, hidden_logv, cell_means, cell_logv\n",
    "\n",
    "    def evaluate(self, inputs, src_label, trg_label):\n",
    "        # variables\n",
    "        input_vars, input_lengths = inputs\n",
    "        batch_size = input_vars.shape[1]\n",
    "        encoder_hidden = self.encoder.initHidden(batch_size).to(device)\n",
    "        encoder_cell = self.encoder.initHidden(batch_size).to(device)\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "            self.encoder.forward(input_vars, input_lengths, src_label, hidden=encoder_hidden, cell=encoder_cell)  \n",
    "\n",
    "        # reparaterization trick\n",
    "        encoder_hidden = self.reparaterization_trick(hidden_means, hidden_logv)\n",
    "        encoder_cell = self.reparaterization_trick(cell_means, cell_logv)\n",
    "        encoder_hidden = torch.cat([encoder_hidden, trg_label.view(1, trg_label.shape[0], trg_label.shape[1])], dim=2)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        encoder_cell = torch.cat([encoder_cell, trg_label.view(1, trg_label.shape[0], trg_label.shape[1])], dim=2)\n",
    "        encoder_cell = self.decoder.latent2cell(encoder_cell)\n",
    "        \n",
    "        # decoder\n",
    "        decoded_sentence = self.decoder.evaluate(context_vector=encoder_hidden, decoder_cell=encoder_cell)\n",
    "        \n",
    "        return decoded_sentence\n",
    "    \n",
    "    def reparaterization_trick(self, mean, logv):\n",
    "        std = torch.exp(0.5*logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return  mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, data_transformer, label, learning_rate, use_cuda, checkpoint_name,\n",
    "                 teacher_forcing_ratio=1.0, kl_weight=0, word_dropout_rate=0):\n",
    "\n",
    "        self.model = model\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "        self.total_iter = 0\n",
    "        \n",
    "        # save list\n",
    "        self.entropy = []\n",
    "        self.kld = []\n",
    "        self.kl_weight_list = []\n",
    "        self.teacher_forcing_ratio_list = []\n",
    "        self.score = []\n",
    "        \n",
    "        # init hyperparameters\n",
    "        self.kl_weight = kl_weight\n",
    "        self.model.decoder.word_dropout_rate = word_dropout_rate\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.kl_weight_list.append(self.kl_weight)\n",
    "        self.teacher_forcing_ratio_list.append(self.teacher_forcing_ratio)\n",
    "        \n",
    "        # record some information about dataset\n",
    "        self.data_transformer = data_transformer\n",
    "        self.label = label\n",
    "        self.vocab_size = self.data_transformer.vocab_size\n",
    "        self.PAD_ID = self.data_transformer.PAD_ID\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        # optimizer setting\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer= torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "#         self.optimizer= torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = torch.nn.NLLLoss(ignore_index=self.PAD_ID, reduction='mean')\n",
    "\n",
    "    def train(self, num_epochs, batch_size, pretrained=False):\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_model()\n",
    "        \n",
    "        self.model.train()\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            mini_batches = self.data_transformer.mini_batches(batch_size=batch_size)\n",
    "            for input_batch, target_batch, label_batch in mini_batches:\n",
    "                self.total_iter += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                self.model.decoder.teacher_forcing_ratio = self.teacher_forcing_ratio\n",
    "                decoder_outputs, decoder_hidden, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "                    self.model(input_batch, target_batch, label_batch)\n",
    "\n",
    "                # calculate the loss and back prop.\n",
    "                cur_loss = self.get_loss(decoder_outputs, target_batch[0])\n",
    "                kl_loss = self.kl_weight * self.get_kl_loss(hidden_means, hidden_logv)+\\\n",
    "                            self.kl_weight* self.get_kl_loss(cell_means, cell_logv)\n",
    "                loss = cur_loss + kl_loss\n",
    "                \n",
    "                self.entropy.append(cur_loss.item())\n",
    "                self.kld.append(kl_loss.item())\n",
    "                \n",
    "                # logging\n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Step:\", step, \"char-loss: \", loss.item())\n",
    "                    print(\"KL_weight: \", self.kl_weight, \"teacher_forcing_ratio: \", self.teacher_forcing_ratio)\n",
    "                    self.save_model()\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # update hyperparameters\n",
    "                self.kl_weight = self.get_kl_weight(self.kl_weight)\n",
    "                self.model.decoder.word_dropout_rate = self.get_word_dropout_rate(self.model.decoder.word_dropout_rate)\n",
    "                self.teacher_forcing_ratio = self.get_teacher_forcing_ratio(self.teacher_forcing_ratio)\n",
    "                self.kl_weight_list.append(self.kl_weight)\n",
    "                self.teacher_forcing_ratio_list.append(self.teacher_forcing_ratio)\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def get_loss(self, decoder_outputs, targets):\n",
    "        b = decoder_outputs.size(1)\n",
    "        t = decoder_outputs.size(0)\n",
    "        targets = targets.contiguous().view(-1)  # S = (B*T)\n",
    "        decoder_outputs = decoder_outputs.view(b * t, -1)  # S = (B*T) x V\n",
    "        return self.criterion(decoder_outputs, targets)\n",
    "    \n",
    "    def get_kl_loss(self, mean, logvar):\n",
    "        result = -0.5 * torch.sum(logvar - torch.pow(mean, 2) - torch.exp(logvar) + 1, 1)\n",
    "        return result.mean()\n",
    "    \n",
    "    def get_kl_weight(self, kl_weight):\n",
    "#         return 0\n",
    "#         if self.total_iter < 50000:\n",
    "#             return 0\n",
    "#         else:\n",
    "#         return 0\n",
    "        return min(1, kl_weight + 0.0000000001)\n",
    "\n",
    "    def get_word_dropout_rate(self, word_dropout_rate):\n",
    "#         if self.total_iter < 50000:\n",
    "#             return 0\n",
    "#         else:\n",
    "#         return 0\n",
    "#         return 0\n",
    "        return min(0.5, word_dropout_rate + 0.00000000001)\n",
    "\n",
    "    def get_teacher_forcing_ratio(self, teacher_forcing_ratio):\n",
    "#         if self.total_iter < 100000:\n",
    "#             return 1\n",
    "#         else:\n",
    "        return max(0, teacher_forcing_ratio - 0.0000000001)\n",
    "#         return 1\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_name)\n",
    "        np.savez(loss_file, entropy=self.entropy, kld=self.kld, kl_weight=self.kl_weight_list,\\\n",
    "                 teacher_forcing_ratio=self.teacher_forcing_ratio_list, score=self.score)\n",
    "        print(\"Model has been saved as %s.\\n\" % self.checkpoint_name)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.checkpoint_name, map_location=device))\n",
    "        load_file = np.load(loss_file)\n",
    "        self.entropy = load_file['entropy'].tolist()\n",
    "        self.kld = load_file['kld'].tolist()\n",
    "        self.kl_weight_list = load_file['kl_weight'].tolist()\n",
    "        self.teacher_forcing_ratio_list = load_file['teacher_forcing_ratio'].tolist()\n",
    "        self.score = load_file['score'].tolist()\n",
    "        print(\"Pretrained model has been loaded.\\n\")\n",
    "\n",
    "    def evaluate(self, words, src_label, trg_label):\n",
    "        # make sure that words is list\n",
    "        if type(words) is not list:\n",
    "            words = [words]\n",
    "        self.model.eval()\n",
    "        # transform word to index-sequence\n",
    "        eval_var = self.data_transformer.evaluation_batch(words=words)\n",
    "        decoded_indices = self.model.evaluate(eval_var, src_label, trg_label)\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(self.data_transformer.vocab.indices_to_sequence(indices))\n",
    "        return results\n",
    "    \n",
    "    def compute_bleu(self, output, reference):\n",
    "        cc = SmoothingFunction()\n",
    "        if len(reference) == 3:\n",
    "            weights = (0.33,0.33,0.33)\n",
    "        else:\n",
    "            weights = (0.25,0.25,0.25,0.25)\n",
    "        return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our models\n",
    "encoder = Encoder(vocab_size=train_loader.vocab_size,\n",
    "                         embedding_size=256,\n",
    "                         output_size=256,\n",
    "                         lat_dim=32).to(device)\n",
    "\n",
    "decoder = Decoder(hidden_size=256,\n",
    "                         output_size=train_loader.vocab_size,\n",
    "                         lat_dim=32,\n",
    "                         max_length=train_loader.max_length,\n",
    "                         teacher_forcing_ratio=1.,\n",
    "                         sos_id=train_loader.SOS_ID,\n",
    "                         use_cuda=True).to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder=encoder,\n",
    "                  decoder=decoder)\n",
    "\n",
    "trainer = Trainer(seq2seq, train_loader, y_train, learning_rate=0.001, use_cuda=True, checkpoint_name=checkpoint_name, \n",
    "                        teacher_forcing_ratio=1, kl_weight=0, word_dropout_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18542f79fbd4f19a10e457154b1823e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  1.841711163520813\n",
      "KL_weight:  4.9000000000000025e-09 teacher_forcing_ratio:  0.9999999950999996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  1.3694227933883667\n",
      "KL_weight:  9.899999999999986e-09 teacher_forcing_ratio:  0.9999999900999992\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.9768053293228149\n",
      "KL_weight:  1.4899999999999948e-08 teacher_forcing_ratio:  0.9999999850999988\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.6661690473556519\n",
      "KL_weight:  1.9899999999999993e-08 teacher_forcing_ratio:  0.9999999800999984\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.4426281750202179\n",
      "KL_weight:  2.4900000000000038e-08 teacher_forcing_ratio:  0.9999999750999979\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.31840360164642334\n",
      "KL_weight:  2.990000000000008e-08 teacher_forcing_ratio:  0.9999999700999975\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.24751277267932892\n",
      "KL_weight:  3.490000000000013e-08 teacher_forcing_ratio:  0.9999999650999971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.13096120953559875\n",
      "KL_weight:  3.990000000000017e-08 teacher_forcing_ratio:  0.9999999600999967\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.1615699678659439\n",
      "KL_weight:  4.490000000000022e-08 teacher_forcing_ratio:  0.9999999550999963\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.1119040921330452\n",
      "KL_weight:  4.990000000000026e-08 teacher_forcing_ratio:  0.9999999500999959\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0856131911277771\n",
      "KL_weight:  5.4900000000000306e-08 teacher_forcing_ratio:  0.9999999450999955\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.08174552768468857\n",
      "KL_weight:  5.990000000000033e-08 teacher_forcing_ratio:  0.999999940099995\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.05041906610131264\n",
      "KL_weight:  6.490000000000005e-08 teacher_forcing_ratio:  0.9999999350999946\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.06017638370394707\n",
      "KL_weight:  6.989999999999976e-08 teacher_forcing_ratio:  0.9999999300999942\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.04254411160945892\n",
      "KL_weight:  7.489999999999947e-08 teacher_forcing_ratio:  0.9999999250999938\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonse \tScore:  0.75062\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      abetshe \tScore:  0.35640\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginhs \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     expendas \tScore:  0.70711\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sentash \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      spliths \tScore:  0.46200\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredmen \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healinges \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.03418591991066933\n",
      "KL_weight:  8.189999999999907e-08 teacher_forcing_ratio:  0.9999999180999932\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.024654287844896317\n",
      "KL_weight:  8.689999999999879e-08 teacher_forcing_ratio:  0.9999999130999928\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.020495600998401642\n",
      "KL_weight:  9.18999999999985e-08 teacher_forcing_ratio:  0.9999999080999924\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.016673432663083076\n",
      "KL_weight:  9.689999999999821e-08 teacher_forcing_ratio:  0.999999903099992\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.02787511982023716\n",
      "KL_weight:  1.0189999999999793e-07 teacher_forcing_ratio:  0.9999998980999916\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.04439867287874222\n",
      "KL_weight:  1.0689999999999764e-07 teacher_forcing_ratio:  0.9999998930999912\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.034366682171821594\n",
      "KL_weight:  1.1189999999999736e-07 teacher_forcing_ratio:  0.9999998880999907\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.025831174105405807\n",
      "KL_weight:  1.1689999999999707e-07 teacher_forcing_ratio:  0.9999998830999903\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.015686262398958206\n",
      "KL_weight:  1.2189999999999714e-07 teacher_forcing_ratio:  0.9999998780999899\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.01070560421794653\n",
      "KL_weight:  1.2689999999999752e-07 teacher_forcing_ratio:  0.9999998730999895\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.007343171164393425\n",
      "KL_weight:  1.318999999999979e-07 teacher_forcing_ratio:  0.9999998680999891\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.006445834878832102\n",
      "KL_weight:  1.3689999999999827e-07 teacher_forcing_ratio:  0.9999998630999887\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.00499161658808589\n",
      "KL_weight:  1.4189999999999864e-07 teacher_forcing_ratio:  0.9999998580999883\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.003835315117612481\n",
      "KL_weight:  1.4689999999999902e-07 teacher_forcing_ratio:  0.9999998530999878\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.004617084749042988\n",
      "KL_weight:  1.518999999999994e-07 teacher_forcing_ratio:  0.9999998480999874\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandonres \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      abetshe \tScore:  0.35640\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginhs \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expendras \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sentars \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      sploits \tScore:  0.15448\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flargench \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functionied \tScore:  0.74194\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   healringes \tScore:  0.27776\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0042003667913377285\n",
      "KL_weight:  1.5889999999999992e-07 teacher_forcing_ratio:  0.9999998410999869\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100 char-loss:  0.0035471580922603607\n",
      "KL_weight:  1.639000000000003e-07 teacher_forcing_ratio:  0.9999998360999864\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002827652730047703\n",
      "KL_weight:  1.6890000000000067e-07 teacher_forcing_ratio:  0.999999831099986\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0028269016183912754\n",
      "KL_weight:  1.7390000000000105e-07 teacher_forcing_ratio:  0.9999998260999856\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002846578136086464\n",
      "KL_weight:  1.7890000000000142e-07 teacher_forcing_ratio:  0.9999998210999852\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0028195076156407595\n",
      "KL_weight:  1.839000000000018e-07 teacher_forcing_ratio:  0.9999998160999848\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0026632105000317097\n",
      "KL_weight:  1.8890000000000217e-07 teacher_forcing_ratio:  0.9999998110999844\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002159676281735301\n",
      "KL_weight:  1.9390000000000255e-07 teacher_forcing_ratio:  0.999999806099984\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0024134088307619095\n",
      "KL_weight:  1.9890000000000293e-07 teacher_forcing_ratio:  0.9999998010999835\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001981225796043873\n",
      "KL_weight:  2.039000000000033e-07 teacher_forcing_ratio:  0.9999997960999831\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0020350716076791286\n",
      "KL_weight:  2.0890000000000368e-07 teacher_forcing_ratio:  0.9999997910999827\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0021960483863949776\n",
      "KL_weight:  2.1390000000000405e-07 teacher_forcing_ratio:  0.9999997860999823\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0018640817143023014\n",
      "KL_weight:  2.1890000000000443e-07 teacher_forcing_ratio:  0.9999997810999819\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0018191831186413765\n",
      "KL_weight:  2.239000000000048e-07 teacher_forcing_ratio:  0.9999997760999815\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0018167627276852727\n",
      "KL_weight:  2.2890000000000518e-07 teacher_forcing_ratio:  0.9999997710999811\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandonres \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abesthed \tScore:  0.14772\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginfs \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     explends \tScore:  0.50000\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sentars \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      sploits \tScore:  0.15448\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flargech \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functionied \tScore:  0.74194\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healrings \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0018497341079637408\n",
      "KL_weight:  2.359000000000057e-07 teacher_forcing_ratio:  0.9999997640999805\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016548102721571922\n",
      "KL_weight:  2.409000000000061e-07 teacher_forcing_ratio:  0.9999997590999801\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017554399091750383\n",
      "KL_weight:  2.4590000000000646e-07 teacher_forcing_ratio:  0.9999997540999797\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0016162674874067307\n",
      "KL_weight:  2.5090000000000683e-07 teacher_forcing_ratio:  0.9999997490999792\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001587203936651349\n",
      "KL_weight:  2.559000000000072e-07 teacher_forcing_ratio:  0.9999997440999788\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014929308090358973\n",
      "KL_weight:  2.609000000000076e-07 teacher_forcing_ratio:  0.9999997390999784\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0014551011845469475\n",
      "KL_weight:  2.6590000000000796e-07 teacher_forcing_ratio:  0.999999734099978\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0014284143690019846\n",
      "KL_weight:  2.7090000000000834e-07 teacher_forcing_ratio:  0.9999997290999776\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0012081341119483113\n",
      "KL_weight:  2.759000000000087e-07 teacher_forcing_ratio:  0.9999997240999772\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0013768805656582117\n",
      "KL_weight:  2.809000000000091e-07 teacher_forcing_ratio:  0.9999997190999768\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0013663549907505512\n",
      "KL_weight:  2.8590000000000946e-07 teacher_forcing_ratio:  0.9999997140999763\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0011492102639749646\n",
      "KL_weight:  2.9090000000000984e-07 teacher_forcing_ratio:  0.9999997090999759\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011548977345228195\n",
      "KL_weight:  2.959000000000102e-07 teacher_forcing_ratio:  0.9999997040999755\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001124733593314886\n",
      "KL_weight:  3.009000000000106e-07 teacher_forcing_ratio:  0.9999996990999751\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001146132592111826\n",
      "KL_weight:  3.0590000000001096e-07 teacher_forcing_ratio:  0.9999996940999747\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandornes \tScore:  0.58143\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      abetshe \tScore:  0.35640\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      begifhs \tScore:  0.43472\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     expnerds \tScore:  0.18803\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sentars \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     sploitsh \tScore:  0.15255\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flargench \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionring \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healrings \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001023103017359972\n",
      "KL_weight:  3.129000000000115e-07 teacher_forcing_ratio:  0.9999996870999741\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0010613329941406846\n",
      "KL_weight:  3.1790000000001187e-07 teacher_forcing_ratio:  0.9999996820999737\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 150 char-loss:  0.0009426159085705876\n",
      "KL_weight:  3.2290000000001224e-07 teacher_forcing_ratio:  0.9999996770999733\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0012627411633729935\n",
      "KL_weight:  3.279000000000126e-07 teacher_forcing_ratio:  0.9999996720999729\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0010289851343259215\n",
      "KL_weight:  3.32900000000013e-07 teacher_forcing_ratio:  0.9999996670999725\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0010880811605602503\n",
      "KL_weight:  3.3790000000001337e-07 teacher_forcing_ratio:  0.999999662099972\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0008945593144744635\n",
      "KL_weight:  3.4290000000001374e-07 teacher_forcing_ratio:  0.9999996570999716\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0010001929476857185\n",
      "KL_weight:  3.479000000000141e-07 teacher_forcing_ratio:  0.9999996520999712\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0008662267937324941\n",
      "KL_weight:  3.529000000000145e-07 teacher_forcing_ratio:  0.9999996470999708\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.000921991653740406\n",
      "KL_weight:  3.5790000000001487e-07 teacher_forcing_ratio:  0.9999996420999704\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0009712516330182552\n",
      "KL_weight:  3.6290000000001525e-07 teacher_forcing_ratio:  0.99999963709997\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0008241176838055253\n",
      "KL_weight:  3.679000000000156e-07 teacher_forcing_ratio:  0.9999996320999696\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  1.042873740196228\n",
      "KL_weight:  3.72900000000016e-07 teacher_forcing_ratio:  0.9999996270999691\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.18720389902591705\n",
      "KL_weight:  3.779000000000164e-07 teacher_forcing_ratio:  0.9999996220999687\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.13216371834278107\n",
      "KL_weight:  3.8290000000001675e-07 teacher_forcing_ratio:  0.9999996170999683\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abetching \tScore:  0.43167\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befighting \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderch \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sentoratens \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:       splits \tScore:  0.46086\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flareding \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healizens \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.03179357200860977\n",
      "KL_weight:  3.899000000000173e-07 teacher_forcing_ratio:  0.9999996100999677\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.018932094797492027\n",
      "KL_weight:  3.9490000000001765e-07 teacher_forcing_ratio:  0.9999996050999673\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.010536580346524715\n",
      "KL_weight:  3.9990000000001803e-07 teacher_forcing_ratio:  0.9999996000999669\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.008259409107267857\n",
      "KL_weight:  4.049000000000184e-07 teacher_forcing_ratio:  0.9999995950999665\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.007277362514287233\n",
      "KL_weight:  4.099000000000188e-07 teacher_forcing_ratio:  0.9999995900999661\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.005965533200651407\n",
      "KL_weight:  4.1490000000001915e-07 teacher_forcing_ratio:  0.9999995850999657\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.004048803821206093\n",
      "KL_weight:  4.1990000000001953e-07 teacher_forcing_ratio:  0.9999995800999653\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0043661161325871944\n",
      "KL_weight:  4.249000000000199e-07 teacher_forcing_ratio:  0.9999995750999648\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.004099640529602766\n",
      "KL_weight:  4.299000000000203e-07 teacher_forcing_ratio:  0.9999995700999644\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.003477639053016901\n",
      "KL_weight:  4.3490000000002066e-07 teacher_forcing_ratio:  0.999999565099964\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0037236129865050316\n",
      "KL_weight:  4.3990000000002103e-07 teacher_forcing_ratio:  0.9999995600999636\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0028632385656237602\n",
      "KL_weight:  4.449000000000214e-07 teacher_forcing_ratio:  0.9999995550999632\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0029755933210253716\n",
      "KL_weight:  4.499000000000218e-07 teacher_forcing_ratio:  0.9999995500999628\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002341771498322487\n",
      "KL_weight:  4.5490000000002216e-07 teacher_forcing_ratio:  0.9999995450999624\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002683785976842046\n",
      "KL_weight:  4.5990000000002253e-07 teacher_forcing_ratio:  0.999999540099962\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abetching \tScore:  0.43167\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befighsing \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expendols \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snetrafes \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:       splits \tScore:  0.46086\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flaredping \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionsing \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healfings \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0021439692936837673\n",
      "KL_weight:  4.6690000000002306e-07 teacher_forcing_ratio:  0.9999995330999614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002059515565633774\n",
      "KL_weight:  4.7190000000002344e-07 teacher_forcing_ratio:  0.999999528099961\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002525084186345339\n",
      "KL_weight:  4.769000000000238e-07 teacher_forcing_ratio:  0.9999995230999605\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.0019584123510867357\n",
      "KL_weight:  4.819000000000241e-07 teacher_forcing_ratio:  0.9999995180999601\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0018878241535276175\n",
      "KL_weight:  4.869000000000245e-07 teacher_forcing_ratio:  0.9999995130999597\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0018320081289857626\n",
      "KL_weight:  4.919000000000249e-07 teacher_forcing_ratio:  0.9999995080999593\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001852640532888472\n",
      "KL_weight:  4.969000000000253e-07 teacher_forcing_ratio:  0.9999995030999589\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0015688934363424778\n",
      "KL_weight:  5.019000000000256e-07 teacher_forcing_ratio:  0.9999994980999585\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0016144721303135157\n",
      "KL_weight:  5.06900000000026e-07 teacher_forcing_ratio:  0.9999994930999581\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001581248128786683\n",
      "KL_weight:  5.119000000000264e-07 teacher_forcing_ratio:  0.9999994880999576\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015513283433392644\n",
      "KL_weight:  5.169000000000268e-07 teacher_forcing_ratio:  0.9999994830999572\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0016278671100735664\n",
      "KL_weight:  5.219000000000271e-07 teacher_forcing_ratio:  0.9999994780999568\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0014390493743121624\n",
      "KL_weight:  5.269000000000275e-07 teacher_forcing_ratio:  0.9999994730999564\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014238241128623486\n",
      "KL_weight:  5.319000000000279e-07 teacher_forcing_ratio:  0.999999468099956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001282285782508552\n",
      "KL_weight:  5.369000000000283e-07 teacher_forcing_ratio:  0.9999994630999556\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abetching \tScore:  0.43167\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befighsing \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     expnoyes \tScore:  0.16348\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snetrafeed \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:       splits \tScore:  0.46086\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flaredping \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionsing \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   healfireng \tScore:  0.26269\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001215350697748363\n",
      "KL_weight:  5.439000000000288e-07 teacher_forcing_ratio:  0.999999456099955\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.001326685887761414\n",
      "KL_weight:  5.489000000000292e-07 teacher_forcing_ratio:  0.9999994510999546\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0013542725937440991\n",
      "KL_weight:  5.539000000000295e-07 teacher_forcing_ratio:  0.9999994460999542\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011808936251327395\n",
      "KL_weight:  5.589000000000299e-07 teacher_forcing_ratio:  0.9999994410999538\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0011252507101744413\n",
      "KL_weight:  5.639000000000303e-07 teacher_forcing_ratio:  0.9999994360999533\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0013074444141238928\n",
      "KL_weight:  5.689000000000307e-07 teacher_forcing_ratio:  0.9999994310999529\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0011751658748835325\n",
      "KL_weight:  5.73900000000031e-07 teacher_forcing_ratio:  0.9999994260999525\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001110014389269054\n",
      "KL_weight:  5.789000000000314e-07 teacher_forcing_ratio:  0.9999994210999521\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0010220312979072332\n",
      "KL_weight:  5.839000000000318e-07 teacher_forcing_ratio:  0.9999994160999517\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001177721656858921\n",
      "KL_weight:  5.889000000000322e-07 teacher_forcing_ratio:  0.9999994110999513\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0011069775791838765\n",
      "KL_weight:  5.939000000000325e-07 teacher_forcing_ratio:  0.9999994060999509\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0010151865426450968\n",
      "KL_weight:  5.989000000000329e-07 teacher_forcing_ratio:  0.9999994010999504\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011110773775726557\n",
      "KL_weight:  6.039000000000333e-07 teacher_forcing_ratio:  0.99999939609995\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0009418826084583998\n",
      "KL_weight:  6.089000000000337e-07 teacher_forcing_ratio:  0.9999993910999496\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0010371701791882515\n",
      "KL_weight:  6.13900000000034e-07 teacher_forcing_ratio:  0.9999993860999492\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetches \tScore:  0.34572\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befgishing \tScore:  0.07731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenchigs \tScore:  0.41113\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sneftraies \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splithes \tScore:  0.45623\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flarneds \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionsing \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   healfirens \tScore:  0.27776\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0009014316601678729\n",
      "KL_weight:  6.209000000000346e-07 teacher_forcing_ratio:  0.9999993790999486\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0009033733513206244\n",
      "KL_weight:  6.25900000000035e-07 teacher_forcing_ratio:  0.9999993740999482\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0009012570953927934\n",
      "KL_weight:  6.309000000000353e-07 teacher_forcing_ratio:  0.9999993690999478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0008888753363862634\n",
      "KL_weight:  6.359000000000357e-07 teacher_forcing_ratio:  0.9999993640999474\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 250 char-loss:  0.0009274360490962863\n",
      "KL_weight:  6.409000000000361e-07 teacher_forcing_ratio:  0.999999359099947\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0009859700221568346\n",
      "KL_weight:  6.459000000000365e-07 teacher_forcing_ratio:  0.9999993540999466\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0009032395901158452\n",
      "KL_weight:  6.509000000000368e-07 teacher_forcing_ratio:  0.9999993490999461\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0008635649573989213\n",
      "KL_weight:  6.559000000000372e-07 teacher_forcing_ratio:  0.9999993440999457\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0009711732272990048\n",
      "KL_weight:  6.609000000000376e-07 teacher_forcing_ratio:  0.9999993390999453\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  1.0402631759643555\n",
      "KL_weight:  6.65900000000038e-07 teacher_forcing_ratio:  0.9999993340999449\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.11831720173358917\n",
      "KL_weight:  6.709000000000383e-07 teacher_forcing_ratio:  0.9999993290999445\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.06767082959413528\n",
      "KL_weight:  6.759000000000387e-07 teacher_forcing_ratio:  0.9999993240999441\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.025484228506684303\n",
      "KL_weight:  6.809000000000391e-07 teacher_forcing_ratio:  0.9999993190999437\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.01769952103495598\n",
      "KL_weight:  6.859000000000395e-07 teacher_forcing_ratio:  0.9999993140999432\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.01111008320003748\n",
      "KL_weight:  6.909000000000398e-07 teacher_forcing_ratio:  0.9999993090999428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abbetaned \tScore:  0.14924\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     begrinks \tScore:  0.18092\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderts \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     senterws \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splotins \tScore:  0.20403\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredman \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     healfing \tScore:  0.34572\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.005747663322836161\n",
      "KL_weight:  6.979000000000404e-07 teacher_forcing_ratio:  0.9999993020999423\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.006127475295215845\n",
      "KL_weight:  7.029000000000407e-07 teacher_forcing_ratio:  0.9999992970999418\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0057451981119811535\n",
      "KL_weight:  7.079000000000411e-07 teacher_forcing_ratio:  0.9999992920999414\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.005002343561500311\n",
      "KL_weight:  7.129000000000415e-07 teacher_forcing_ratio:  0.999999287099941\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.004337165504693985\n",
      "KL_weight:  7.179000000000419e-07 teacher_forcing_ratio:  0.9999992820999406\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.004231747705489397\n",
      "KL_weight:  7.229000000000422e-07 teacher_forcing_ratio:  0.9999992770999402\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0037063146010041237\n",
      "KL_weight:  7.279000000000426e-07 teacher_forcing_ratio:  0.9999992720999398\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.003757782280445099\n",
      "KL_weight:  7.32900000000043e-07 teacher_forcing_ratio:  0.9999992670999394\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.003765217959880829\n",
      "KL_weight:  7.379000000000434e-07 teacher_forcing_ratio:  0.999999262099939\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.00309201842173934\n",
      "KL_weight:  7.429000000000437e-07 teacher_forcing_ratio:  0.9999992570999385\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002808845369145274\n",
      "KL_weight:  7.479000000000441e-07 teacher_forcing_ratio:  0.9999992520999381\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0028583232779055834\n",
      "KL_weight:  7.529000000000445e-07 teacher_forcing_ratio:  0.9999992470999377\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002930548507720232\n",
      "KL_weight:  7.579000000000449e-07 teacher_forcing_ratio:  0.9999992420999373\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002747411374002695\n",
      "KL_weight:  7.629000000000452e-07 teacher_forcing_ratio:  0.9999992370999369\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0027773233596235514\n",
      "KL_weight:  7.679000000000456e-07 teacher_forcing_ratio:  0.9999992320999365\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetches \tScore:  0.34572\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginks \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expenderated \tScore:  0.41723\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sentwers \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splithering \tScore:  0.46925\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flareduns \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healinges \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002397294621914625\n",
      "KL_weight:  7.749000000000461e-07 teacher_forcing_ratio:  0.9999992250999359\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002325408160686493\n",
      "KL_weight:  7.799000000000465e-07 teacher_forcing_ratio:  0.9999992200999355\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0021668761037290096\n",
      "KL_weight:  7.849000000000469e-07 teacher_forcing_ratio:  0.9999992150999351\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0023079016245901585\n",
      "KL_weight:  7.899000000000473e-07 teacher_forcing_ratio:  0.9999992100999346\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0021624413784593344\n",
      "KL_weight:  7.949000000000476e-07 teacher_forcing_ratio:  0.9999992050999342\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 300 char-loss:  0.002134758047759533\n",
      "KL_weight:  7.99900000000048e-07 teacher_forcing_ratio:  0.9999992000999338\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001980321016162634\n",
      "KL_weight:  8.049000000000484e-07 teacher_forcing_ratio:  0.9999991950999334\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0017695194110274315\n",
      "KL_weight:  8.099000000000488e-07 teacher_forcing_ratio:  0.999999190099933\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0018839745316654444\n",
      "KL_weight:  8.149000000000492e-07 teacher_forcing_ratio:  0.9999991850999326\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0016765538603067398\n",
      "KL_weight:  8.199000000000495e-07 teacher_forcing_ratio:  0.9999991800999322\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0017143248114734888\n",
      "KL_weight:  8.249000000000499e-07 teacher_forcing_ratio:  0.9999991750999317\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0016419077292084694\n",
      "KL_weight:  8.299000000000503e-07 teacher_forcing_ratio:  0.9999991700999313\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0017932872287929058\n",
      "KL_weight:  8.349000000000507e-07 teacher_forcing_ratio:  0.9999991650999309\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0016996918711811304\n",
      "KL_weight:  8.39900000000051e-07 teacher_forcing_ratio:  0.9999991600999305\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0015355120413005352\n",
      "KL_weight:  8.449000000000514e-07 teacher_forcing_ratio:  0.9999991550999301\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetches \tScore:  0.34572\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginks \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expnoweds \tScore:  0.16233\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senterwade \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splithering \tScore:  0.46925\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredman \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     healfing \tScore:  0.34572\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015613867435604334\n",
      "KL_weight:  8.519000000000519e-07 teacher_forcing_ratio:  0.9999991480999295\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0015491287922486663\n",
      "KL_weight:  8.569000000000523e-07 teacher_forcing_ratio:  0.9999991430999291\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017203653696924448\n",
      "KL_weight:  8.619000000000527e-07 teacher_forcing_ratio:  0.9999991380999287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014551946660503745\n",
      "KL_weight:  8.669000000000531e-07 teacher_forcing_ratio:  0.9999991330999283\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001534987473860383\n",
      "KL_weight:  8.719000000000534e-07 teacher_forcing_ratio:  0.9999991280999279\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0013749529607594013\n",
      "KL_weight:  8.769000000000538e-07 teacher_forcing_ratio:  0.9999991230999274\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0013925331877544522\n",
      "KL_weight:  8.819000000000542e-07 teacher_forcing_ratio:  0.999999118099927\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0013570920564234257\n",
      "KL_weight:  8.869000000000546e-07 teacher_forcing_ratio:  0.9999991130999266\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0013140254886820912\n",
      "KL_weight:  8.919000000000549e-07 teacher_forcing_ratio:  0.9999991080999262\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0013310597278177738\n",
      "KL_weight:  8.969000000000553e-07 teacher_forcing_ratio:  0.9999991030999258\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0012379507534205914\n",
      "KL_weight:  9.019000000000557e-07 teacher_forcing_ratio:  0.9999990980999254\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001297444337978959\n",
      "KL_weight:  9.069000000000561e-07 teacher_forcing_ratio:  0.999999093099925\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0012872847728431225\n",
      "KL_weight:  9.119000000000564e-07 teacher_forcing_ratio:  0.9999990880999245\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0012371354969218373\n",
      "KL_weight:  9.169000000000568e-07 teacher_forcing_ratio:  0.9999990830999241\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001303821336477995\n",
      "KL_weight:  9.219000000000572e-07 teacher_forcing_ratio:  0.9999990780999237\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abandonks \tScore:  0.72598\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetfers \tScore:  0.34572\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begrinkes \tScore:  0.15620\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expenderated \tScore:  0.41723\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentweris \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splither \tScore:  0.45623\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredman \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healizens \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001086276606656611\n",
      "KL_weight:  9.289000000000577e-07 teacher_forcing_ratio:  0.9999990710999231\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0011148025514557958\n",
      "KL_weight:  9.339000000000581e-07 teacher_forcing_ratio:  0.9999990660999227\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0010795872658491135\n",
      "KL_weight:  9.389000000000585e-07 teacher_forcing_ratio:  0.9999990610999223\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0010609208839014173\n",
      "KL_weight:  9.439000000000588e-07 teacher_forcing_ratio:  0.9999990560999219\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0010889507830142975\n",
      "KL_weight:  9.489000000000592e-07 teacher_forcing_ratio:  0.9999990510999215\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0010898514883592725\n",
      "KL_weight:  9.539000000000596e-07 teacher_forcing_ratio:  0.9999990460999211\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.0010674401419237256\n",
      "KL_weight:  9.5890000000006e-07 teacher_forcing_ratio:  0.9999990410999207\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001057362649589777\n",
      "KL_weight:  9.639000000000603e-07 teacher_forcing_ratio:  0.9999990360999202\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0010523293167352676\n",
      "KL_weight:  9.689000000000607e-07 teacher_forcing_ratio:  0.9999990310999198\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0010314162354916334\n",
      "KL_weight:  9.73900000000061e-07 teacher_forcing_ratio:  0.9999990260999194\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0010282929288223386\n",
      "KL_weight:  9.789000000000615e-07 teacher_forcing_ratio:  0.999999021099919\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0010415775468572974\n",
      "KL_weight:  9.839000000000618e-07 teacher_forcing_ratio:  0.9999990160999186\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011035117786377668\n",
      "KL_weight:  9.889000000000622e-07 teacher_forcing_ratio:  0.9999990110999182\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0009873935487121344\n",
      "KL_weight:  9.939000000000626e-07 teacher_forcing_ratio:  0.9999990060999178\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.34763091802597046\n",
      "KL_weight:  9.98900000000063e-07 teacher_forcing_ratio:  0.9999990010999174\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   adanforney \tScore:  0.07260\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      abtense \tScore:  0.07614\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befighten \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    explended \tScore:  0.19960\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    senterves \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitchew \tScore:  0.44632\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarged \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fanstifount \tScore:  0.06484\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  fantulcting \tScore:  0.11531\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   healowings \tScore:  0.27776\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.05296340212225914\n",
      "KL_weight:  1.0059000000000635e-06 teacher_forcing_ratio:  0.9999989940999168\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.02587226778268814\n",
      "KL_weight:  1.0109000000000639e-06 teacher_forcing_ratio:  0.9999989890999164\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.011172623373568058\n",
      "KL_weight:  1.0159000000000643e-06 teacher_forcing_ratio:  0.9999989840999159\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.004735455382615328\n",
      "KL_weight:  1.0209000000000646e-06 teacher_forcing_ratio:  0.9999989790999155\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.003752522636204958\n",
      "KL_weight:  1.025900000000065e-06 teacher_forcing_ratio:  0.9999989740999151\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0032445695251226425\n",
      "KL_weight:  1.0309000000000654e-06 teacher_forcing_ratio:  0.9999989690999147\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0027603665366768837\n",
      "KL_weight:  1.0359000000000658e-06 teacher_forcing_ratio:  0.9999989640999143\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0028150896541774273\n",
      "KL_weight:  1.0409000000000661e-06 teacher_forcing_ratio:  0.9999989590999139\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0026383441872894764\n",
      "KL_weight:  1.0459000000000665e-06 teacher_forcing_ratio:  0.9999989540999135\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0024093561805784702\n",
      "KL_weight:  1.0509000000000669e-06 teacher_forcing_ratio:  0.999998949099913\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0020946504082530737\n",
      "KL_weight:  1.0559000000000673e-06 teacher_forcing_ratio:  0.9999989440999126\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0022651255130767822\n",
      "KL_weight:  1.0609000000000676e-06 teacher_forcing_ratio:  0.9999989390999122\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002146290149539709\n",
      "KL_weight:  1.065900000000068e-06 teacher_forcing_ratio:  0.9999989340999118\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001958457985892892\n",
      "KL_weight:  1.0709000000000684e-06 teacher_forcing_ratio:  0.9999989290999114\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002075709868222475\n",
      "KL_weight:  1.0759000000000688e-06 teacher_forcing_ratio:  0.999998924099911\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandoncing \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abetshein \tScore:  0.35495\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begringing \tScore:  0.16784\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    explendes \tScore:  0.20744\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sensowted \tScore:  0.13485\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitches \tScore:  0.44632\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredman \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healinges \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0018004138255491853\n",
      "KL_weight:  1.0829000000000693e-06 teacher_forcing_ratio:  0.9999989170999104\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0017651519738137722\n",
      "KL_weight:  1.0879000000000697e-06 teacher_forcing_ratio:  0.99999891209991\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0018366712611168623\n",
      "KL_weight:  1.09290000000007e-06 teacher_forcing_ratio:  0.9999989070999096\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001471721800044179\n",
      "KL_weight:  1.0979000000000704e-06 teacher_forcing_ratio:  0.9999989020999092\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0016914804000407457\n",
      "KL_weight:  1.1029000000000708e-06 teacher_forcing_ratio:  0.9999988970999087\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0016003584023565054\n",
      "KL_weight:  1.1079000000000712e-06 teacher_forcing_ratio:  0.9999988920999083\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001734443474560976\n",
      "KL_weight:  1.1129000000000715e-06 teacher_forcing_ratio:  0.9999988870999079\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 400 char-loss:  0.001570563530549407\n",
      "KL_weight:  1.117900000000072e-06 teacher_forcing_ratio:  0.9999988820999075\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001619880087673664\n",
      "KL_weight:  1.1229000000000723e-06 teacher_forcing_ratio:  0.9999988770999071\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0015364123973995447\n",
      "KL_weight:  1.1279000000000727e-06 teacher_forcing_ratio:  0.9999988720999067\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0014304689830169082\n",
      "KL_weight:  1.132900000000073e-06 teacher_forcing_ratio:  0.9999988670999063\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001485710497945547\n",
      "KL_weight:  1.1379000000000734e-06 teacher_forcing_ratio:  0.9999988620999058\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.001485448912717402\n",
      "KL_weight:  1.1429000000000738e-06 teacher_forcing_ratio:  0.9999988570999054\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0012988215312361717\n",
      "KL_weight:  1.1479000000000742e-06 teacher_forcing_ratio:  0.999998852099905\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0013198850210756063\n",
      "KL_weight:  1.1529000000000745e-06 teacher_forcing_ratio:  0.9999988470999046\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandonake \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abetchering \tScore:  0.33933\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beginfes \tScore:  0.54108\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   explendert \tScore:  0.17567\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     senforts \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splitche \tScore:  0.45623\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flaredming \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  healizening \tScore:  0.23462\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0012774612987414002\n",
      "KL_weight:  1.159900000000075e-06 teacher_forcing_ratio:  0.999998840099904\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0013300295686349273\n",
      "KL_weight:  1.1649000000000754e-06 teacher_forcing_ratio:  0.9999988350999036\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.00121922860853374\n",
      "KL_weight:  1.1699000000000758e-06 teacher_forcing_ratio:  0.9999988300999032\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011705502402037382\n",
      "KL_weight:  1.1749000000000762e-06 teacher_forcing_ratio:  0.9999988250999028\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001228849752806127\n",
      "KL_weight:  1.1799000000000766e-06 teacher_forcing_ratio:  0.9999988200999024\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0010572089813649654\n",
      "KL_weight:  1.184900000000077e-06 teacher_forcing_ratio:  0.999998815099902\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0012134872376918793\n",
      "KL_weight:  1.1899000000000773e-06 teacher_forcing_ratio:  0.9999988100999015\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001175653887912631\n",
      "KL_weight:  1.1949000000000777e-06 teacher_forcing_ratio:  0.9999988050999011\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0010451421840116382\n",
      "KL_weight:  1.199900000000078e-06 teacher_forcing_ratio:  0.9999988000999007\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0011885757558047771\n",
      "KL_weight:  1.2049000000000785e-06 teacher_forcing_ratio:  0.9999987950999003\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001087354263290763\n",
      "KL_weight:  1.2099000000000788e-06 teacher_forcing_ratio:  0.9999987900998999\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0010253755608573556\n",
      "KL_weight:  1.2149000000000792e-06 teacher_forcing_ratio:  0.9999987850998995\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011105805169790983\n",
      "KL_weight:  1.2199000000000796e-06 teacher_forcing_ratio:  0.9999987800998991\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0010200102115049958\n",
      "KL_weight:  1.22490000000008e-06 teacher_forcing_ratio:  0.9999987750998987\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0010140747763216496\n",
      "KL_weight:  1.2299000000000803e-06 teacher_forcing_ratio:  0.9999987700998982\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandoncing \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetches \tScore:  0.34572\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     besfoign \tScore:  0.07731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   explenders \tScore:  0.18257\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     senforts \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   sploisting \tScore:  0.39281\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flaredming \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healinges \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0010689720511436462\n",
      "KL_weight:  1.2369000000000809e-06 teacher_forcing_ratio:  0.9999987630998977\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0010302331065759063\n",
      "KL_weight:  1.2419000000000812e-06 teacher_forcing_ratio:  0.9999987580998972\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0010404579807072878\n",
      "KL_weight:  1.2469000000000816e-06 teacher_forcing_ratio:  0.9999987530998968\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0009819655679166317\n",
      "KL_weight:  1.251900000000082e-06 teacher_forcing_ratio:  0.9999987480998964\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001011338783428073\n",
      "KL_weight:  1.2569000000000824e-06 teacher_forcing_ratio:  0.999998743099896\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0009808053728193045\n",
      "KL_weight:  1.2619000000000827e-06 teacher_forcing_ratio:  0.9999987380998956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0009005909669212997\n",
      "KL_weight:  1.2669000000000831e-06 teacher_forcing_ratio:  0.9999987330998952\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0009279190562665462\n",
      "KL_weight:  1.2719000000000835e-06 teacher_forcing_ratio:  0.9999987280998948\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 450 char-loss:  0.000980951590463519\n",
      "KL_weight:  1.2769000000000839e-06 teacher_forcing_ratio:  0.9999987230998943\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0009178949403576553\n",
      "KL_weight:  1.2819000000000842e-06 teacher_forcing_ratio:  0.9999987180998939\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0009161449270322919\n",
      "KL_weight:  1.2869000000000846e-06 teacher_forcing_ratio:  0.9999987130998935\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0008692715200595558\n",
      "KL_weight:  1.291900000000085e-06 teacher_forcing_ratio:  0.9999987080998931\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0009467486524954438\n",
      "KL_weight:  1.2969000000000854e-06 teacher_forcing_ratio:  0.9999987030998927\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0008215835550799966\n",
      "KL_weight:  1.3019000000000857e-06 teacher_forcing_ratio:  0.9999986980998923\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0008393506286665797\n",
      "KL_weight:  1.3069000000000861e-06 teacher_forcing_ratio:  0.9999986930998919\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandoncing \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   abestering \tScore:  0.18257\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginks \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   explenders \tScore:  0.18257\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snewatest \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitchear \tScore:  0.39281\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaredman \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healching \tScore:  0.29847\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0008790444117039442\n",
      "KL_weight:  1.3139000000000866e-06 teacher_forcing_ratio:  0.9999986860998913\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0008238707669079304\n",
      "KL_weight:  1.318900000000087e-06 teacher_forcing_ratio:  0.9999986810998909\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0009119234746322036\n",
      "KL_weight:  1.3239000000000874e-06 teacher_forcing_ratio:  0.9999986760998905\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0009241151274181902\n",
      "KL_weight:  1.3289000000000878e-06 teacher_forcing_ratio:  0.99999867109989\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0008311757701449096\n",
      "KL_weight:  1.3339000000000881e-06 teacher_forcing_ratio:  0.9999986660998896\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0008454054477624595\n",
      "KL_weight:  1.3389000000000885e-06 teacher_forcing_ratio:  0.9999986610998892\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0008608808275312185\n",
      "KL_weight:  1.343900000000089e-06 teacher_forcing_ratio:  0.9999986560998888\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0007855618023313582\n",
      "KL_weight:  1.3489000000000893e-06 teacher_forcing_ratio:  0.9999986510998884\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0007756269187666476\n",
      "KL_weight:  1.3539000000000896e-06 teacher_forcing_ratio:  0.999998646099888\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0007884023361839354\n",
      "KL_weight:  1.35890000000009e-06 teacher_forcing_ratio:  0.9999986410998876\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0007935299654491246\n",
      "KL_weight:  1.3639000000000904e-06 teacher_forcing_ratio:  0.9999986360998872\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0008249940001405776\n",
      "KL_weight:  1.3689000000000908e-06 teacher_forcing_ratio:  0.9999986310998867\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0008928634342737496\n",
      "KL_weight:  1.3739000000000911e-06 teacher_forcing_ratio:  0.9999986260998863\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.000748408492654562\n",
      "KL_weight:  1.3789000000000915e-06 teacher_forcing_ratio:  0.9999986210998859\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0007324140169657767\n",
      "KL_weight:  1.383900000000092e-06 teacher_forcing_ratio:  0.9999986160998855\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandoncing \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abbetched \tScore:  0.14114\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      beginks \tScore:  0.64346\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    explonest \tScore:  0.14114\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     snewotes \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splister \tScore:  0.32260\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flaroned \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   healchinge \tScore:  0.26269\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0006848162738606334\n",
      "KL_weight:  1.3909000000000924e-06 teacher_forcing_ratio:  0.9999986090998849\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0007952041923999786\n",
      "KL_weight:  1.3959000000000928e-06 teacher_forcing_ratio:  0.9999986040998845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1207374557852745\n",
      "KL_weight:  1.4009000000000932e-06 teacher_forcing_ratio:  0.9999985990998841\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.026151495054364204\n",
      "KL_weight:  1.4059000000000936e-06 teacher_forcing_ratio:  0.9999985940998837\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.00652663130313158\n",
      "KL_weight:  1.410900000000094e-06 teacher_forcing_ratio:  0.9999985890998833\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00534942839294672\n",
      "KL_weight:  1.4159000000000943e-06 teacher_forcing_ratio:  0.9999985840998828\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0033712112344801426\n",
      "KL_weight:  1.4209000000000947e-06 teacher_forcing_ratio:  0.9999985790998824\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0029907808639109135\n",
      "KL_weight:  1.425900000000095e-06 teacher_forcing_ratio:  0.999998574099882\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002647851128131151\n",
      "KL_weight:  1.4309000000000954e-06 teacher_forcing_ratio:  0.9999985690998816\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500 char-loss:  0.0025265857111662626\n",
      "KL_weight:  1.4359000000000958e-06 teacher_forcing_ratio:  0.9999985640998812\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002448050770908594\n",
      "KL_weight:  1.4409000000000962e-06 teacher_forcing_ratio:  0.9999985590998808\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0023425885010510683\n",
      "KL_weight:  1.4459000000000966e-06 teacher_forcing_ratio:  0.9999985540998804\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002074556890875101\n",
      "KL_weight:  1.450900000000097e-06 teacher_forcing_ratio:  0.99999854909988\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002197963884100318\n",
      "KL_weight:  1.4559000000000973e-06 teacher_forcing_ratio:  0.9999985440998795\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002071860246360302\n",
      "KL_weight:  1.4609000000000977e-06 teacher_forcing_ratio:  0.9999985390998791\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandoncing \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abbetted \tScore:  0.39281\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begrinked \tScore:  0.14924\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     expender \tScore:  0.68037\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senterated \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitpate \tScore:  0.46714\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flardewing \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: heawhineling \tScore:  0.09059\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002005109330639243\n",
      "KL_weight:  1.4679000000000982e-06 teacher_forcing_ratio:  0.9999985320998785\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0018815048970282078\n",
      "KL_weight:  1.4729000000000986e-06 teacher_forcing_ratio:  0.9999985270998781\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0019374627154320478\n",
      "KL_weight:  1.477900000000099e-06 teacher_forcing_ratio:  0.9999985220998777\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0018230166751891375\n",
      "KL_weight:  1.4829000000000993e-06 teacher_forcing_ratio:  0.9999985170998773\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0018494445830583572\n",
      "KL_weight:  1.4879000000000997e-06 teacher_forcing_ratio:  0.9999985120998769\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0016740465071052313\n",
      "KL_weight:  1.4929000000001e-06 teacher_forcing_ratio:  0.9999985070998765\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001615904737263918\n",
      "KL_weight:  1.4979000000001005e-06 teacher_forcing_ratio:  0.9999985020998761\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016237935051321983\n",
      "KL_weight:  1.5029000000001008e-06 teacher_forcing_ratio:  0.9999984970998756\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0015883005689829588\n",
      "KL_weight:  1.5079000000001012e-06 teacher_forcing_ratio:  0.9999984920998752\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0015759369125589728\n",
      "KL_weight:  1.5129000000001016e-06 teacher_forcing_ratio:  0.9999984870998748\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015883741434663534\n",
      "KL_weight:  1.517900000000102e-06 teacher_forcing_ratio:  0.9999984820998744\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001451363554224372\n",
      "KL_weight:  1.5229000000001023e-06 teacher_forcing_ratio:  0.999998477099874\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0014661680907011032\n",
      "KL_weight:  1.5279000000001027e-06 teacher_forcing_ratio:  0.9999984720998736\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014059317763894796\n",
      "KL_weight:  1.532900000000103e-06 teacher_forcing_ratio:  0.9999984670998732\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0014830008149147034\n",
      "KL_weight:  1.5379000000001035e-06 teacher_forcing_ratio:  0.9999984620998728\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandoncew \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   abethering \tScore:  0.37992\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begringed \tScore:  0.14924\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderak \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senterated \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splithering \tScore:  0.46925\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flardewing \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    hearlinge \tScore:  0.12753\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0014361586654558778\n",
      "KL_weight:  1.544900000000104e-06 teacher_forcing_ratio:  0.9999984550998722\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0013834580313414335\n",
      "KL_weight:  1.5499000000001044e-06 teacher_forcing_ratio:  0.9999984500998718\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0013610073365271091\n",
      "KL_weight:  1.5549000000001047e-06 teacher_forcing_ratio:  0.9999984450998713\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014100598637014627\n",
      "KL_weight:  1.5599000000001051e-06 teacher_forcing_ratio:  0.9999984400998709\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001286149024963379\n",
      "KL_weight:  1.5649000000001055e-06 teacher_forcing_ratio:  0.9999984350998705\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014438736252486706\n",
      "KL_weight:  1.5699000000001059e-06 teacher_forcing_ratio:  0.9999984300998701\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0012007802724838257\n",
      "KL_weight:  1.5749000000001063e-06 teacher_forcing_ratio:  0.9999984250998697\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0012471139198169112\n",
      "KL_weight:  1.5799000000001066e-06 teacher_forcing_ratio:  0.9999984200998693\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001147320494055748\n",
      "KL_weight:  1.584900000000107e-06 teacher_forcing_ratio:  0.9999984150998689\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001269038999453187\n",
      "KL_weight:  1.5899000000001074e-06 teacher_forcing_ratio:  0.9999984100998685\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 550 char-loss:  0.0012478618882596493\n",
      "KL_weight:  1.5949000000001078e-06 teacher_forcing_ratio:  0.999998405099868\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.00128021533600986\n",
      "KL_weight:  1.5999000000001081e-06 teacher_forcing_ratio:  0.9999984000998676\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0012325395364314318\n",
      "KL_weight:  1.6049000000001085e-06 teacher_forcing_ratio:  0.9999983950998672\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0011645273771137\n",
      "KL_weight:  1.6099000000001089e-06 teacher_forcing_ratio:  0.9999983900998668\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0011295854346826673\n",
      "KL_weight:  1.6149000000001093e-06 teacher_forcing_ratio:  0.9999983850998664\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abandorening \tScore:  0.44834\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abbetted \tScore:  0.39281\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    beferting \tScore:  0.07583\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderak \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      senters \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitreap \tScore:  0.44632\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarbedge \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hearklening \tScore:  0.10025\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0011559813283383846\n",
      "KL_weight:  1.6219000000001098e-06 teacher_forcing_ratio:  0.9999983780998658\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0011187986237928271\n",
      "KL_weight:  1.6269000000001102e-06 teacher_forcing_ratio:  0.9999983730998654\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0011388009879738092\n",
      "KL_weight:  1.6319000000001105e-06 teacher_forcing_ratio:  0.999998368099865\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0010938772466033697\n",
      "KL_weight:  1.636900000000111e-06 teacher_forcing_ratio:  0.9999983630998646\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001109194359742105\n",
      "KL_weight:  1.6419000000001113e-06 teacher_forcing_ratio:  0.9999983580998641\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00107960298191756\n",
      "KL_weight:  1.6469000000001117e-06 teacher_forcing_ratio:  0.9999983530998637\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0010041836649179459\n",
      "KL_weight:  1.651900000000112e-06 teacher_forcing_ratio:  0.9999983480998633\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0010801247553899884\n",
      "KL_weight:  1.6569000000001124e-06 teacher_forcing_ratio:  0.9999983430998629\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0009818457765504718\n",
      "KL_weight:  1.6619000000001128e-06 teacher_forcing_ratio:  0.9999983380998625\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0010227544698864222\n",
      "KL_weight:  1.6669000000001132e-06 teacher_forcing_ratio:  0.9999983330998621\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0010192164918407798\n",
      "KL_weight:  1.6719000000001135e-06 teacher_forcing_ratio:  0.9999983280998617\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.000982804805971682\n",
      "KL_weight:  1.676900000000114e-06 teacher_forcing_ratio:  0.9999983230998613\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0010264237644150853\n",
      "KL_weight:  1.6819000000001143e-06 teacher_forcing_ratio:  0.9999983180998608\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0010500723728910089\n",
      "KL_weight:  1.6869000000001147e-06 teacher_forcing_ratio:  0.9999983130998604\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0009780509863048792\n",
      "KL_weight:  1.691900000000115e-06 teacher_forcing_ratio:  0.99999830809986\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandoncew \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   abethering \tScore:  0.37992\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beforign \tScore:  0.07386\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expenderaks \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snetweard \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splistarying \tScore:  0.31702\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarbedgin \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    hearlinge \tScore:  0.12753\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0009159778710454702\n",
      "KL_weight:  1.6989000000001156e-06 teacher_forcing_ratio:  0.9999983010998594\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0009809277253225446\n",
      "KL_weight:  1.703900000000116e-06 teacher_forcing_ratio:  0.999998296099859\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0010041543282568455\n",
      "KL_weight:  1.7089000000001163e-06 teacher_forcing_ratio:  0.9999982910998586\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0010414575226604939\n",
      "KL_weight:  1.7139000000001167e-06 teacher_forcing_ratio:  0.9999982860998582\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0008941960986703634\n",
      "KL_weight:  1.718900000000117e-06 teacher_forcing_ratio:  0.9999982810998578\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0008902046829462051\n",
      "KL_weight:  1.7239000000001174e-06 teacher_forcing_ratio:  0.9999982760998574\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.000869138166308403\n",
      "KL_weight:  1.7289000000001178e-06 teacher_forcing_ratio:  0.999998271099857\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0009370300685986876\n",
      "KL_weight:  1.7339000000001182e-06 teacher_forcing_ratio:  0.9999982660998565\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0009597644675523043\n",
      "KL_weight:  1.7389000000001186e-06 teacher_forcing_ratio:  0.9999982610998561\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0009347834857180715\n",
      "KL_weight:  1.743900000000119e-06 teacher_forcing_ratio:  0.9999982560998557\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0009187855175696313\n",
      "KL_weight:  1.7489000000001193e-06 teacher_forcing_ratio:  0.9999982510998553\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 600 char-loss:  0.000882943975739181\n",
      "KL_weight:  1.7539000000001197e-06 teacher_forcing_ratio:  0.9999982460998549\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0008643291075713933\n",
      "KL_weight:  1.75890000000012e-06 teacher_forcing_ratio:  0.9999982410998545\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0008427620050497353\n",
      "KL_weight:  1.7639000000001204e-06 teacher_forcing_ratio:  0.999998236099854\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0008844155818223953\n",
      "KL_weight:  1.7689000000001208e-06 teacher_forcing_ratio:  0.9999982310998536\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandoncew \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abbenter \tScore:  0.08784\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   beforigned \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderak \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     swenters \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitreak \tScore:  0.44632\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarbed \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionying \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healfingh \tScore:  0.29847\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0009093900443986058\n",
      "KL_weight:  1.7759000000001214e-06 teacher_forcing_ratio:  0.9999982240998531\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0008314732112921774\n",
      "KL_weight:  1.7809000000001217e-06 teacher_forcing_ratio:  0.9999982190998526\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0008042152039706707\n",
      "KL_weight:  1.785900000000122e-06 teacher_forcing_ratio:  0.9999982140998522\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0007550157606601715\n",
      "KL_weight:  1.7909000000001225e-06 teacher_forcing_ratio:  0.9999982090998518\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14397281408309937\n",
      "KL_weight:  1.7959000000001229e-06 teacher_forcing_ratio:  0.9999982040998514\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08453679829835892\n",
      "KL_weight:  1.8009000000001232e-06 teacher_forcing_ratio:  0.999998199099851\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.009293459355831146\n",
      "KL_weight:  1.8059000000001236e-06 teacher_forcing_ratio:  0.9999981940998506\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.004708853550255299\n",
      "KL_weight:  1.810900000000124e-06 teacher_forcing_ratio:  0.9999981890998502\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0036371243186295033\n",
      "KL_weight:  1.8159000000001244e-06 teacher_forcing_ratio:  0.9999981840998498\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0027528060600161552\n",
      "KL_weight:  1.8209000000001247e-06 teacher_forcing_ratio:  0.9999981790998493\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0025908611714839935\n",
      "KL_weight:  1.8259000000001251e-06 teacher_forcing_ratio:  0.9999981740998489\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0022465232759714127\n",
      "KL_weight:  1.8309000000001255e-06 teacher_forcing_ratio:  0.9999981690998485\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0023129498586058617\n",
      "KL_weight:  1.8359000000001259e-06 teacher_forcing_ratio:  0.9999981640998481\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002043673302978277\n",
      "KL_weight:  1.8409000000001262e-06 teacher_forcing_ratio:  0.9999981590998477\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0018734033219516277\n",
      "KL_weight:  1.8459000000001266e-06 teacher_forcing_ratio:  0.9999981540998473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandonked \tScore:  0.70711\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abterfied \tScore:  0.06377\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begrinked \tScore:  0.14924\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expendiens \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stenswer \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splistering \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flargeld \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearklinge \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002034801058471203\n",
      "KL_weight:  1.8529000000001271e-06 teacher_forcing_ratio:  0.9999981470998467\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.001832829788327217\n",
      "KL_weight:  1.8579000000001275e-06 teacher_forcing_ratio:  0.9999981420998463\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.001998962601646781\n",
      "KL_weight:  1.8629000000001279e-06 teacher_forcing_ratio:  0.9999981370998459\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0016578588401898742\n",
      "KL_weight:  1.8679000000001283e-06 teacher_forcing_ratio:  0.9999981320998454\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0017189306672662497\n",
      "KL_weight:  1.8729000000001286e-06 teacher_forcing_ratio:  0.999998127099845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001601488096639514\n",
      "KL_weight:  1.877900000000129e-06 teacher_forcing_ratio:  0.9999981220998446\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001691830693744123\n",
      "KL_weight:  1.8829000000001294e-06 teacher_forcing_ratio:  0.9999981170998442\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016611298779025674\n",
      "KL_weight:  1.8879000000001298e-06 teacher_forcing_ratio:  0.9999981120998438\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001696670544333756\n",
      "KL_weight:  1.8929000000001301e-06 teacher_forcing_ratio:  0.9999981070998434\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0015227941330522299\n",
      "KL_weight:  1.8979000000001305e-06 teacher_forcing_ratio:  0.999998102099843\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015142838237807155\n",
      "KL_weight:  1.9029000000001309e-06 teacher_forcing_ratio:  0.9999980970998426\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0014633332611992955\n",
      "KL_weight:  1.90790000000013e-06 teacher_forcing_ratio:  0.9999980920998421\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 650 char-loss:  0.001462425570935011\n",
      "KL_weight:  1.9129000000001198e-06 teacher_forcing_ratio:  0.9999980870998417\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0015828754985705018\n",
      "KL_weight:  1.9179000000001096e-06 teacher_forcing_ratio:  0.9999980820998413\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001480922452174127\n",
      "KL_weight:  1.9229000000000994e-06 teacher_forcing_ratio:  0.9999980770998409\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandonking \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   abetrainge \tScore:  0.37992\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begribend \tScore:  0.13485\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expendiends \tScore:  0.57067\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stenwers \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splistering \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarked \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fundicturing \tScore:  0.11531\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hearklinged \tScore:  0.10025\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0012968211667612195\n",
      "KL_weight:  1.929900000000085e-06 teacher_forcing_ratio:  0.9999980700998403\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0014481785474345088\n",
      "KL_weight:  1.934900000000075e-06 teacher_forcing_ratio:  0.9999980650998399\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0014485258143395185\n",
      "KL_weight:  1.9399000000000646e-06 teacher_forcing_ratio:  0.9999980600998395\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001432348508387804\n",
      "KL_weight:  1.9449000000000544e-06 teacher_forcing_ratio:  0.9999980550998391\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001228563953191042\n",
      "KL_weight:  1.9499000000000442e-06 teacher_forcing_ratio:  0.9999980500998387\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0013204370625317097\n",
      "KL_weight:  1.954900000000034e-06 teacher_forcing_ratio:  0.9999980450998383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0012816236121580005\n",
      "KL_weight:  1.959900000000024e-06 teacher_forcing_ratio:  0.9999980400998378\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0011906587751582265\n",
      "KL_weight:  1.9649000000000136e-06 teacher_forcing_ratio:  0.9999980350998374\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0012503353646025062\n",
      "KL_weight:  1.9699000000000034e-06 teacher_forcing_ratio:  0.999998030099837\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0011118053225800395\n",
      "KL_weight:  1.974899999999993e-06 teacher_forcing_ratio:  0.9999980250998366\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0011818294879049063\n",
      "KL_weight:  1.979899999999983e-06 teacher_forcing_ratio:  0.9999980200998362\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0012061850866302848\n",
      "KL_weight:  1.9848999999999727e-06 teacher_forcing_ratio:  0.9999980150998358\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011940442491322756\n",
      "KL_weight:  1.9898999999999625e-06 teacher_forcing_ratio:  0.9999980100998354\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0011534392833709717\n",
      "KL_weight:  1.9948999999999523e-06 teacher_forcing_ratio:  0.9999980050998349\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001143762026913464\n",
      "KL_weight:  1.999899999999942e-06 teacher_forcing_ratio:  0.9999980000998345\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandoning \tScore:  0.63894\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abterfied \tScore:  0.06377\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begriftend \tScore:  0.11868\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expendires \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stenvers \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splistring \tScore:  0.39281\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarked \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fundicturing \tScore:  0.11531\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearklinge \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001091932412236929\n",
      "KL_weight:  2.006899999999928e-06 teacher_forcing_ratio:  0.999997993099834\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.001171998679637909\n",
      "KL_weight:  2.0118999999999176e-06 teacher_forcing_ratio:  0.9999979880998335\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0010810933308675885\n",
      "KL_weight:  2.0168999999999074e-06 teacher_forcing_ratio:  0.9999979830998331\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011101129930466413\n",
      "KL_weight:  2.021899999999897e-06 teacher_forcing_ratio:  0.9999979780998327\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0011422914685681462\n",
      "KL_weight:  2.026899999999887e-06 teacher_forcing_ratio:  0.9999979730998323\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0010799749288707972\n",
      "KL_weight:  2.0318999999998767e-06 teacher_forcing_ratio:  0.9999979680998319\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0011626894120126963\n",
      "KL_weight:  2.0368999999998665e-06 teacher_forcing_ratio:  0.9999979630998315\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001064747804775834\n",
      "KL_weight:  2.0418999999998563e-06 teacher_forcing_ratio:  0.999997958099831\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0010975932236760855\n",
      "KL_weight:  2.046899999999846e-06 teacher_forcing_ratio:  0.9999979530998306\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0010010102996602654\n",
      "KL_weight:  2.051899999999836e-06 teacher_forcing_ratio:  0.9999979480998302\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0010289992205798626\n",
      "KL_weight:  2.0568999999998257e-06 teacher_forcing_ratio:  0.9999979430998298\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0009721966343931854\n",
      "KL_weight:  2.0618999999998155e-06 teacher_forcing_ratio:  0.9999979380998294\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0010872173588722944\n",
      "KL_weight:  2.0668999999998052e-06 teacher_forcing_ratio:  0.999997933099829\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 700 char-loss:  0.0009927033679559827\n",
      "KL_weight:  2.071899999999795e-06 teacher_forcing_ratio:  0.9999979280998286\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0035966383293271065\n",
      "KL_weight:  2.076899999999785e-06 teacher_forcing_ratio:  0.9999979230998282\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandonking \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abetrainged \tScore:  0.33933\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bergainked \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expenders \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stensore \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  spliptering \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flardening \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functioninging \tScore:  0.51424\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearlinged \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.06033959239721298\n",
      "KL_weight:  2.0838999999997705e-06 teacher_forcing_ratio:  0.9999979160998276\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.02331557124853134\n",
      "KL_weight:  2.0888999999997603e-06 teacher_forcing_ratio:  0.9999979110998272\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.012226506136357784\n",
      "KL_weight:  2.09389999999975e-06 teacher_forcing_ratio:  0.9999979060998267\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.003811210859566927\n",
      "KL_weight:  2.09889999999974e-06 teacher_forcing_ratio:  0.9999979010998263\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0025894753634929657\n",
      "KL_weight:  2.1038999999997297e-06 teacher_forcing_ratio:  0.9999978960998259\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023998008109629154\n",
      "KL_weight:  2.1088999999997195e-06 teacher_forcing_ratio:  0.9999978910998255\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.00210584863089025\n",
      "KL_weight:  2.1138999999997093e-06 teacher_forcing_ratio:  0.9999978860998251\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001931736129336059\n",
      "KL_weight:  2.118899999999699e-06 teacher_forcing_ratio:  0.9999978810998247\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0019295667298138142\n",
      "KL_weight:  2.123899999999689e-06 teacher_forcing_ratio:  0.9999978760998243\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002078582998365164\n",
      "KL_weight:  2.1288999999996786e-06 teacher_forcing_ratio:  0.9999978710998239\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0019302326254546642\n",
      "KL_weight:  2.1338999999996684e-06 teacher_forcing_ratio:  0.9999978660998234\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0017599603161215782\n",
      "KL_weight:  2.138899999999658e-06 teacher_forcing_ratio:  0.999997861099823\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0017748998943716288\n",
      "KL_weight:  2.143899999999648e-06 teacher_forcing_ratio:  0.9999978560998226\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0017125677550211549\n",
      "KL_weight:  2.1488999999996378e-06 teacher_forcing_ratio:  0.9999978510998222\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001694065285846591\n",
      "KL_weight:  2.1538999999996276e-06 teacher_forcing_ratio:  0.9999978460998218\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonwacked \tScore:  0.07176\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abstering \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beshoing \tScore:  0.09193\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expendred \tScore:  0.58739\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stensore \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splisting \tScore:  0.59695\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   falderling \tScore:  0.03156\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functioninged \tScore:  0.61154\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearlinges \tScore:  0.11868\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0016251171473413706\n",
      "KL_weight:  2.1608999999996133e-06 teacher_forcing_ratio:  0.9999978390998212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016623600386083126\n",
      "KL_weight:  2.165899999999603e-06 teacher_forcing_ratio:  0.9999978340998208\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0015209896955639124\n",
      "KL_weight:  2.170899999999593e-06 teacher_forcing_ratio:  0.9999978290998204\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014501665718853474\n",
      "KL_weight:  2.1758999999995826e-06 teacher_forcing_ratio:  0.99999782409982\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0014272496337071061\n",
      "KL_weight:  2.1808999999995724e-06 teacher_forcing_ratio:  0.9999978190998196\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014622592134401202\n",
      "KL_weight:  2.185899999999562e-06 teacher_forcing_ratio:  0.9999978140998191\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0013591877650469542\n",
      "KL_weight:  2.190899999999552e-06 teacher_forcing_ratio:  0.9999978090998187\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001492721727117896\n",
      "KL_weight:  2.1958999999995418e-06 teacher_forcing_ratio:  0.9999978040998183\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0013847961090505123\n",
      "KL_weight:  2.2008999999995316e-06 teacher_forcing_ratio:  0.9999977990998179\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0013807921204715967\n",
      "KL_weight:  2.2058999999995213e-06 teacher_forcing_ratio:  0.9999977940998175\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001419251086190343\n",
      "KL_weight:  2.210899999999511e-06 teacher_forcing_ratio:  0.9999977890998171\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0014051334001123905\n",
      "KL_weight:  2.215899999999501e-06 teacher_forcing_ratio:  0.9999977840998167\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0013017383171245456\n",
      "KL_weight:  2.2208999999994907e-06 teacher_forcing_ratio:  0.9999977790998162\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014246185310184956\n",
      "KL_weight:  2.2258999999994805e-06 teacher_forcing_ratio:  0.9999977740998158\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 750 char-loss:  0.0013077708426862955\n",
      "KL_weight:  2.2308999999994703e-06 teacher_forcing_ratio:  0.9999977690998154\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonwacked \tScore:  0.07176\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abstering \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestowing \tScore:  0.07937\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   experdends \tScore:  0.50813\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stenswer \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splisting \tScore:  0.59695\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flardep \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functioninged \tScore:  0.61154\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearlinged \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0013017606688663363\n",
      "KL_weight:  2.237899999999456e-06 teacher_forcing_ratio:  0.9999977620998148\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0013746602926403284\n",
      "KL_weight:  2.2428999999994458e-06 teacher_forcing_ratio:  0.9999977570998144\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0012747850269079208\n",
      "KL_weight:  2.2478999999994356e-06 teacher_forcing_ratio:  0.999997752099814\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0012118913000449538\n",
      "KL_weight:  2.2528999999994254e-06 teacher_forcing_ratio:  0.9999977470998136\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001135759404860437\n",
      "KL_weight:  2.257899999999415e-06 teacher_forcing_ratio:  0.9999977420998132\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0013019484467804432\n",
      "KL_weight:  2.262899999999405e-06 teacher_forcing_ratio:  0.9999977370998128\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0011646547354757786\n",
      "KL_weight:  2.2678999999993947e-06 teacher_forcing_ratio:  0.9999977320998124\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0012594396248459816\n",
      "KL_weight:  2.2728999999993845e-06 teacher_forcing_ratio:  0.9999977270998119\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0012255820911377668\n",
      "KL_weight:  2.2778999999993743e-06 teacher_forcing_ratio:  0.9999977220998115\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0012812080094590783\n",
      "KL_weight:  2.282899999999364e-06 teacher_forcing_ratio:  0.9999977170998111\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0011668133083730936\n",
      "KL_weight:  2.287899999999354e-06 teacher_forcing_ratio:  0.9999977120998107\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0011215535923838615\n",
      "KL_weight:  2.2928999999993437e-06 teacher_forcing_ratio:  0.9999977070998103\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011336171301081777\n",
      "KL_weight:  2.2978999999993334e-06 teacher_forcing_ratio:  0.9999977020998099\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0011350237764418125\n",
      "KL_weight:  2.3028999999993232e-06 teacher_forcing_ratio:  0.9999976970998095\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0011162078008055687\n",
      "KL_weight:  2.307899999999313e-06 teacher_forcing_ratio:  0.999997692099809\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandonking \tScore:  0.57067\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abserting \tScore:  0.36889\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   beshiewing \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expreakned \tScore:  0.12422\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stensher \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splister \tScore:  0.32260\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   falcherate \tScore:  0.03156\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functionize \tScore:  0.69893\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearlinged \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0011810582363978028\n",
      "KL_weight:  2.3148999999992987e-06 teacher_forcing_ratio:  0.9999976850998085\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.001024839817546308\n",
      "KL_weight:  2.3198999999992885e-06 teacher_forcing_ratio:  0.999997680099808\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0010618834057822824\n",
      "KL_weight:  2.3248999999992783e-06 teacher_forcing_ratio:  0.9999976750998076\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001077559543773532\n",
      "KL_weight:  2.329899999999268e-06 teacher_forcing_ratio:  0.9999976700998072\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0010056488681584597\n",
      "KL_weight:  2.334899999999258e-06 teacher_forcing_ratio:  0.9999976650998068\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001017080619931221\n",
      "KL_weight:  2.3398999999992477e-06 teacher_forcing_ratio:  0.9999976600998064\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0009594677248969674\n",
      "KL_weight:  2.3448999999992374e-06 teacher_forcing_ratio:  0.999997655099806\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0010227295570075512\n",
      "KL_weight:  2.3498999999992272e-06 teacher_forcing_ratio:  0.9999976500998056\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.12354633212089539\n",
      "KL_weight:  2.354899999999217e-06 teacher_forcing_ratio:  0.9999976450998052\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.04573376476764679\n",
      "KL_weight:  2.359899999999207e-06 teacher_forcing_ratio:  0.9999976400998047\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.011625567451119423\n",
      "KL_weight:  2.3648999999991966e-06 teacher_forcing_ratio:  0.9999976350998043\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.00613061711192131\n",
      "KL_weight:  2.3698999999991864e-06 teacher_forcing_ratio:  0.9999976300998039\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.003169311210513115\n",
      "KL_weight:  2.374899999999176e-06 teacher_forcing_ratio:  0.9999976250998035\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0022963860537856817\n",
      "KL_weight:  2.379899999999166e-06 teacher_forcing_ratio:  0.9999976200998031\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0022621280513703823\n",
      "KL_weight:  2.3848999999991557e-06 teacher_forcing_ratio:  0.9999976150998027\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abonfastend \tScore:  0.07419\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abstering \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befighten \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpendied \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senthering \tScore:  0.10446\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitteing \tScore:  0.65804\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarmed \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heasligned \tScore:  0.11868\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002205201890319586\n",
      "KL_weight:  2.3918999999991415e-06 teacher_forcing_ratio:  0.9999976080998021\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002022107830271125\n",
      "KL_weight:  2.3968999999991312e-06 teacher_forcing_ratio:  0.9999976030998017\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0020294166170060635\n",
      "KL_weight:  2.401899999999121e-06 teacher_forcing_ratio:  0.9999975980998013\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0020266755018383265\n",
      "KL_weight:  2.406899999999111e-06 teacher_forcing_ratio:  0.9999975930998009\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0019799917936325073\n",
      "KL_weight:  2.4118999999991006e-06 teacher_forcing_ratio:  0.9999975880998004\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0019424445927143097\n",
      "KL_weight:  2.4168999999990904e-06 teacher_forcing_ratio:  0.9999975830998\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0019900365732610226\n",
      "KL_weight:  2.42189999999908e-06 teacher_forcing_ratio:  0.9999975780997996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016899318434298038\n",
      "KL_weight:  2.42689999999907e-06 teacher_forcing_ratio:  0.9999975730997992\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0017799495253711939\n",
      "KL_weight:  2.4318999999990598e-06 teacher_forcing_ratio:  0.9999975680997988\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001761539140716195\n",
      "KL_weight:  2.4368999999990495e-06 teacher_forcing_ratio:  0.9999975630997984\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0016705668531358242\n",
      "KL_weight:  2.4418999999990393e-06 teacher_forcing_ratio:  0.999997558099798\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001662212423980236\n",
      "KL_weight:  2.446899999999029e-06 teacher_forcing_ratio:  0.9999975530997975\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0016039307229220867\n",
      "KL_weight:  2.451899999999019e-06 teacher_forcing_ratio:  0.9999975480997971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0016373228281736374\n",
      "KL_weight:  2.4568999999990087e-06 teacher_forcing_ratio:  0.9999975430997967\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0015841490821912885\n",
      "KL_weight:  2.4618999999989985e-06 teacher_forcing_ratio:  0.9999975380997963\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonwained \tScore:  0.14178\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    bastering \tScore:  0.14669\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befighten \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpendied \tScore:  0.51697\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senthering \tScore:  0.10446\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarmed \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionized \tScore:  0.67042\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heasligned \tScore:  0.11868\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0016034907894209027\n",
      "KL_weight:  2.468899999998984e-06 teacher_forcing_ratio:  0.9999975310997957\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0015637774486094713\n",
      "KL_weight:  2.473899999998974e-06 teacher_forcing_ratio:  0.9999975260997953\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0015068528009578586\n",
      "KL_weight:  2.4788999999989638e-06 teacher_forcing_ratio:  0.9999975210997949\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014793227892369032\n",
      "KL_weight:  2.4838999999989535e-06 teacher_forcing_ratio:  0.9999975160997945\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0015095557319000363\n",
      "KL_weight:  2.4888999999989433e-06 teacher_forcing_ratio:  0.9999975110997941\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014721875777468085\n",
      "KL_weight:  2.493899999998933e-06 teacher_forcing_ratio:  0.9999975060997937\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0014193779788911343\n",
      "KL_weight:  2.498899999998923e-06 teacher_forcing_ratio:  0.9999975010997932\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0015384280122816563\n",
      "KL_weight:  2.5038999999989127e-06 teacher_forcing_ratio:  0.9999974960997928\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001392679987475276\n",
      "KL_weight:  2.5088999999989025e-06 teacher_forcing_ratio:  0.9999974910997924\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0014106187736615539\n",
      "KL_weight:  2.5138999999988923e-06 teacher_forcing_ratio:  0.999997486099792\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001273682457394898\n",
      "KL_weight:  2.518899999998882e-06 teacher_forcing_ratio:  0.9999974810997916\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0014926933217793703\n",
      "KL_weight:  2.523899999998872e-06 teacher_forcing_ratio:  0.9999974760997912\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0014628058997914195\n",
      "KL_weight:  2.5288999999988616e-06 teacher_forcing_ratio:  0.9999974710997908\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0013619837118312716\n",
      "KL_weight:  2.5338999999988514e-06 teacher_forcing_ratio:  0.9999974660997903\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0014207481872290373\n",
      "KL_weight:  2.538899999998841e-06 teacher_forcing_ratio:  0.9999974610997899\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abonfasted \tScore:  0.08034\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  basteringed \tScore:  0.11531\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befighten \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expendiems \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     senthore \tScore:  0.13747\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitteing \tScore:  0.65804\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flardeming \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionized \tScore:  0.67042\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heasligned \tScore:  0.11868\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.001257510157302022\n",
      "KL_weight:  2.545899999998827e-06 teacher_forcing_ratio:  0.9999974540997894\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0013666888698935509\n",
      "KL_weight:  2.5508999999988167e-06 teacher_forcing_ratio:  0.9999974490997889\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0012886231997981668\n",
      "KL_weight:  2.5558999999988065e-06 teacher_forcing_ratio:  0.9999974440997885\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011699226452037692\n",
      "KL_weight:  2.5608999999987963e-06 teacher_forcing_ratio:  0.9999974390997881\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0012684183893725276\n",
      "KL_weight:  2.565899999998786e-06 teacher_forcing_ratio:  0.9999974340997877\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0011394073953852057\n",
      "KL_weight:  2.570899999998776e-06 teacher_forcing_ratio:  0.9999974290997873\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001233239658176899\n",
      "KL_weight:  2.5758999999987656e-06 teacher_forcing_ratio:  0.9999974240997869\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0012006699107587337\n",
      "KL_weight:  2.5808999999987554e-06 teacher_forcing_ratio:  0.9999974190997865\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0012556794099509716\n",
      "KL_weight:  2.5858999999987452e-06 teacher_forcing_ratio:  0.999997414099786\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001196591416373849\n",
      "KL_weight:  2.590899999998735e-06 teacher_forcing_ratio:  0.9999974090997856\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015593054704368114\n",
      "KL_weight:  2.595899999998725e-06 teacher_forcing_ratio:  0.9999974040997852\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.03078482672572136\n",
      "KL_weight:  2.6008999999987146e-06 teacher_forcing_ratio:  0.9999973990997848\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.04118809849023819\n",
      "KL_weight:  2.6058999999987044e-06 teacher_forcing_ratio:  0.9999973940997844\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.01925649307668209\n",
      "KL_weight:  2.610899999998694e-06 teacher_forcing_ratio:  0.999997389099784\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.009229243732988834\n",
      "KL_weight:  2.615899999998684e-06 teacher_forcing_ratio:  0.9999973840997836\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandounced \tScore:  0.53483\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   babettered \tScore:  0.39281\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestigned \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexpendering \tScore:  0.41723\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentersing \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flareshed \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hexhainwing \tScore:  0.04412\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002939910627901554\n",
      "KL_weight:  2.6228999999986696e-06 teacher_forcing_ratio:  0.999997377099783\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0025825784541666508\n",
      "KL_weight:  2.6278999999986594e-06 teacher_forcing_ratio:  0.9999973720997826\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0033630868420004845\n",
      "KL_weight:  2.6328999999986492e-06 teacher_forcing_ratio:  0.9999973670997822\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0022460962645709515\n",
      "KL_weight:  2.637899999998639e-06 teacher_forcing_ratio:  0.9999973620997817\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0019086566753685474\n",
      "KL_weight:  2.642899999998629e-06 teacher_forcing_ratio:  0.9999973570997813\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001938983565196395\n",
      "KL_weight:  2.6478999999986186e-06 teacher_forcing_ratio:  0.9999973520997809\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0019090903224423528\n",
      "KL_weight:  2.6528999999986084e-06 teacher_forcing_ratio:  0.9999973470997805\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001887067104689777\n",
      "KL_weight:  2.657899999998598e-06 teacher_forcing_ratio:  0.9999973420997801\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0018866603495553136\n",
      "KL_weight:  2.662899999998588e-06 teacher_forcing_ratio:  0.9999973370997797\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0018135459395125508\n",
      "KL_weight:  2.6678999999985777e-06 teacher_forcing_ratio:  0.9999973320997793\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0016888619866222143\n",
      "KL_weight:  2.6728999999985675e-06 teacher_forcing_ratio:  0.9999973270997788\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0017679722514003515\n",
      "KL_weight:  2.6778999999985573e-06 teacher_forcing_ratio:  0.9999973220997784\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0016976648475974798\n",
      "KL_weight:  2.682899999998547e-06 teacher_forcing_ratio:  0.999997317099778\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0017852563178166747\n",
      "KL_weight:  2.687899999998537e-06 teacher_forcing_ratio:  0.9999973120997776\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0017029583686962724\n",
      "KL_weight:  2.6928999999985267e-06 teacher_forcing_ratio:  0.9999973070997772\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandornked \tScore:  0.53483\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     bastered \tScore:  0.03928\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestigned \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexwending \tScore:  0.14772\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      senters \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarepted \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: hexhainsaling \tScore:  0.04913\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015860887942835689\n",
      "KL_weight:  2.6998999999985124e-06 teacher_forcing_ratio:  0.9999973000997766\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100 char-loss:  0.0015696799382567406\n",
      "KL_weight:  2.704899999998502e-06 teacher_forcing_ratio:  0.9999972950997762\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0016158329090103507\n",
      "KL_weight:  2.709899999998492e-06 teacher_forcing_ratio:  0.9999972900997758\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014031775062903762\n",
      "KL_weight:  2.7148999999984817e-06 teacher_forcing_ratio:  0.9999972850997754\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0014881618553772569\n",
      "KL_weight:  2.7198999999984715e-06 teacher_forcing_ratio:  0.999997280099775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0016155631747096777\n",
      "KL_weight:  2.7248999999984613e-06 teacher_forcing_ratio:  0.9999972750997745\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0015425232704728842\n",
      "KL_weight:  2.729899999998451e-06 teacher_forcing_ratio:  0.9999972700997741\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001412833807989955\n",
      "KL_weight:  2.734899999998441e-06 teacher_forcing_ratio:  0.9999972650997737\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001479871105402708\n",
      "KL_weight:  2.7398999999984307e-06 teacher_forcing_ratio:  0.9999972600997733\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0013916939496994019\n",
      "KL_weight:  2.7448999999984205e-06 teacher_forcing_ratio:  0.9999972550997729\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0014628133503720164\n",
      "KL_weight:  2.7498999999984103e-06 teacher_forcing_ratio:  0.9999972500997725\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0014127183239907026\n",
      "KL_weight:  2.7548999999984e-06 teacher_forcing_ratio:  0.9999972450997721\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0013941481010988355\n",
      "KL_weight:  2.75989999999839e-06 teacher_forcing_ratio:  0.9999972400997716\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014297562884166837\n",
      "KL_weight:  2.7648999999983796e-06 teacher_forcing_ratio:  0.9999972350997712\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0013841161271557212\n",
      "KL_weight:  2.7698999999983694e-06 teacher_forcing_ratio:  0.9999972300997708\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandornked \tScore:  0.53483\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     bastered \tScore:  0.03928\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestigned \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexwendies \tScore:  0.15353\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sentores \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitring \tScore:  0.59695\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    faltering \tScore:  0.03586\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hearkingled \tScore:  0.10025\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0013170064194127917\n",
      "KL_weight:  2.776899999998355e-06 teacher_forcing_ratio:  0.9999972230997702\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00146600476000458\n",
      "KL_weight:  2.781899999998345e-06 teacher_forcing_ratio:  0.9999972180997698\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0015133965061977506\n",
      "KL_weight:  2.7868999999983347e-06 teacher_forcing_ratio:  0.9999972130997694\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0013431432889774442\n",
      "KL_weight:  2.7918999999983245e-06 teacher_forcing_ratio:  0.999997208099769\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0013506141258403659\n",
      "KL_weight:  2.7968999999983143e-06 teacher_forcing_ratio:  0.9999972030997686\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0012771474430337548\n",
      "KL_weight:  2.801899999998304e-06 teacher_forcing_ratio:  0.9999971980997682\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0012636149767786264\n",
      "KL_weight:  2.806899999998294e-06 teacher_forcing_ratio:  0.9999971930997678\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0013118484057486057\n",
      "KL_weight:  2.8118999999982836e-06 teacher_forcing_ratio:  0.9999971880997673\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001226344145834446\n",
      "KL_weight:  2.8168999999982734e-06 teacher_forcing_ratio:  0.9999971830997669\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001251622335985303\n",
      "KL_weight:  2.821899999998263e-06 teacher_forcing_ratio:  0.9999971780997665\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0012958822771906853\n",
      "KL_weight:  2.826899999998253e-06 teacher_forcing_ratio:  0.9999971730997661\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0012069829972460866\n",
      "KL_weight:  2.8318999999982428e-06 teacher_forcing_ratio:  0.9999971680997657\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011896288488060236\n",
      "KL_weight:  2.8368999999982326e-06 teacher_forcing_ratio:  0.9999971630997653\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0012538363225758076\n",
      "KL_weight:  2.8418999999982223e-06 teacher_forcing_ratio:  0.9999971580997649\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001258792239241302\n",
      "KL_weight:  2.846899999998212e-06 teacher_forcing_ratio:  0.9999971530997644\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandornked \tScore:  0.53483\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  bastereding \tScore:  0.11531\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestigned \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pextenders \tScore:  0.15353\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      senters \tScore:  0.17567\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splitred \tScore:  0.45623\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarepted \tScore:  0.44632\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearlinged \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0011492556659504771\n",
      "KL_weight:  2.853899999998198e-06 teacher_forcing_ratio:  0.9999971460997639\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0011965769808739424\n",
      "KL_weight:  2.8588999999981876e-06 teacher_forcing_ratio:  0.9999971410997635\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 150 char-loss:  0.0011074242647737265\n",
      "KL_weight:  2.8638999999981774e-06 teacher_forcing_ratio:  0.999997136099763\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011343567166477442\n",
      "KL_weight:  2.868899999998167e-06 teacher_forcing_ratio:  0.9999971310997626\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001201409613713622\n",
      "KL_weight:  2.873899999998157e-06 teacher_forcing_ratio:  0.9999971260997622\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0010756446281448007\n",
      "KL_weight:  2.8788999999981468e-06 teacher_forcing_ratio:  0.9999971210997618\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0010436656884849072\n",
      "KL_weight:  2.8838999999981366e-06 teacher_forcing_ratio:  0.9999971160997614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0010924647795036435\n",
      "KL_weight:  2.8888999999981264e-06 teacher_forcing_ratio:  0.999997111099761\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002437317045405507\n",
      "KL_weight:  2.893899999998116e-06 teacher_forcing_ratio:  0.9999971060997606\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.07711630314588547\n",
      "KL_weight:  2.898899999998106e-06 teacher_forcing_ratio:  0.9999971010997601\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.04437995329499245\n",
      "KL_weight:  2.9038999999980957e-06 teacher_forcing_ratio:  0.9999970960997597\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.010467931628227234\n",
      "KL_weight:  2.9088999999980855e-06 teacher_forcing_ratio:  0.9999970910997593\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.007711304817348719\n",
      "KL_weight:  2.9138999999980753e-06 teacher_forcing_ratio:  0.9999970860997589\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002842554822564125\n",
      "KL_weight:  2.918899999998065e-06 teacher_forcing_ratio:  0.9999970810997585\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0026240749284625053\n",
      "KL_weight:  2.923899999998055e-06 teacher_forcing_ratio:  0.9999970760997581\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abandonker \tScore:  0.66063\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    bacterbed \tScore:  0.06031\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    beforming \tScore:  0.07583\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expendipens \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snotersks \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flarkent \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   bhaltening \tScore:  0.05308\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0023319614119827747\n",
      "KL_weight:  2.9308999999980406e-06 teacher_forcing_ratio:  0.9999970690997575\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002295956015586853\n",
      "KL_weight:  2.9358999999980304e-06 teacher_forcing_ratio:  0.9999970640997571\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0021816587541252375\n",
      "KL_weight:  2.94089999999802e-06 teacher_forcing_ratio:  0.9999970590997567\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002015926642343402\n",
      "KL_weight:  2.94589999999801e-06 teacher_forcing_ratio:  0.9999970540997563\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0019569883588701487\n",
      "KL_weight:  2.9508999999979997e-06 teacher_forcing_ratio:  0.9999970490997558\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0019978659693151712\n",
      "KL_weight:  2.9558999999979895e-06 teacher_forcing_ratio:  0.9999970440997554\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002045257482677698\n",
      "KL_weight:  2.9608999999979793e-06 teacher_forcing_ratio:  0.999997039099755\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0019081642385572195\n",
      "KL_weight:  2.965899999997969e-06 teacher_forcing_ratio:  0.9999970340997546\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0017732316628098488\n",
      "KL_weight:  2.970899999997959e-06 teacher_forcing_ratio:  0.9999970290997542\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0018184958025813103\n",
      "KL_weight:  2.9758999999979487e-06 teacher_forcing_ratio:  0.9999970240997538\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0018090796656906605\n",
      "KL_weight:  2.9808999999979384e-06 teacher_forcing_ratio:  0.9999970190997534\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0018200927879661322\n",
      "KL_weight:  2.9858999999979282e-06 teacher_forcing_ratio:  0.999997014099753\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0017196969129145145\n",
      "KL_weight:  2.990899999997918e-06 teacher_forcing_ratio:  0.9999970090997525\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001754677388817072\n",
      "KL_weight:  2.995899999997908e-06 teacher_forcing_ratio:  0.9999970040997521\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0018201363272964954\n",
      "KL_weight:  3.0008999999978976e-06 teacher_forcing_ratio:  0.9999969990997517\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abastondening \tScore:  0.11686\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   basterfied \tScore:  0.03156\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestoringe \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expernoted \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentrouns \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flartence \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: bhalterizing \tScore:  0.04284\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0016694568330422044\n",
      "KL_weight:  3.0078999999978833e-06 teacher_forcing_ratio:  0.9999969920997511\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016488019609823823\n",
      "KL_weight:  3.012899999997873e-06 teacher_forcing_ratio:  0.9999969870997507\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.001587487873621285\n",
      "KL_weight:  3.017899999997863e-06 teacher_forcing_ratio:  0.9999969820997503\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.0017323788488283753\n",
      "KL_weight:  3.0228999999978527e-06 teacher_forcing_ratio:  0.9999969770997499\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0018098715227097273\n",
      "KL_weight:  3.0278999999978424e-06 teacher_forcing_ratio:  0.9999969720997495\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014808325795456767\n",
      "KL_weight:  3.0328999999978322e-06 teacher_forcing_ratio:  0.9999969670997491\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0015338637167587876\n",
      "KL_weight:  3.037899999997822e-06 teacher_forcing_ratio:  0.9999969620997486\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0014386860420927405\n",
      "KL_weight:  3.042899999997812e-06 teacher_forcing_ratio:  0.9999969570997482\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001428925315849483\n",
      "KL_weight:  3.0478999999978016e-06 teacher_forcing_ratio:  0.9999969520997478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0014430253067985177\n",
      "KL_weight:  3.0528999999977914e-06 teacher_forcing_ratio:  0.9999969470997474\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0016048811376094818\n",
      "KL_weight:  3.057899999997781e-06 teacher_forcing_ratio:  0.999996942099747\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.00162895570974797\n",
      "KL_weight:  3.062899999997771e-06 teacher_forcing_ratio:  0.9999969370997466\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0015136126894503832\n",
      "KL_weight:  3.0678999999977608e-06 teacher_forcing_ratio:  0.9999969320997462\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014871073653921485\n",
      "KL_weight:  3.0728999999977505e-06 teacher_forcing_ratio:  0.9999969270997457\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0013427621452137828\n",
      "KL_weight:  3.0778999999977403e-06 teacher_forcing_ratio:  0.9999969220997453\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abastondening \tScore:  0.11686\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   bafterming \tScore:  0.12910\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestoringe \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expernodes \tScore:  0.30214\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentroses \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splitchering \tScore:  0.42401\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarterize \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   bharlinges \tScore:  0.03156\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0013558146310970187\n",
      "KL_weight:  3.084899999997726e-06 teacher_forcing_ratio:  0.9999969150997448\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0012609121622517705\n",
      "KL_weight:  3.089899999997716e-06 teacher_forcing_ratio:  0.9999969100997443\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0014359330525621772\n",
      "KL_weight:  3.0948999999977056e-06 teacher_forcing_ratio:  0.9999969050997439\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0013323400635272264\n",
      "KL_weight:  3.0998999999976954e-06 teacher_forcing_ratio:  0.9999969000997435\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0012938339496031404\n",
      "KL_weight:  3.104899999997685e-06 teacher_forcing_ratio:  0.9999968950997431\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001243079430423677\n",
      "KL_weight:  3.109899999997675e-06 teacher_forcing_ratio:  0.9999968900997427\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001350122387520969\n",
      "KL_weight:  3.1148999999976648e-06 teacher_forcing_ratio:  0.9999968850997423\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0013925554230809212\n",
      "KL_weight:  3.1198999999976545e-06 teacher_forcing_ratio:  0.9999968800997419\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0012785191647708416\n",
      "KL_weight:  3.1248999999976443e-06 teacher_forcing_ratio:  0.9999968750997414\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0013657480012625456\n",
      "KL_weight:  3.129899999997634e-06 teacher_forcing_ratio:  0.999996870099741\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00139153643976897\n",
      "KL_weight:  3.134899999997624e-06 teacher_forcing_ratio:  0.9999968650997406\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0015079982113093138\n",
      "KL_weight:  3.1398999999976137e-06 teacher_forcing_ratio:  0.9999968600997402\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0011451630853116512\n",
      "KL_weight:  3.1448999999976035e-06 teacher_forcing_ratio:  0.9999968550997398\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001260649412870407\n",
      "KL_weight:  3.1498999999975933e-06 teacher_forcing_ratio:  0.9999968500997394\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0012189841363579035\n",
      "KL_weight:  3.154899999997583e-06 teacher_forcing_ratio:  0.999996845099739\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   bansoraked \tScore:  0.14287\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   basterfing \tScore:  0.12910\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestoringe \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expertands \tScore:  0.37992\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stestone \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splittering \tScore:  0.58773\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarteash \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  bhartencish \tScore:  0.02666\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0012881627772003412\n",
      "KL_weight:  3.1618999999975688e-06 teacher_forcing_ratio:  0.9999968380997384\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0012448811903595924\n",
      "KL_weight:  3.1668999999975585e-06 teacher_forcing_ratio:  0.999996833099738\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.001246187137439847\n",
      "KL_weight:  3.1718999999975483e-06 teacher_forcing_ratio:  0.9999968280997376\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0011451792670413852\n",
      "KL_weight:  3.176899999997538e-06 teacher_forcing_ratio:  0.9999968230997371\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 250 char-loss:  0.0011239588493481278\n",
      "KL_weight:  3.181899999997528e-06 teacher_forcing_ratio:  0.9999968180997367\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0011531285708770156\n",
      "KL_weight:  3.1868999999975177e-06 teacher_forcing_ratio:  0.9999968130997363\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0013499517226591706\n",
      "KL_weight:  3.1918999999975075e-06 teacher_forcing_ratio:  0.9999968080997359\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0012151533737778664\n",
      "KL_weight:  3.1968999999974973e-06 teacher_forcing_ratio:  0.9999968030997355\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0010985068511217833\n",
      "KL_weight:  3.201899999997487e-06 teacher_forcing_ratio:  0.9999967980997351\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0010917489416897297\n",
      "KL_weight:  3.206899999997477e-06 teacher_forcing_ratio:  0.9999967930997347\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001014977809973061\n",
      "KL_weight:  3.2118999999974666e-06 teacher_forcing_ratio:  0.9999967880997342\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001135889790020883\n",
      "KL_weight:  3.2168999999974564e-06 teacher_forcing_ratio:  0.9999967830997338\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0010680004488676786\n",
      "KL_weight:  3.2218999999974462e-06 teacher_forcing_ratio:  0.9999967780997334\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0015603177016600966\n",
      "KL_weight:  3.226899999997436e-06 teacher_forcing_ratio:  0.999996773099733\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.09061207622289658\n",
      "KL_weight:  3.231899999997426e-06 teacher_forcing_ratio:  0.9999967680997326\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abaffondsaring \tScore:  0.10390\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    betabling \tScore:  0.21935\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestiganed \tScore:  0.05874\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experskated \tScore:  0.25965\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentorbes \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splittraching \tScore:  0.48443\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    faltreals \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fortackniduing \tScore:  0.02402\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fountifforing \tScore:  0.05344\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: bhailesaginated \tScore:  0.01977\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.025828387588262558\n",
      "KL_weight:  3.2388999999974115e-06 teacher_forcing_ratio:  0.999996761099732\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00569318700581789\n",
      "KL_weight:  3.2438999999974013e-06 teacher_forcing_ratio:  0.9999967560997316\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.003847857005894184\n",
      "KL_weight:  3.248899999997391e-06 teacher_forcing_ratio:  0.9999967510997312\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.003096131607890129\n",
      "KL_weight:  3.253899999997381e-06 teacher_forcing_ratio:  0.9999967460997308\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0024275369942188263\n",
      "KL_weight:  3.2588999999973706e-06 teacher_forcing_ratio:  0.9999967410997304\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023950855247676373\n",
      "KL_weight:  3.2638999999973604e-06 teacher_forcing_ratio:  0.9999967360997299\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002231260295957327\n",
      "KL_weight:  3.2688999999973502e-06 teacher_forcing_ratio:  0.9999967310997295\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0021324236877262592\n",
      "KL_weight:  3.27389999999734e-06 teacher_forcing_ratio:  0.9999967260997291\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0020257821306586266\n",
      "KL_weight:  3.27889999999733e-06 teacher_forcing_ratio:  0.9999967210997287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002013921272009611\n",
      "KL_weight:  3.2838999999973196e-06 teacher_forcing_ratio:  0.9999967160997283\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001914589200168848\n",
      "KL_weight:  3.2888999999973094e-06 teacher_forcing_ratio:  0.9999967110997279\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0018025210592895746\n",
      "KL_weight:  3.293899999997299e-06 teacher_forcing_ratio:  0.9999967060997275\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.001735159894451499\n",
      "KL_weight:  3.298899999997289e-06 teacher_forcing_ratio:  0.999996701099727\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0019820421002805233\n",
      "KL_weight:  3.3038999999972787e-06 teacher_forcing_ratio:  0.9999966960997266\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001857071416452527\n",
      "KL_weight:  3.3088999999972685e-06 teacher_forcing_ratio:  0.9999966910997262\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abanfornday \tScore:  0.28998\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    bastering \tScore:  0.14669\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   besfigrent \tScore:  0.05874\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expenders \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   swestounes \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splistring \tScore:  0.39281\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarbeade \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fincounting \tScore:  0.07419\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fincountingling \tScore:  0.05203\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: behailenging \tScore:  0.02409\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0019112613517791033\n",
      "KL_weight:  3.3158999999972542e-06 teacher_forcing_ratio:  0.9999966840997256\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0018255648901686072\n",
      "KL_weight:  3.320899999997244e-06 teacher_forcing_ratio:  0.9999966790997252\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017096538795158267\n",
      "KL_weight:  3.325899999997234e-06 teacher_forcing_ratio:  0.9999966740997248\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0017469713930040598\n",
      "KL_weight:  3.3308999999972236e-06 teacher_forcing_ratio:  0.9999966690997244\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0015328230801969767\n",
      "KL_weight:  3.3358999999972134e-06 teacher_forcing_ratio:  0.999996664099724\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 300 char-loss:  0.0017613038653507829\n",
      "KL_weight:  3.340899999997203e-06 teacher_forcing_ratio:  0.9999966590997236\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0016303407028317451\n",
      "KL_weight:  3.345899999997193e-06 teacher_forcing_ratio:  0.9999966540997232\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0017617986304685473\n",
      "KL_weight:  3.3508999999971827e-06 teacher_forcing_ratio:  0.9999966490997227\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0015828557079657912\n",
      "KL_weight:  3.3558999999971725e-06 teacher_forcing_ratio:  0.9999966440997223\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001648981822654605\n",
      "KL_weight:  3.3608999999971623e-06 teacher_forcing_ratio:  0.9999966390997219\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015296409837901592\n",
      "KL_weight:  3.365899999997152e-06 teacher_forcing_ratio:  0.9999966340997215\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0015552975237369537\n",
      "KL_weight:  3.370899999997142e-06 teacher_forcing_ratio:  0.9999966290997211\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0016559739597141743\n",
      "KL_weight:  3.3758999999971317e-06 teacher_forcing_ratio:  0.9999966240997207\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001491083763539791\n",
      "KL_weight:  3.3808999999971215e-06 teacher_forcing_ratio:  0.9999966190997203\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0015280377119779587\n",
      "KL_weight:  3.3858999999971113e-06 teacher_forcing_ratio:  0.9999966140997198\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abanforning \tScore:  0.25965\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    bastering \tScore:  0.14669\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   besfighten \tScore:  0.05874\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expenderims \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    swestones \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splistering \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarbered \tScore:  0.33913\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fincountingling \tScore:  0.05203\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fincountingling \tScore:  0.05203\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   bhealizeng \tScore:  0.26269\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015535573475062847\n",
      "KL_weight:  3.392899999997097e-06 teacher_forcing_ratio:  0.9999966070997193\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0015790032921358943\n",
      "KL_weight:  3.3978999999970867e-06 teacher_forcing_ratio:  0.9999966020997189\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0014259649906307459\n",
      "KL_weight:  3.4028999999970765e-06 teacher_forcing_ratio:  0.9999965970997184\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014330579433590174\n",
      "KL_weight:  3.4078999999970663e-06 teacher_forcing_ratio:  0.999996592099718\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001504845917224884\n",
      "KL_weight:  3.412899999997056e-06 teacher_forcing_ratio:  0.9999965870997176\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0013890141854062676\n",
      "KL_weight:  3.417899999997046e-06 teacher_forcing_ratio:  0.9999965820997172\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.010241232812404633\n",
      "KL_weight:  3.4228999999970357e-06 teacher_forcing_ratio:  0.9999965770997168\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.007245304528623819\n",
      "KL_weight:  3.4278999999970255e-06 teacher_forcing_ratio:  0.9999965720997164\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.011672411113977432\n",
      "KL_weight:  3.4328999999970153e-06 teacher_forcing_ratio:  0.999996567099716\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.008342152461409569\n",
      "KL_weight:  3.437899999997005e-06 teacher_forcing_ratio:  0.9999965620997155\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.004470889922231436\n",
      "KL_weight:  3.442899999996995e-06 teacher_forcing_ratio:  0.9999965570997151\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0037076876033097506\n",
      "KL_weight:  3.4478999999969846e-06 teacher_forcing_ratio:  0.9999965520997147\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0023397300392389297\n",
      "KL_weight:  3.4528999999969744e-06 teacher_forcing_ratio:  0.9999965470997143\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.00224321405403316\n",
      "KL_weight:  3.457899999996964e-06 teacher_forcing_ratio:  0.9999965420997139\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002244524657726288\n",
      "KL_weight:  3.462899999996954e-06 teacher_forcing_ratio:  0.9999965370997135\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abswandoning \tScore:  0.36463\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  bastereting \tScore:  0.29982\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begrishen \tScore:  0.14114\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  weppedinted \tScore:  0.05013\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentrouns \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarbed \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fenticulating \tScore:  0.04494\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: hearlignated \tScore:  0.09059\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0019851953256875277\n",
      "KL_weight:  3.4698999999969397e-06 teacher_forcing_ratio:  0.9999965300997129\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0019628102891147137\n",
      "KL_weight:  3.4748999999969295e-06 teacher_forcing_ratio:  0.9999965250997125\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0018892157822847366\n",
      "KL_weight:  3.4798999999969193e-06 teacher_forcing_ratio:  0.9999965200997121\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0018378692911937833\n",
      "KL_weight:  3.484899999996909e-06 teacher_forcing_ratio:  0.9999965150997117\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0017952037742361426\n",
      "KL_weight:  3.489899999996899e-06 teacher_forcing_ratio:  0.9999965100997112\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001797555247321725\n",
      "KL_weight:  3.4948999999968886e-06 teacher_forcing_ratio:  0.9999965050997108\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.0017930458998307586\n",
      "KL_weight:  3.4998999999968784e-06 teacher_forcing_ratio:  0.9999965000997104\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0017793490551412106\n",
      "KL_weight:  3.504899999996868e-06 teacher_forcing_ratio:  0.99999649509971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0018222706858068705\n",
      "KL_weight:  3.509899999996858e-06 teacher_forcing_ratio:  0.9999964900997096\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0016747614135965705\n",
      "KL_weight:  3.5148999999968478e-06 teacher_forcing_ratio:  0.9999964850997092\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015698483912274241\n",
      "KL_weight:  3.5198999999968376e-06 teacher_forcing_ratio:  0.9999964800997088\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0016636851942166686\n",
      "KL_weight:  3.5248999999968274e-06 teacher_forcing_ratio:  0.9999964750997083\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0014727304223924875\n",
      "KL_weight:  3.529899999996817e-06 teacher_forcing_ratio:  0.9999964700997079\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0015733838081359863\n",
      "KL_weight:  3.534899999996807e-06 teacher_forcing_ratio:  0.9999964650997075\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0015733897453173995\n",
      "KL_weight:  3.5398999999967967e-06 teacher_forcing_ratio:  0.9999964600997071\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonwained \tScore:  0.14178\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    babstered \tScore:  0.06031\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  begrinksing \tScore:  0.12278\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  weppaderisk \tScore:  0.02819\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentrouns \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splitching \tScore:  0.52538\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flarbed \tScore:  0.43472\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fenticulating \tScore:  0.04494\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: hearlignated \tScore:  0.09059\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015383160207420588\n",
      "KL_weight:  3.5468999999967824e-06 teacher_forcing_ratio:  0.9999964530997065\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0014640494482591748\n",
      "KL_weight:  3.551899999996772e-06 teacher_forcing_ratio:  0.9999964480997061\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0014960186090320349\n",
      "KL_weight:  3.556899999996762e-06 teacher_forcing_ratio:  0.9999964430997057\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014630721416324377\n",
      "KL_weight:  3.5618999999967518e-06 teacher_forcing_ratio:  0.9999964380997053\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0015825704904273152\n",
      "KL_weight:  3.5668999999967416e-06 teacher_forcing_ratio:  0.9999964330997049\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014314439613372087\n",
      "KL_weight:  3.5718999999967314e-06 teacher_forcing_ratio:  0.9999964280997045\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001529764849692583\n",
      "KL_weight:  3.576899999996721e-06 teacher_forcing_ratio:  0.999996423099704\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0014179523568600416\n",
      "KL_weight:  3.581899999996711e-06 teacher_forcing_ratio:  0.9999964180997036\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0014181535225361586\n",
      "KL_weight:  3.5868999999967007e-06 teacher_forcing_ratio:  0.9999964130997032\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001411200501024723\n",
      "KL_weight:  3.5918999999966905e-06 teacher_forcing_ratio:  0.9999964080997028\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0013242409331724048\n",
      "KL_weight:  3.5968999999966803e-06 teacher_forcing_ratio:  0.9999964030997024\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001411318895407021\n",
      "KL_weight:  3.60189999999667e-06 teacher_forcing_ratio:  0.999996398099702\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0013164898846298456\n",
      "KL_weight:  3.60689999999666e-06 teacher_forcing_ratio:  0.9999963930997016\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.00146028574090451\n",
      "KL_weight:  3.6118999999966497e-06 teacher_forcing_ratio:  0.9999963880997012\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.006418503355234861\n",
      "KL_weight:  3.6168999999966394e-06 teacher_forcing_ratio:  0.9999963830997007\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abswanconing \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  batestering \tScore:  0.11922\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  befigmening \tScore:  0.05961\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderts \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     spentser \tScore:  0.08307\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splitring \tScore:  0.59695\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    blarpeash \tScore:  0.12753\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionaling \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funtifoncien \tScore:  0.13951\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hearleging \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.04685785248875618\n",
      "KL_weight:  3.623899999996625e-06 teacher_forcing_ratio:  0.9999963760997002\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.014479685574769974\n",
      "KL_weight:  3.628899999996615e-06 teacher_forcing_ratio:  0.9999963710996997\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.004456748720258474\n",
      "KL_weight:  3.6338999999966047e-06 teacher_forcing_ratio:  0.9999963660996993\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0033711609430611134\n",
      "KL_weight:  3.6388999999965945e-06 teacher_forcing_ratio:  0.9999963610996989\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002567213261500001\n",
      "KL_weight:  3.6438999999965843e-06 teacher_forcing_ratio:  0.9999963560996985\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0024756903294473886\n",
      "KL_weight:  3.648899999996574e-06 teacher_forcing_ratio:  0.9999963510996981\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002385220490396023\n",
      "KL_weight:  3.653899999996564e-06 teacher_forcing_ratio:  0.9999963460996977\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 400 char-loss:  0.002055432414636016\n",
      "KL_weight:  3.6588999999965537e-06 teacher_forcing_ratio:  0.9999963410996973\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002113461261615157\n",
      "KL_weight:  3.6638999999965434e-06 teacher_forcing_ratio:  0.9999963360996968\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0021242231596261263\n",
      "KL_weight:  3.6688999999965332e-06 teacher_forcing_ratio:  0.9999963310996964\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0021244422532618046\n",
      "KL_weight:  3.673899999996523e-06 teacher_forcing_ratio:  0.999996326099696\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0020619090646505356\n",
      "KL_weight:  3.678899999996513e-06 teacher_forcing_ratio:  0.9999963210996956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0019800132140517235\n",
      "KL_weight:  3.6838999999965026e-06 teacher_forcing_ratio:  0.9999963160996952\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0019403200130909681\n",
      "KL_weight:  3.6888999999964924e-06 teacher_forcing_ratio:  0.9999963110996948\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0017548144096508622\n",
      "KL_weight:  3.693899999996482e-06 teacher_forcing_ratio:  0.9999963060996944\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abstrangoned \tScore:  0.28646\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abstering \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestigning \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpenders \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentreates \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splitrating \tScore:  0.58773\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarpeash \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functiongating \tScore:  0.51424\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionishing \tScore:  0.51424\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: hehalignsher \tScore:  0.05386\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0017280993051826954\n",
      "KL_weight:  3.700899999996468e-06 teacher_forcing_ratio:  0.9999962990996938\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016612382605671883\n",
      "KL_weight:  3.7058999999964577e-06 teacher_forcing_ratio:  0.9999962940996934\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0016776127740740776\n",
      "KL_weight:  3.7108999999964475e-06 teacher_forcing_ratio:  0.999996289099693\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001722441054880619\n",
      "KL_weight:  3.7158999999964372e-06 teacher_forcing_ratio:  0.9999962840996925\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0016306557226926088\n",
      "KL_weight:  3.720899999996427e-06 teacher_forcing_ratio:  0.9999962790996921\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001641048351302743\n",
      "KL_weight:  3.725899999996417e-06 teacher_forcing_ratio:  0.9999962740996917\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0016967968549579382\n",
      "KL_weight:  3.7308999999964066e-06 teacher_forcing_ratio:  0.9999962690996913\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016609219601377845\n",
      "KL_weight:  3.7358999999963964e-06 teacher_forcing_ratio:  0.9999962640996909\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001470218296162784\n",
      "KL_weight:  3.740899999996386e-06 teacher_forcing_ratio:  0.9999962590996905\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0014875520719215274\n",
      "KL_weight:  3.745899999996376e-06 teacher_forcing_ratio:  0.9999962540996901\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0014875029446557164\n",
      "KL_weight:  3.7508999999963658e-06 teacher_forcing_ratio:  0.9999962490996896\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0014744444051757455\n",
      "KL_weight:  3.7558999999963555e-06 teacher_forcing_ratio:  0.9999962440996892\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.001448973547667265\n",
      "KL_weight:  3.7608999999963453e-06 teacher_forcing_ratio:  0.9999962390996888\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0014515649527311325\n",
      "KL_weight:  3.765899999996335e-06 teacher_forcing_ratio:  0.9999962340996884\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0014275615103542805\n",
      "KL_weight:  3.770899999996325e-06 teacher_forcing_ratio:  0.999996229099688\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   absornaped \tScore:  0.07260\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abstering \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestigning \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    wexpersed \tScore:  0.33032\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentrates \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splitrating \tScore:  0.58773\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarpered \tScore:  0.33913\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: festicupaning \tScore:  0.04494\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionging \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: healseraging \tScore:  0.31702\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001466569839976728\n",
      "KL_weight:  3.7778999999963106e-06 teacher_forcing_ratio:  0.9999962220996874\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0015867139445617795\n",
      "KL_weight:  3.7828999999963004e-06 teacher_forcing_ratio:  0.999996217099687\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0016554202884435654\n",
      "KL_weight:  3.78789999999629e-06 teacher_forcing_ratio:  0.9999962120996866\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014744707150384784\n",
      "KL_weight:  3.79289999999628e-06 teacher_forcing_ratio:  0.9999962070996862\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.00156032619997859\n",
      "KL_weight:  3.7978999999962698e-06 teacher_forcing_ratio:  0.9999962020996858\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0014238859293982387\n",
      "KL_weight:  3.8028999999962595e-06 teacher_forcing_ratio:  0.9999961970996853\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0014426499838009477\n",
      "KL_weight:  3.8078999999962493e-06 teacher_forcing_ratio:  0.9999961920996849\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016242277342826128\n",
      "KL_weight:  3.812899999996239e-06 teacher_forcing_ratio:  0.9999961870996845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 450 char-loss:  0.0013479456538334489\n",
      "KL_weight:  3.817899999996243e-06 teacher_forcing_ratio:  0.9999961820996841\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.030094319954514503\n",
      "KL_weight:  3.822899999996254e-06 teacher_forcing_ratio:  0.9999961770996837\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.01968386583030224\n",
      "KL_weight:  3.827899999996265e-06 teacher_forcing_ratio:  0.9999961720996833\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.008286833763122559\n",
      "KL_weight:  3.832899999996276e-06 teacher_forcing_ratio:  0.9999961670996829\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.004055303055793047\n",
      "KL_weight:  3.837899999996287e-06 teacher_forcing_ratio:  0.9999961620996825\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.003026237478479743\n",
      "KL_weight:  3.842899999996298e-06 teacher_forcing_ratio:  0.999996157099682\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002898694481700659\n",
      "KL_weight:  3.847899999996309e-06 teacher_forcing_ratio:  0.9999961520996816\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   absontared \tScore:  0.08034\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abstereting \tScore:  0.31702\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    bestrigne \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expenderst \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   mistenares \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  mispretling \tScore:  0.14178\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  frealtraped \tScore:  0.05013\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fincounterating \tScore:  0.05203\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fenctiparing \tScore:  0.24384\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: hesharlieving \tScore:  0.04132\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0023599222768098116\n",
      "KL_weight:  3.854899999996324e-06 teacher_forcing_ratio:  0.999996145099681\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0023879888467490673\n",
      "KL_weight:  3.859899999996335e-06 teacher_forcing_ratio:  0.9999961400996806\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002543915994465351\n",
      "KL_weight:  3.864899999996346e-06 teacher_forcing_ratio:  0.9999961350996802\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.00235420698300004\n",
      "KL_weight:  3.869899999996357e-06 teacher_forcing_ratio:  0.9999961300996798\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0022709807381033897\n",
      "KL_weight:  3.874899999996368e-06 teacher_forcing_ratio:  0.9999961250996794\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002189295133575797\n",
      "KL_weight:  3.879899999996379e-06 teacher_forcing_ratio:  0.999996120099679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0021276611369103193\n",
      "KL_weight:  3.88489999999639e-06 teacher_forcing_ratio:  0.9999961150996786\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0020694092381745577\n",
      "KL_weight:  3.889899999996401e-06 teacher_forcing_ratio:  0.9999961100996781\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002013665856793523\n",
      "KL_weight:  3.894899999996412e-06 teacher_forcing_ratio:  0.9999961050996777\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0018057427369058132\n",
      "KL_weight:  3.899899999996423e-06 teacher_forcing_ratio:  0.9999961000996773\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0018981773173436522\n",
      "KL_weight:  3.904899999996434e-06 teacher_forcing_ratio:  0.9999960950996769\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0019625111017376184\n",
      "KL_weight:  3.909899999996445e-06 teacher_forcing_ratio:  0.9999960900996765\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0017506860895082355\n",
      "KL_weight:  3.914899999996456e-06 teacher_forcing_ratio:  0.9999960850996761\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002130465116351843\n",
      "KL_weight:  3.9198999999964665e-06 teacher_forcing_ratio:  0.9999960800996757\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0020175836980342865\n",
      "KL_weight:  3.9248999999964775e-06 teacher_forcing_ratio:  0.9999960750996753\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonfarned \tScore:  0.14178\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absettering \tScore:  0.17828\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestigrens \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   wexpenders \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentersled \tScore:  0.11868\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  misreplting \tScore:  0.29982\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flarpearing \tScore:  0.24808\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fencortinuing \tScore:  0.05526\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fencrittanizing \tScore:  0.03823\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: heharlivesing \tScore:  0.04132\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001772940275259316\n",
      "KL_weight:  3.931899999996493e-06 teacher_forcing_ratio:  0.9999960680996747\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0017211262602359056\n",
      "KL_weight:  3.936899999996504e-06 teacher_forcing_ratio:  0.9999960630996743\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017131338827311993\n",
      "KL_weight:  3.941899999996515e-06 teacher_forcing_ratio:  0.9999960580996738\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0019038349855691195\n",
      "KL_weight:  3.946899999996526e-06 teacher_forcing_ratio:  0.9999960530996734\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001652613515034318\n",
      "KL_weight:  3.951899999996537e-06 teacher_forcing_ratio:  0.999996048099673\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0016562946839258075\n",
      "KL_weight:  3.956899999996548e-06 teacher_forcing_ratio:  0.9999960430996726\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0017105895094573498\n",
      "KL_weight:  3.961899999996559e-06 teacher_forcing_ratio:  0.9999960380996722\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016763453604653478\n",
      "KL_weight:  3.96689999999657e-06 teacher_forcing_ratio:  0.9999960330996718\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0014872929314151406\n",
      "KL_weight:  3.9718999999965806e-06 teacher_forcing_ratio:  0.9999960280996714\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500 char-loss:  0.001631299965083599\n",
      "KL_weight:  3.9768999999965915e-06 teacher_forcing_ratio:  0.999996023099671\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0015403332654386759\n",
      "KL_weight:  3.9818999999966025e-06 teacher_forcing_ratio:  0.9999960180996705\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0015424847370013595\n",
      "KL_weight:  3.9868999999966135e-06 teacher_forcing_ratio:  0.9999960130996701\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0014900057576596737\n",
      "KL_weight:  3.991899999996624e-06 teacher_forcing_ratio:  0.9999960080996697\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001443506102077663\n",
      "KL_weight:  3.996899999996635e-06 teacher_forcing_ratio:  0.9999960030996693\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0014014217304065824\n",
      "KL_weight:  4.001899999996646e-06 teacher_forcing_ratio:  0.9999959980996689\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonfarled \tScore:  0.07176\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absettering \tScore:  0.17828\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestighine \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expenders \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sterensote \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  mispretling \tScore:  0.14178\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarmerted \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fencratizing \tScore:  0.05638\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fercuntioning \tScore:  0.25451\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hestarleing \tScore:  0.05013\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0014897463843226433\n",
      "KL_weight:  4.008899999996662e-06 teacher_forcing_ratio:  0.9999959910996683\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0013922714861109853\n",
      "KL_weight:  4.013899999996673e-06 teacher_forcing_ratio:  0.9999959860996679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0014089675387367606\n",
      "KL_weight:  4.018899999996684e-06 teacher_forcing_ratio:  0.9999959810996675\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0014368671691045165\n",
      "KL_weight:  4.023899999996695e-06 teacher_forcing_ratio:  0.9999959760996671\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001539515214972198\n",
      "KL_weight:  4.0288999999967055e-06 teacher_forcing_ratio:  0.9999959710996666\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0015306035056710243\n",
      "KL_weight:  4.0338999999967165e-06 teacher_forcing_ratio:  0.9999959660996662\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0014203155878931284\n",
      "KL_weight:  4.0388999999967275e-06 teacher_forcing_ratio:  0.9999959610996658\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0012931922683492303\n",
      "KL_weight:  4.0438999999967384e-06 teacher_forcing_ratio:  0.9999959560996654\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0314105860888958\n",
      "KL_weight:  4.048899999996749e-06 teacher_forcing_ratio:  0.999995951099665\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.038548704236745834\n",
      "KL_weight:  4.05389999999676e-06 teacher_forcing_ratio:  0.9999959460996646\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.014381160959601402\n",
      "KL_weight:  4.058899999996771e-06 teacher_forcing_ratio:  0.9999959410996642\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.008024181239306927\n",
      "KL_weight:  4.063899999996782e-06 teacher_forcing_ratio:  0.9999959360996638\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0035511101596057415\n",
      "KL_weight:  4.068899999996793e-06 teacher_forcing_ratio:  0.9999959310996633\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0027595299761742353\n",
      "KL_weight:  4.073899999996804e-06 teacher_forcing_ratio:  0.9999959260996629\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0026541356928646564\n",
      "KL_weight:  4.078899999996815e-06 teacher_forcing_ratio:  0.9999959210996625\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abspandoning \tScore:  0.36463\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   babtersted \tScore:  0.05612\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: bestrakinged \tScore:  0.05638\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   penderates \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  stenstraned \tScore:  0.05013\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splistrept \tScore:  0.29072\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flarpeashed \tScore:  0.24808\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: heaspelating \tScore:  0.09578\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002420088741928339\n",
      "KL_weight:  4.0858999999968305e-06 teacher_forcing_ratio:  0.9999959140996619\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002444386947900057\n",
      "KL_weight:  4.0908999999968415e-06 teacher_forcing_ratio:  0.9999959090996615\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0023876491468399763\n",
      "KL_weight:  4.0958999999968525e-06 teacher_forcing_ratio:  0.9999959040996611\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002254645572975278\n",
      "KL_weight:  4.1008999999968634e-06 teacher_forcing_ratio:  0.9999958990996607\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0022409548982977867\n",
      "KL_weight:  4.105899999996874e-06 teacher_forcing_ratio:  0.9999958940996603\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0021499963477253914\n",
      "KL_weight:  4.110899999996885e-06 teacher_forcing_ratio:  0.9999958890996599\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0021302371751517057\n",
      "KL_weight:  4.115899999996896e-06 teacher_forcing_ratio:  0.9999958840996594\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0020507306326180696\n",
      "KL_weight:  4.120899999996907e-06 teacher_forcing_ratio:  0.999995879099659\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0019374829716980457\n",
      "KL_weight:  4.125899999996918e-06 teacher_forcing_ratio:  0.9999958740996586\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0020299251191318035\n",
      "KL_weight:  4.130899999996929e-06 teacher_forcing_ratio:  0.9999958690996582\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 550 char-loss:  0.0021234590094536543\n",
      "KL_weight:  4.13589999999694e-06 teacher_forcing_ratio:  0.9999958640996578\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0019030426628887653\n",
      "KL_weight:  4.140899999996951e-06 teacher_forcing_ratio:  0.9999958590996574\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0019028009846806526\n",
      "KL_weight:  4.145899999996962e-06 teacher_forcing_ratio:  0.999995854099657\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0018894312670454383\n",
      "KL_weight:  4.150899999996973e-06 teacher_forcing_ratio:  0.9999958490996566\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0018175119766965508\n",
      "KL_weight:  4.155899999996984e-06 teacher_forcing_ratio:  0.9999958440996561\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abspandoning \tScore:  0.36463\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  babtersaten \tScore:  0.05246\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestrignes \tScore:  0.05874\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  pexpanderes \tScore:  0.13712\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     smenters \tScore:  0.06985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  mproslitted \tScore:  0.25965\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flarpeashed \tScore:  0.24808\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: heasperalided \tScore:  0.09669\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0017062552506104112\n",
      "KL_weight:  4.162899999996999e-06 teacher_forcing_ratio:  0.9999958370996556\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016981875523924828\n",
      "KL_weight:  4.16789999999701e-06 teacher_forcing_ratio:  0.9999958320996551\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0016454514116048813\n",
      "KL_weight:  4.172899999997021e-06 teacher_forcing_ratio:  0.9999958270996547\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0018428417388349771\n",
      "KL_weight:  4.177899999997032e-06 teacher_forcing_ratio:  0.9999958220996543\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.001714339479804039\n",
      "KL_weight:  4.182899999997043e-06 teacher_forcing_ratio:  0.9999958170996539\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001689855707809329\n",
      "KL_weight:  4.187899999997054e-06 teacher_forcing_ratio:  0.9999958120996535\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001618558424524963\n",
      "KL_weight:  4.192899999997065e-06 teacher_forcing_ratio:  0.9999958070996531\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0015928196953609586\n",
      "KL_weight:  4.197899999997076e-06 teacher_forcing_ratio:  0.9999958020996527\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0016525404062122107\n",
      "KL_weight:  4.202899999997087e-06 teacher_forcing_ratio:  0.9999957970996523\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0015702972887083888\n",
      "KL_weight:  4.207899999997098e-06 teacher_forcing_ratio:  0.9999957920996518\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0017141965217888355\n",
      "KL_weight:  4.212899999997109e-06 teacher_forcing_ratio:  0.9999957870996514\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002077196491882205\n",
      "KL_weight:  4.21789999999712e-06 teacher_forcing_ratio:  0.999995782099651\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.006384850479662418\n",
      "KL_weight:  4.222899999997131e-06 teacher_forcing_ratio:  0.9999957770996506\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.006372096017003059\n",
      "KL_weight:  4.227899999997142e-06 teacher_forcing_ratio:  0.9999957720996502\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.009572306647896767\n",
      "KL_weight:  4.232899999997153e-06 teacher_forcing_ratio:  0.9999957670996498\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: absonhanding \tScore:  0.12390\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absettering \tScore:  0.17828\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: begrishening \tScore:  0.11095\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpernded \tScore:  0.31239\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     swetters \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  smispleting \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    fadrolesh \tScore:  0.03586\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionquishe \tScore:  0.51424\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionquishe \tScore:  0.52961\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: heastignaling \tScore:  0.09669\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.009002084843814373\n",
      "KL_weight:  4.239899999997168e-06 teacher_forcing_ratio:  0.9999957600996492\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.003479371080175042\n",
      "KL_weight:  4.244899999997179e-06 teacher_forcing_ratio:  0.9999957550996488\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0027217683382332325\n",
      "KL_weight:  4.24989999999719e-06 teacher_forcing_ratio:  0.9999957500996484\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0024996346328407526\n",
      "KL_weight:  4.254899999997201e-06 teacher_forcing_ratio:  0.999995745099648\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0025724328588694334\n",
      "KL_weight:  4.259899999997212e-06 teacher_forcing_ratio:  0.9999957400996475\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023346294183284044\n",
      "KL_weight:  4.264899999997223e-06 teacher_forcing_ratio:  0.9999957350996471\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0021384803112596273\n",
      "KL_weight:  4.269899999997234e-06 teacher_forcing_ratio:  0.9999957300996467\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002125839004293084\n",
      "KL_weight:  4.274899999997245e-06 teacher_forcing_ratio:  0.9999957250996463\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0020185604225844145\n",
      "KL_weight:  4.279899999997256e-06 teacher_forcing_ratio:  0.9999957200996459\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002296280348673463\n",
      "KL_weight:  4.284899999997267e-06 teacher_forcing_ratio:  0.9999957150996455\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0019519127672538161\n",
      "KL_weight:  4.289899999997278e-06 teacher_forcing_ratio:  0.999995710099645\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 600 char-loss:  0.002092708833515644\n",
      "KL_weight:  4.294899999997289e-06 teacher_forcing_ratio:  0.9999957050996446\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002221603412181139\n",
      "KL_weight:  4.2998999999973e-06 teacher_forcing_ratio:  0.9999957000996442\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0022269010078161955\n",
      "KL_weight:  4.304899999997311e-06 teacher_forcing_ratio:  0.9999956950996438\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0020502619445323944\n",
      "KL_weight:  4.309899999997322e-06 teacher_forcing_ratio:  0.9999956900996434\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absankonded \tScore:  0.08682\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  babsteringe \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befightens \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpenders \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentrates \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splishtering \tScore:  0.31702\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarpeding \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionates \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizes \tScore:  0.63156\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: bhaswealinged \tScore:  0.08737\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002021338324993849\n",
      "KL_weight:  4.316899999997337e-06 teacher_forcing_ratio:  0.9999956830996428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0019807934295386076\n",
      "KL_weight:  4.321899999997348e-06 teacher_forcing_ratio:  0.9999956780996424\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0018623190699145198\n",
      "KL_weight:  4.326899999997359e-06 teacher_forcing_ratio:  0.999995673099642\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001792187220416963\n",
      "KL_weight:  4.33189999999737e-06 teacher_forcing_ratio:  0.9999956680996416\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0019690576009452343\n",
      "KL_weight:  4.336899999997381e-06 teacher_forcing_ratio:  0.9999956630996412\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001757142599672079\n",
      "KL_weight:  4.341899999997392e-06 teacher_forcing_ratio:  0.9999956580996407\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001710321637801826\n",
      "KL_weight:  4.346899999997403e-06 teacher_forcing_ratio:  0.9999956530996403\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016846141079440713\n",
      "KL_weight:  4.351899999997414e-06 teacher_forcing_ratio:  0.9999956480996399\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0016453817952424288\n",
      "KL_weight:  4.356899999997425e-06 teacher_forcing_ratio:  0.9999956430996395\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0015209967968985438\n",
      "KL_weight:  4.361899999997436e-06 teacher_forcing_ratio:  0.9999956380996391\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0016124851536005735\n",
      "KL_weight:  4.366899999997447e-06 teacher_forcing_ratio:  0.9999956330996387\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0016286377795040607\n",
      "KL_weight:  4.371899999997458e-06 teacher_forcing_ratio:  0.9999956280996383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0015904414467513561\n",
      "KL_weight:  4.376899999997469e-06 teacher_forcing_ratio:  0.9999956230996379\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001581398886628449\n",
      "KL_weight:  4.38189999999748e-06 teacher_forcing_ratio:  0.9999956180996374\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0014959601685404778\n",
      "KL_weight:  4.3868999999974905e-06 teacher_forcing_ratio:  0.999995613099637\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absantonded \tScore:  0.08682\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   baystering \tScore:  0.12910\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   beshoifing \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   xenderksed \tScore:  0.12422\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sentistears \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splishopting \tScore:  0.42401\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flabpred \tScore:  0.17286\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionatesing \tScore:  0.49009\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  bhasterizes \tScore:  0.02666\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015394368674606085\n",
      "KL_weight:  4.393899999997506e-06 teacher_forcing_ratio:  0.9999956060996364\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0014542646240442991\n",
      "KL_weight:  4.398899999997517e-06 teacher_forcing_ratio:  0.999995601099636\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0016568752471357584\n",
      "KL_weight:  4.403899999997528e-06 teacher_forcing_ratio:  0.9999955960996356\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0015385684091597795\n",
      "KL_weight:  4.408899999997539e-06 teacher_forcing_ratio:  0.9999955910996352\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0015827114693820477\n",
      "KL_weight:  4.41389999999755e-06 teacher_forcing_ratio:  0.9999955860996348\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.001451160293072462\n",
      "KL_weight:  4.418899999997561e-06 teacher_forcing_ratio:  0.9999955810996344\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0013469336554408073\n",
      "KL_weight:  4.423899999997572e-06 teacher_forcing_ratio:  0.999995576099634\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0014999407576397061\n",
      "KL_weight:  4.428899999997583e-06 teacher_forcing_ratio:  0.9999955710996336\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0013714995002374053\n",
      "KL_weight:  4.433899999997594e-06 teacher_forcing_ratio:  0.9999955660996331\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.07807289063930511\n",
      "KL_weight:  4.4388999999976046e-06 teacher_forcing_ratio:  0.9999955610996327\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.019077090546488762\n",
      "KL_weight:  4.4438999999976155e-06 teacher_forcing_ratio:  0.9999955560996323\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.016681412234902382\n",
      "KL_weight:  4.4488999999976265e-06 teacher_forcing_ratio:  0.9999955510996319\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 650 char-loss:  0.004160367418080568\n",
      "KL_weight:  4.4538999999976375e-06 teacher_forcing_ratio:  0.9999955460996315\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0036135492846369743\n",
      "KL_weight:  4.458899999997648e-06 teacher_forcing_ratio:  0.9999955410996311\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0030696443282067776\n",
      "KL_weight:  4.463899999997659e-06 teacher_forcing_ratio:  0.9999955360996307\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abdonpanied \tScore:  0.15439\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absettering \tScore:  0.17828\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  bedjingling \tScore:  0.05961\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expendersing \tScore:  0.43362\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   misstender \tScore:  0.11868\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   misploting \tScore:  0.39281\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  billapsered \tScore:  0.05638\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: onfictarized \tScore:  0.05638\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: onficturinged \tScore:  0.06466\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: besharignaled \tScore:  0.04132\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0024867260362952948\n",
      "KL_weight:  4.470899999997675e-06 teacher_forcing_ratio:  0.9999955290996301\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0025098773185163736\n",
      "KL_weight:  4.475899999997686e-06 teacher_forcing_ratio:  0.9999955240996297\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002401649719104171\n",
      "KL_weight:  4.480899999997697e-06 teacher_forcing_ratio:  0.9999955190996292\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0023136979434639215\n",
      "KL_weight:  4.485899999997708e-06 teacher_forcing_ratio:  0.9999955140996288\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0022495489101856947\n",
      "KL_weight:  4.490899999997719e-06 teacher_forcing_ratio:  0.9999955090996284\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002278374508023262\n",
      "KL_weight:  4.4958999999977295e-06 teacher_forcing_ratio:  0.999995504099628\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002005245303735137\n",
      "KL_weight:  4.5008999999977405e-06 teacher_forcing_ratio:  0.9999954990996276\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002127782441675663\n",
      "KL_weight:  4.5058999999977515e-06 teacher_forcing_ratio:  0.9999954940996272\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002054282696917653\n",
      "KL_weight:  4.5108999999977624e-06 teacher_forcing_ratio:  0.9999954890996268\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001980200409889221\n",
      "KL_weight:  4.515899999997773e-06 teacher_forcing_ratio:  0.9999954840996264\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001979106105864048\n",
      "KL_weight:  4.520899999997784e-06 teacher_forcing_ratio:  0.9999954790996259\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0020885970443487167\n",
      "KL_weight:  4.525899999997795e-06 teacher_forcing_ratio:  0.9999954740996255\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0019565015099942684\n",
      "KL_weight:  4.530899999997806e-06 teacher_forcing_ratio:  0.9999954690996251\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002066076500341296\n",
      "KL_weight:  4.535899999997817e-06 teacher_forcing_ratio:  0.9999954640996247\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0019426451763138175\n",
      "KL_weight:  4.540899999997828e-06 teacher_forcing_ratio:  0.9999954590996243\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abdenpalion \tScore:  0.06704\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   absertized \tScore:  0.06674\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: bederigninges \tScore:  0.05142\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experspends \tScore:  0.53107\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   missenters \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  misplotined \tScore:  0.16307\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    florapsed \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functiongist \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functiongised \tScore:  0.61154\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    hedpailes \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.00189964531455189\n",
      "KL_weight:  4.5478999999978436e-06 teacher_forcing_ratio:  0.9999954520996237\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0018506462220102549\n",
      "KL_weight:  4.5528999999978545e-06 teacher_forcing_ratio:  0.9999954470996233\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017511195037513971\n",
      "KL_weight:  4.5578999999978655e-06 teacher_forcing_ratio:  0.9999954420996229\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001841345801949501\n",
      "KL_weight:  4.5628999999978765e-06 teacher_forcing_ratio:  0.9999954370996225\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0018045621691271663\n",
      "KL_weight:  4.567899999997887e-06 teacher_forcing_ratio:  0.999995432099622\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0018619828624650836\n",
      "KL_weight:  4.572899999997898e-06 teacher_forcing_ratio:  0.9999954270996216\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0017985242884606123\n",
      "KL_weight:  4.577899999997909e-06 teacher_forcing_ratio:  0.9999954220996212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0016418517334386706\n",
      "KL_weight:  4.58289999999792e-06 teacher_forcing_ratio:  0.9999954170996208\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001955899642780423\n",
      "KL_weight:  4.587899999997931e-06 teacher_forcing_ratio:  0.9999954120996204\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0016831657849252224\n",
      "KL_weight:  4.592899999997942e-06 teacher_forcing_ratio:  0.99999540709962\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0017115602968260646\n",
      "KL_weight:  4.597899999997953e-06 teacher_forcing_ratio:  0.9999954020996196\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.001664373674429953\n",
      "KL_weight:  4.602899999997964e-06 teacher_forcing_ratio:  0.9999953970996192\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0015704067191109061\n",
      "KL_weight:  4.607899999997975e-06 teacher_forcing_ratio:  0.9999953920996187\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 700 char-loss:  0.0016265888698399067\n",
      "KL_weight:  4.612899999997986e-06 teacher_forcing_ratio:  0.9999953870996183\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0015775925712659955\n",
      "KL_weight:  4.617899999997997e-06 teacher_forcing_ratio:  0.9999953820996179\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abdronappend \tScore:  0.06905\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absettinged \tScore:  0.51931\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: bedisterings \tScore:  0.05638\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experspends \tScore:  0.53107\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   mistrendes \tScore:  0.11868\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  displetsing \tScore:  0.16860\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: florapteding \tScore:  0.04529\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functiongist \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functiongisted \tScore:  0.56220\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: besfuringoed \tScore:  0.02026\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0015264081303030252\n",
      "KL_weight:  4.624899999998012e-06 teacher_forcing_ratio:  0.9999953750996173\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0014821799704805017\n",
      "KL_weight:  4.629899999998023e-06 teacher_forcing_ratio:  0.9999953700996169\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0015195702435448766\n",
      "KL_weight:  4.634899999998034e-06 teacher_forcing_ratio:  0.9999953650996165\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0015616093296557665\n",
      "KL_weight:  4.639899999998045e-06 teacher_forcing_ratio:  0.9999953600996161\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0017171679064631462\n",
      "KL_weight:  4.644899999998056e-06 teacher_forcing_ratio:  0.9999953550996157\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.025157399475574493\n",
      "KL_weight:  4.649899999998067e-06 teacher_forcing_ratio:  0.9999953500996153\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.04953407868742943\n",
      "KL_weight:  4.654899999998078e-06 teacher_forcing_ratio:  0.9999953450996149\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.007761363871395588\n",
      "KL_weight:  4.659899999998089e-06 teacher_forcing_ratio:  0.9999953400996144\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.008637133985757828\n",
      "KL_weight:  4.6648999999981e-06 teacher_forcing_ratio:  0.999995335099614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.00475622434169054\n",
      "KL_weight:  4.669899999998111e-06 teacher_forcing_ratio:  0.9999953300996136\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0027390962932258844\n",
      "KL_weight:  4.674899999998122e-06 teacher_forcing_ratio:  0.9999953250996132\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002618097933009267\n",
      "KL_weight:  4.679899999998133e-06 teacher_forcing_ratio:  0.9999953200996128\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002438893308863044\n",
      "KL_weight:  4.684899999998144e-06 teacher_forcing_ratio:  0.9999953150996124\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0024536065757274628\n",
      "KL_weight:  4.689899999998155e-06 teacher_forcing_ratio:  0.999995310099612\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0023089840542525053\n",
      "KL_weight:  4.694899999998166e-06 teacher_forcing_ratio:  0.9999953050996115\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  advanksting \tScore:  0.05013\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   backerting \tScore:  0.30214\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: berignecting \tScore:  0.05386\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  kexpendings \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snetcrates \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   sklistring \tScore:  0.14287\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flardenting \tScore:  0.24808\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fuctinatinuing \tScore:  0.09669\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionizing \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  jearchating \tScore:  0.04412\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0022337879054248333\n",
      "KL_weight:  4.701899999998181e-06 teacher_forcing_ratio:  0.999995298099611\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002303460845723748\n",
      "KL_weight:  4.706899999998192e-06 teacher_forcing_ratio:  0.9999952930996105\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0022172252647578716\n",
      "KL_weight:  4.711899999998203e-06 teacher_forcing_ratio:  0.9999952880996101\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002111341105774045\n",
      "KL_weight:  4.716899999998214e-06 teacher_forcing_ratio:  0.9999952830996097\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002064842265099287\n",
      "KL_weight:  4.721899999998225e-06 teacher_forcing_ratio:  0.9999952780996093\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002072684234008193\n",
      "KL_weight:  4.726899999998236e-06 teacher_forcing_ratio:  0.9999952730996089\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0019163944525644183\n",
      "KL_weight:  4.731899999998247e-06 teacher_forcing_ratio:  0.9999952680996085\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0020920096430927515\n",
      "KL_weight:  4.736899999998258e-06 teacher_forcing_ratio:  0.9999952630996081\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002100089332088828\n",
      "KL_weight:  4.741899999998269e-06 teacher_forcing_ratio:  0.9999952580996077\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0020517478697001934\n",
      "KL_weight:  4.74689999999828e-06 teacher_forcing_ratio:  0.9999952530996072\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0020869746804237366\n",
      "KL_weight:  4.751899999998291e-06 teacher_forcing_ratio:  0.9999952480996068\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0018210472771897912\n",
      "KL_weight:  4.756899999998302e-06 teacher_forcing_ratio:  0.9999952430996064\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0017927979351952672\n",
      "KL_weight:  4.761899999998313e-06 teacher_forcing_ratio:  0.999995238099606\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0019250517943874002\n",
      "KL_weight:  4.766899999998324e-06 teacher_forcing_ratio:  0.9999952330996056\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 750 char-loss:  0.0019125244580209255\n",
      "KL_weight:  4.771899999998335e-06 teacher_forcing_ratio:  0.9999952280996052\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  advanksting \tScore:  0.05013\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   backerting \tScore:  0.30214\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bedimunies \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expendersting \tScore:  0.39553\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentracted \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   sklistring \tScore:  0.14287\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flardenting \tScore:  0.24808\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fuctinatinuing \tScore:  0.09669\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fectifanciding \tScore:  0.09998\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  benalighted \tScore:  0.04741\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0017444592667743564\n",
      "KL_weight:  4.77889999999835e-06 teacher_forcing_ratio:  0.9999952210996046\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0023671407252550125\n",
      "KL_weight:  4.783899999998361e-06 teacher_forcing_ratio:  0.9999952160996042\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0018040203722193837\n",
      "KL_weight:  4.788899999998372e-06 teacher_forcing_ratio:  0.9999952110996038\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0018524222541600466\n",
      "KL_weight:  4.793899999998383e-06 teacher_forcing_ratio:  0.9999952060996034\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0016798023134469986\n",
      "KL_weight:  4.798899999998394e-06 teacher_forcing_ratio:  0.9999952010996029\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0016671023331582546\n",
      "KL_weight:  4.803899999998405e-06 teacher_forcing_ratio:  0.9999951960996025\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0017576910322532058\n",
      "KL_weight:  4.808899999998416e-06 teacher_forcing_ratio:  0.9999951910996021\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001865809434093535\n",
      "KL_weight:  4.813899999998427e-06 teacher_forcing_ratio:  0.9999951860996017\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0015867679612711072\n",
      "KL_weight:  4.818899999998438e-06 teacher_forcing_ratio:  0.9999951810996013\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001591797568835318\n",
      "KL_weight:  4.823899999998449e-06 teacher_forcing_ratio:  0.9999951760996009\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001655766274780035\n",
      "KL_weight:  4.82889999999846e-06 teacher_forcing_ratio:  0.9999951710996005\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0016036831075325608\n",
      "KL_weight:  4.833899999998471e-06 teacher_forcing_ratio:  0.9999951660996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0016423980705440044\n",
      "KL_weight:  4.838899999998482e-06 teacher_forcing_ratio:  0.9999951610995996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.001693950267508626\n",
      "KL_weight:  4.843899999998493e-06 teacher_forcing_ratio:  0.9999951560995992\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0016674830112606287\n",
      "KL_weight:  4.8488999999985036e-06 teacher_forcing_ratio:  0.9999951510995988\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  adjoncaling \tScore:  0.05246\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  featrinying \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  bejintering \tScore:  0.05961\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expendersing \tScore:  0.43362\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snectrises \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   sklistring \tScore:  0.14287\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   fladreyiny \tScore:  0.13135\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functioniating \tScore:  0.51424\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: bechaingared \tScore:  0.02242\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.001478673773817718\n",
      "KL_weight:  4.855899999998519e-06 teacher_forcing_ratio:  0.9999951440995982\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0014503923011943698\n",
      "KL_weight:  4.86089999999853e-06 teacher_forcing_ratio:  0.9999951390995978\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.001644877134822309\n",
      "KL_weight:  4.865899999998541e-06 teacher_forcing_ratio:  0.9999951340995974\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0016686103772372007\n",
      "KL_weight:  4.870899999998552e-06 teacher_forcing_ratio:  0.999995129099597\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.007233059033751488\n",
      "KL_weight:  4.875899999998563e-06 teacher_forcing_ratio:  0.9999951240995966\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.05686101317405701\n",
      "KL_weight:  4.880899999998574e-06 teacher_forcing_ratio:  0.9999951190995962\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.022447790950536728\n",
      "KL_weight:  4.885899999998585e-06 teacher_forcing_ratio:  0.9999951140995957\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.018159473314881325\n",
      "KL_weight:  4.890899999998596e-06 teacher_forcing_ratio:  0.9999951090995953\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.012503568083047867\n",
      "KL_weight:  4.895899999998607e-06 teacher_forcing_ratio:  0.9999951040995949\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002880523446947336\n",
      "KL_weight:  4.900899999998618e-06 teacher_forcing_ratio:  0.9999950990995945\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0026587597094476223\n",
      "KL_weight:  4.9058999999986286e-06 teacher_forcing_ratio:  0.9999950940995941\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0026901804376393557\n",
      "KL_weight:  4.9108999999986395e-06 teacher_forcing_ratio:  0.9999950890995937\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0024972138926386833\n",
      "KL_weight:  4.9158999999986505e-06 teacher_forcing_ratio:  0.9999950840995933\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002365748630836606\n",
      "KL_weight:  4.9208999999986614e-06 teacher_forcing_ratio:  0.9999950790995928\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0024114118423312902\n",
      "KL_weight:  4.925899999998672e-06 teacher_forcing_ratio:  0.9999950740995924\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fadmonaleding \tScore:  0.05526\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  fetablinges \tScore:  0.13712\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: besfignaries \tScore:  0.04741\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpenders \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentersing \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  mislipliten \tScore:  0.26986\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flabdres \tScore:  0.17286\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functiagnize \tScore:  0.43362\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functiatening \tScore:  0.40896\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: behailensing \tScore:  0.02547\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002284630201756954\n",
      "KL_weight:  4.932899999998688e-06 teacher_forcing_ratio:  0.9999950670995919\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021217619068920612\n",
      "KL_weight:  4.937899999998699e-06 teacher_forcing_ratio:  0.9999950620995914\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0026080459356307983\n",
      "KL_weight:  4.94289999999871e-06 teacher_forcing_ratio:  0.999995057099591\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0024724050890654325\n",
      "KL_weight:  4.947899999998721e-06 teacher_forcing_ratio:  0.9999950520995906\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002122086239978671\n",
      "KL_weight:  4.952899999998732e-06 teacher_forcing_ratio:  0.9999950470995902\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0021953321993350983\n",
      "KL_weight:  4.957899999998743e-06 teacher_forcing_ratio:  0.9999950420995898\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0021503225434571505\n",
      "KL_weight:  4.9628999999987535e-06 teacher_forcing_ratio:  0.9999950370995894\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0020345840603113174\n",
      "KL_weight:  4.9678999999987645e-06 teacher_forcing_ratio:  0.999995032099589\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.001913514919579029\n",
      "KL_weight:  4.9728999999987755e-06 teacher_forcing_ratio:  0.9999950270995885\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.001893686130642891\n",
      "KL_weight:  4.9778999999987864e-06 teacher_forcing_ratio:  0.9999950220995881\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.001968254568055272\n",
      "KL_weight:  4.982899999998797e-06 teacher_forcing_ratio:  0.9999950170995877\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002069894690066576\n",
      "KL_weight:  4.987899999998808e-06 teacher_forcing_ratio:  0.9999950120995873\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0019803710747510195\n",
      "KL_weight:  4.992899999998819e-06 teacher_forcing_ratio:  0.9999950070995869\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0018939164001494646\n",
      "KL_weight:  4.99789999999883e-06 teacher_forcing_ratio:  0.9999950020995865\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0018640088383108377\n",
      "KL_weight:  5.002899999998841e-06 teacher_forcing_ratio:  0.9999949970995861\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fadmonaleding \tScore:  0.05526\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   befalteing \tScore:  0.14287\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   besfignies \tScore:  0.05874\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexpenders \tScore:  0.53728\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict: sintermanses \tScore:  0.04284\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: skistrapling \tScore:  0.15235\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flaspired \tScore:  0.14924\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functifapening \tScore:  0.36362\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functifateding \tScore:  0.40526\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: feashiateringed \tScore:  0.03324\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0017990953056141734\n",
      "KL_weight:  5.009899999998857e-06 teacher_forcing_ratio:  0.9999949900995855\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0016942794900387526\n",
      "KL_weight:  5.0148999999988676e-06 teacher_forcing_ratio:  0.9999949850995851\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017724537756294012\n",
      "KL_weight:  5.0198999999988785e-06 teacher_forcing_ratio:  0.9999949800995847\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.009084587916731834\n",
      "KL_weight:  5.0248999999988895e-06 teacher_forcing_ratio:  0.9999949750995842\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.003123912727460265\n",
      "KL_weight:  5.0298999999989005e-06 teacher_forcing_ratio:  0.9999949700995838\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.008903560228645802\n",
      "KL_weight:  5.034899999998911e-06 teacher_forcing_ratio:  0.9999949650995834\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.007315421476960182\n",
      "KL_weight:  5.039899999998922e-06 teacher_forcing_ratio:  0.999994960099583\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0032641130965203047\n",
      "KL_weight:  5.044899999998933e-06 teacher_forcing_ratio:  0.9999949550995826\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0030562717001885176\n",
      "KL_weight:  5.049899999998944e-06 teacher_forcing_ratio:  0.9999949500995822\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002795931650325656\n",
      "KL_weight:  5.054899999998955e-06 teacher_forcing_ratio:  0.9999949450995818\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002593799028545618\n",
      "KL_weight:  5.059899999998966e-06 teacher_forcing_ratio:  0.9999949400995813\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0026153300423175097\n",
      "KL_weight:  5.064899999998977e-06 teacher_forcing_ratio:  0.9999949350995809\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002141006290912628\n",
      "KL_weight:  5.069899999998988e-06 teacher_forcing_ratio:  0.9999949300995805\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002240266650915146\n",
      "KL_weight:  5.074899999998999e-06 teacher_forcing_ratio:  0.9999949250995801\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0021406481973826885\n",
      "KL_weight:  5.07989999999901e-06 teacher_forcing_ratio:  0.9999949200995797\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abdenlonizes \tScore:  0.05859\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  featbersing \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: besfimatening \tScore:  0.05142\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   exphenders \tScore:  0.18257\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sentermains \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splithrinking \tScore:  0.38677\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flabdrels \tScore:  0.14924\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fectifanching \tScore:  0.10120\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fectinatuning \tScore:  0.10875\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: behainsapering \tScore:  0.02020\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.0019353068200871348\n",
      "KL_weight:  5.0868999999990254e-06 teacher_forcing_ratio:  0.9999949130995791\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0020453021861612797\n",
      "KL_weight:  5.091899999999036e-06 teacher_forcing_ratio:  0.9999949080995787\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0019653495401144028\n",
      "KL_weight:  5.096899999999047e-06 teacher_forcing_ratio:  0.9999949030995783\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0020552107598632574\n",
      "KL_weight:  5.101899999999058e-06 teacher_forcing_ratio:  0.9999948980995779\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0019001828040927649\n",
      "KL_weight:  5.106899999999069e-06 teacher_forcing_ratio:  0.9999948930995775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002134308684617281\n",
      "KL_weight:  5.11189999999908e-06 teacher_forcing_ratio:  0.999994888099577\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0019631104078143835\n",
      "KL_weight:  5.116899999999091e-06 teacher_forcing_ratio:  0.9999948830995766\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0033162885811179876\n",
      "KL_weight:  5.121899999999102e-06 teacher_forcing_ratio:  0.9999948780995762\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0040101557970047\n",
      "KL_weight:  5.126899999999113e-06 teacher_forcing_ratio:  0.9999948730995758\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0027096765115857124\n",
      "KL_weight:  5.131899999999124e-06 teacher_forcing_ratio:  0.9999948680995754\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.003378625027835369\n",
      "KL_weight:  5.136899999999135e-06 teacher_forcing_ratio:  0.999994863099575\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0038698972202837467\n",
      "KL_weight:  5.141899999999146e-06 teacher_forcing_ratio:  0.9999948580995746\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.008497124537825584\n",
      "KL_weight:  5.146899999999157e-06 teacher_forcing_ratio:  0.9999948530995741\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.008671490475535393\n",
      "KL_weight:  5.151899999999168e-06 teacher_forcing_ratio:  0.9999948480995737\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.009854806587100029\n",
      "KL_weight:  5.156899999999179e-06 teacher_forcing_ratio:  0.9999948430995733\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     foanding \tScore:  0.13784\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    fostering \tScore:  0.13485\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   fersioning \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexphondeding \tScore:  0.10875\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      snoring \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: snickrishing \tScore:  0.09578\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   clarreding \tScore:  0.12422\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: confiltinging \tScore:  0.05344\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   finchoring \tScore:  0.05874\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    cheraring \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.049752309918403625\n",
      "KL_weight:  5.163899999999194e-06 teacher_forcing_ratio:  0.9999948360995727\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.003449481911957264\n",
      "KL_weight:  5.168899999999205e-06 teacher_forcing_ratio:  0.9999948310995723\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.004024555440992117\n",
      "KL_weight:  5.173899999999216e-06 teacher_forcing_ratio:  0.9999948260995719\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0029159202240407467\n",
      "KL_weight:  5.178899999999227e-06 teacher_forcing_ratio:  0.9999948210995715\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0027603143826127052\n",
      "KL_weight:  5.183899999999238e-06 teacher_forcing_ratio:  0.9999948160995711\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023136772215366364\n",
      "KL_weight:  5.188899999999249e-06 teacher_forcing_ratio:  0.9999948110995707\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.003496479010209441\n",
      "KL_weight:  5.19389999999926e-06 teacher_forcing_ratio:  0.9999948060995703\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002879086183384061\n",
      "KL_weight:  5.198899999999271e-06 teacher_forcing_ratio:  0.9999948010995698\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0028024606872349977\n",
      "KL_weight:  5.203899999999282e-06 teacher_forcing_ratio:  0.9999947960995694\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0025426321662962437\n",
      "KL_weight:  5.208899999999293e-06 teacher_forcing_ratio:  0.999994791099569\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00241229310631752\n",
      "KL_weight:  5.213899999999304e-06 teacher_forcing_ratio:  0.9999947860995686\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002223326824605465\n",
      "KL_weight:  5.218899999999315e-06 teacher_forcing_ratio:  0.9999947810995682\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002437395043671131\n",
      "KL_weight:  5.223899999999326e-06 teacher_forcing_ratio:  0.9999947760995678\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002269007731229067\n",
      "KL_weight:  5.228899999999337e-06 teacher_forcing_ratio:  0.9999947710995674\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0022097770124673843\n",
      "KL_weight:  5.233899999999348e-06 teacher_forcing_ratio:  0.999994766099567\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fasdonachinging \tScore:  0.07780\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  festabrying \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestigning \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexpendinged \tScore:  0.41723\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  snectirgnoy \tScore:  0.02481\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: flostinuting \tScore:  0.25212\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: flasteringoe \tScore:  0.09578\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: nficturoning \tScore:  0.06058\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fonscituning \tScore:  0.06058\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: henlacterishing \tScore:  0.03515\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002166321501135826\n",
      "KL_weight:  5.240899999999363e-06 teacher_forcing_ratio:  0.9999947590995664\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100 char-loss:  0.002127590822055936\n",
      "KL_weight:  5.245899999999374e-06 teacher_forcing_ratio:  0.999994754099566\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0019131154986098409\n",
      "KL_weight:  5.250899999999385e-06 teacher_forcing_ratio:  0.9999947490995655\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.001958621433004737\n",
      "KL_weight:  5.255899999999396e-06 teacher_forcing_ratio:  0.9999947440995651\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002047282177954912\n",
      "KL_weight:  5.260899999999407e-06 teacher_forcing_ratio:  0.9999947390995647\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0019713921938091516\n",
      "KL_weight:  5.265899999999418e-06 teacher_forcing_ratio:  0.9999947340995643\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001955669140443206\n",
      "KL_weight:  5.270899999999429e-06 teacher_forcing_ratio:  0.9999947290995639\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0018892987864091992\n",
      "KL_weight:  5.27589999999944e-06 teacher_forcing_ratio:  0.9999947240995635\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0020529108587652445\n",
      "KL_weight:  5.280899999999451e-06 teacher_forcing_ratio:  0.9999947190995631\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0018016514368355274\n",
      "KL_weight:  5.285899999999462e-06 teacher_forcing_ratio:  0.9999947140995626\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0018526436761021614\n",
      "KL_weight:  5.290899999999473e-06 teacher_forcing_ratio:  0.9999947090995622\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0017671652603894472\n",
      "KL_weight:  5.295899999999484e-06 teacher_forcing_ratio:  0.9999947040995618\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.014096519909799099\n",
      "KL_weight:  5.300899999999495e-06 teacher_forcing_ratio:  0.9999946990995614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.018086738884449005\n",
      "KL_weight:  5.305899999999506e-06 teacher_forcing_ratio:  0.999994694099561\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0067098019644618034\n",
      "KL_weight:  5.310899999999517e-06 teacher_forcing_ratio:  0.9999946890995606\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fanswingenting \tScore:  0.03592\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: fasterbeding \tScore:  0.11531\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: festignareing \tScore:  0.04132\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pendermaides \tScore:  0.23462\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  snectiaters \tScore:  0.02666\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   sintarcles \tScore:  0.05612\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  coanceraded \tScore:  0.02481\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fnustifaching \tScore:  0.04494\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  snotifating \tScore:  0.05246\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: chainteralinged \tScore:  0.03324\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0034849178045988083\n",
      "KL_weight:  5.317899999999532e-06 teacher_forcing_ratio:  0.99999468209956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.003315143520012498\n",
      "KL_weight:  5.322899999999543e-06 teacher_forcing_ratio:  0.9999946770995596\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0028895034920424223\n",
      "KL_weight:  5.327899999999554e-06 teacher_forcing_ratio:  0.9999946720995592\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002613762393593788\n",
      "KL_weight:  5.332899999999565e-06 teacher_forcing_ratio:  0.9999946670995588\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002559109590947628\n",
      "KL_weight:  5.337899999999576e-06 teacher_forcing_ratio:  0.9999946620995583\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0027063596062362194\n",
      "KL_weight:  5.342899999999587e-06 teacher_forcing_ratio:  0.9999946570995579\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0023201124276965857\n",
      "KL_weight:  5.347899999999598e-06 teacher_forcing_ratio:  0.9999946520995575\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0020969968754798174\n",
      "KL_weight:  5.352899999999609e-06 teacher_forcing_ratio:  0.9999946470995571\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002299532061442733\n",
      "KL_weight:  5.35789999999962e-06 teacher_forcing_ratio:  0.9999946420995567\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002223594579845667\n",
      "KL_weight:  5.362899999999631e-06 teacher_forcing_ratio:  0.9999946370995563\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002952299080789089\n",
      "KL_weight:  5.367899999999642e-06 teacher_forcing_ratio:  0.9999946320995559\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0023892559111118317\n",
      "KL_weight:  5.3728999999996526e-06 teacher_forcing_ratio:  0.9999946270995554\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0023535224609076977\n",
      "KL_weight:  5.3778999999996635e-06 teacher_forcing_ratio:  0.999994622099555\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0023333532735705376\n",
      "KL_weight:  5.3828999999996745e-06 teacher_forcing_ratio:  0.9999946170995546\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0022346130572259426\n",
      "KL_weight:  5.3878999999996854e-06 teacher_forcing_ratio:  0.9999946120995542\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fadconalizing \tScore:  0.04324\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   festabring \tScore:  0.14287\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: desformining \tScore:  0.04529\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexondersing \tScore:  0.06484\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    stensting \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splittering \tScore:  0.58773\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flarodear \tScore:  0.31560\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: ficturanteding \tScore:  0.04132\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: shachelating \tScore:  0.04529\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0024382546544075012\n",
      "KL_weight:  5.394899999999701e-06 teacher_forcing_ratio:  0.9999946050995536\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021717585623264313\n",
      "KL_weight:  5.399899999999712e-06 teacher_forcing_ratio:  0.9999946000995532\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 150 char-loss:  0.0020962157286703587\n",
      "KL_weight:  5.404899999999723e-06 teacher_forcing_ratio:  0.9999945950995528\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0020247080828994513\n",
      "KL_weight:  5.409899999999734e-06 teacher_forcing_ratio:  0.9999945900995524\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.006510825362056494\n",
      "KL_weight:  5.414899999999745e-06 teacher_forcing_ratio:  0.999994585099552\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.015356350690126419\n",
      "KL_weight:  5.419899999999756e-06 teacher_forcing_ratio:  0.9999945800995516\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.004402891732752323\n",
      "KL_weight:  5.4248999999997666e-06 teacher_forcing_ratio:  0.9999945750995511\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.003308661747723818\n",
      "KL_weight:  5.4298999999997775e-06 teacher_forcing_ratio:  0.9999945700995507\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.003103648778051138\n",
      "KL_weight:  5.4348999999997885e-06 teacher_forcing_ratio:  0.9999945650995503\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0027381540276110172\n",
      "KL_weight:  5.4398999999997995e-06 teacher_forcing_ratio:  0.9999945600995499\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0025015652645379305\n",
      "KL_weight:  5.4448999999998104e-06 teacher_forcing_ratio:  0.9999945550995495\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002360423095524311\n",
      "KL_weight:  5.449899999999821e-06 teacher_forcing_ratio:  0.9999945500995491\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0023992450442165136\n",
      "KL_weight:  5.454899999999832e-06 teacher_forcing_ratio:  0.9999945450995487\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0022238667588680983\n",
      "KL_weight:  5.459899999999843e-06 teacher_forcing_ratio:  0.9999945400995482\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0023689381778240204\n",
      "KL_weight:  5.464899999999854e-06 teacher_forcing_ratio:  0.9999945350995478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: faschoranking \tScore:  0.04132\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   fasterying \tScore:  0.12422\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  jembinysing \tScore:  0.05246\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexperdaning \tScore:  0.23462\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sentaryings \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splittering \tScore:  0.58773\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flasterared \tScore:  0.14991\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionaping \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionatizing \tScore:  0.47587\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: shachelating \tScore:  0.04529\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0027627130039036274\n",
      "KL_weight:  5.47189999999987e-06 teacher_forcing_ratio:  0.9999945280995473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002196445595473051\n",
      "KL_weight:  5.476899999999881e-06 teacher_forcing_ratio:  0.9999945230995468\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0029955084901303053\n",
      "KL_weight:  5.4818999999998916e-06 teacher_forcing_ratio:  0.9999945180995464\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.003338571870699525\n",
      "KL_weight:  5.4868999999999025e-06 teacher_forcing_ratio:  0.999994513099546\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0027752036694437265\n",
      "KL_weight:  5.4918999999999135e-06 teacher_forcing_ratio:  0.9999945080995456\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0032409599516540766\n",
      "KL_weight:  5.4968999999999244e-06 teacher_forcing_ratio:  0.9999945030995452\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002552543068304658\n",
      "KL_weight:  5.501899999999935e-06 teacher_forcing_ratio:  0.9999944980995448\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0022596048656851053\n",
      "KL_weight:  5.506899999999946e-06 teacher_forcing_ratio:  0.9999944930995444\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0022211086470633745\n",
      "KL_weight:  5.511899999999957e-06 teacher_forcing_ratio:  0.9999944880995439\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0022432783152908087\n",
      "KL_weight:  5.516899999999968e-06 teacher_forcing_ratio:  0.9999944830995435\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002400376135483384\n",
      "KL_weight:  5.521899999999979e-06 teacher_forcing_ratio:  0.9999944780995431\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0022113672457635403\n",
      "KL_weight:  5.52689999999999e-06 teacher_forcing_ratio:  0.9999944730995427\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002028156304731965\n",
      "KL_weight:  5.531900000000001e-06 teacher_forcing_ratio:  0.9999944680995423\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0020520153921097517\n",
      "KL_weight:  5.536900000000012e-06 teacher_forcing_ratio:  0.9999944630995419\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0019700336270034313\n",
      "KL_weight:  5.541900000000023e-06 teacher_forcing_ratio:  0.9999944580995415\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  fadonysaing \tScore:  0.11095\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   fabstering \tScore:  0.14287\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: jefistouring \tScore:  0.04529\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    pexonders \tScore:  0.09129\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict: sconsertaing \tScore:  0.04284\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: smistrapling \tScore:  0.15235\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flasterding \tScore:  0.10600\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: convisteranying \tScore:  0.03679\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionapishin \tScore:  0.47587\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: shachelating \tScore:  0.04529\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002165533136576414\n",
      "KL_weight:  5.5489000000000385e-06 teacher_forcing_ratio:  0.9999944510995409\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00201422069221735\n",
      "KL_weight:  5.5539000000000494e-06 teacher_forcing_ratio:  0.9999944460995405\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0019236891530454159\n",
      "KL_weight:  5.55890000000006e-06 teacher_forcing_ratio:  0.99999444109954\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.001953527331352234\n",
      "KL_weight:  5.563900000000071e-06 teacher_forcing_ratio:  0.9999944360995396\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0018735404592007399\n",
      "KL_weight:  5.568900000000082e-06 teacher_forcing_ratio:  0.9999944310995392\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0020087547600269318\n",
      "KL_weight:  5.573900000000093e-06 teacher_forcing_ratio:  0.9999944260995388\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0018464180175215006\n",
      "KL_weight:  5.578900000000104e-06 teacher_forcing_ratio:  0.9999944210995384\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0017986230086535215\n",
      "KL_weight:  5.583900000000115e-06 teacher_forcing_ratio:  0.999994416099538\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0017601638101041317\n",
      "KL_weight:  5.588900000000126e-06 teacher_forcing_ratio:  0.9999944110995376\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.008948935195803642\n",
      "KL_weight:  5.593900000000137e-06 teacher_forcing_ratio:  0.9999944060995372\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.01393392775207758\n",
      "KL_weight:  5.598900000000148e-06 teacher_forcing_ratio:  0.9999944010995367\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.009118067100644112\n",
      "KL_weight:  5.603900000000159e-06 teacher_forcing_ratio:  0.9999943960995363\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0037378096021711826\n",
      "KL_weight:  5.60890000000017e-06 teacher_forcing_ratio:  0.9999943910995359\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.003484918735921383\n",
      "KL_weight:  5.613900000000181e-06 teacher_forcing_ratio:  0.9999943860995355\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0029802811332046986\n",
      "KL_weight:  5.618900000000192e-06 teacher_forcing_ratio:  0.9999943810995351\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    fadonized \tScore:  0.15620\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   festarying \tScore:  0.12422\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   jeffisting \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pexconseds \tScore:  0.08034\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sminserting \tScore:  0.04741\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  smistreping \tScore:  0.11531\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   disprealen \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: focunsidating \tScore:  0.05526\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: confisturing \tScore:  0.05094\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  sealhousing \tScore:  0.10600\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002924695611000061\n",
      "KL_weight:  5.625900000000207e-06 teacher_forcing_ratio:  0.9999943740995345\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002749745501205325\n",
      "KL_weight:  5.630900000000218e-06 teacher_forcing_ratio:  0.9999943690995341\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0025553980376571417\n",
      "KL_weight:  5.635900000000229e-06 teacher_forcing_ratio:  0.9999943640995337\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002905050525441766\n",
      "KL_weight:  5.64090000000024e-06 teacher_forcing_ratio:  0.9999943590995333\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.003001714590936899\n",
      "KL_weight:  5.645900000000251e-06 teacher_forcing_ratio:  0.9999943540995329\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0027599248569458723\n",
      "KL_weight:  5.650900000000262e-06 teacher_forcing_ratio:  0.9999943490995324\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0026309287641197443\n",
      "KL_weight:  5.655900000000273e-06 teacher_forcing_ratio:  0.999994344099532\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0023798744659870863\n",
      "KL_weight:  5.660900000000284e-06 teacher_forcing_ratio:  0.9999943390995316\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002301687840372324\n",
      "KL_weight:  5.665900000000295e-06 teacher_forcing_ratio:  0.9999943340995312\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0022034752182662487\n",
      "KL_weight:  5.670900000000306e-06 teacher_forcing_ratio:  0.9999943290995308\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0027516467962414026\n",
      "KL_weight:  5.675900000000317e-06 teacher_forcing_ratio:  0.9999943240995304\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0025714437942951918\n",
      "KL_weight:  5.680900000000328e-06 teacher_forcing_ratio:  0.99999431909953\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0024508624337613583\n",
      "KL_weight:  5.685900000000339e-06 teacher_forcing_ratio:  0.9999943140995295\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0022492646239697933\n",
      "KL_weight:  5.69090000000035e-06 teacher_forcing_ratio:  0.9999943090995291\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002205607481300831\n",
      "KL_weight:  5.695900000000361e-06 teacher_forcing_ratio:  0.9999943040995287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: coandalashing \tScore:  0.09145\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  disebarling \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  fessignuing \tScore:  0.05013\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  pexsondests \tScore:  0.07176\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    smentisfy \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  smispreding \tScore:  0.12278\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: flasperacing \tScore:  0.09578\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: confustinating \tScore:  0.05622\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funcostinating \tScore:  0.22719\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: meschaigning \tScore:  0.02409\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002171265659853816\n",
      "KL_weight:  5.702900000000376e-06 teacher_forcing_ratio:  0.9999942970995281\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021784137934446335\n",
      "KL_weight:  5.707900000000387e-06 teacher_forcing_ratio:  0.9999942920995277\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0020791376009583473\n",
      "KL_weight:  5.712900000000398e-06 teacher_forcing_ratio:  0.9999942870995273\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0020321726333349943\n",
      "KL_weight:  5.717900000000409e-06 teacher_forcing_ratio:  0.9999942820995269\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 250 char-loss:  0.0019933790899813175\n",
      "KL_weight:  5.72290000000042e-06 teacher_forcing_ratio:  0.9999942770995265\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0019550565630197525\n",
      "KL_weight:  5.727900000000431e-06 teacher_forcing_ratio:  0.9999942720995261\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.001905418699607253\n",
      "KL_weight:  5.732900000000442e-06 teacher_forcing_ratio:  0.9999942670995257\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.001956136664375663\n",
      "KL_weight:  5.737900000000453e-06 teacher_forcing_ratio:  0.9999942620995252\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0018433962250128388\n",
      "KL_weight:  5.742900000000464e-06 teacher_forcing_ratio:  0.9999942570995248\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002060968428850174\n",
      "KL_weight:  5.747900000000475e-06 teacher_forcing_ratio:  0.9999942520995244\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.03383317589759827\n",
      "KL_weight:  5.752900000000486e-06 teacher_forcing_ratio:  0.999994247099524\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.008066372945904732\n",
      "KL_weight:  5.757900000000497e-06 teacher_forcing_ratio:  0.9999942420995236\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.004844246432185173\n",
      "KL_weight:  5.762900000000508e-06 teacher_forcing_ratio:  0.9999942370995232\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.005271979607641697\n",
      "KL_weight:  5.767900000000519e-06 teacher_forcing_ratio:  0.9999942320995228\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0035690783988684416\n",
      "KL_weight:  5.77290000000053e-06 teacher_forcing_ratio:  0.9999942270995223\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  dasfonasing \tScore:  0.05246\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  fasterizing \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  besfignying \tScore:  0.06239\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: depercespsing \tScore:  0.04324\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   stescounts \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  smirlipting \tScore:  0.29982\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  scarbelinge \tScore:  0.04741\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionapishin \tScore:  0.47587\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: consiftinueding \tScore:  0.05501\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  schearinged \tScore:  0.10025\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0028171781450510025\n",
      "KL_weight:  5.779900000000545e-06 teacher_forcing_ratio:  0.9999942200995218\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002684160368517041\n",
      "KL_weight:  5.784900000000556e-06 teacher_forcing_ratio:  0.9999942150995214\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002417377894744277\n",
      "KL_weight:  5.789900000000567e-06 teacher_forcing_ratio:  0.9999942100995209\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0023744129575788975\n",
      "KL_weight:  5.794900000000578e-06 teacher_forcing_ratio:  0.9999942050995205\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002312291879206896\n",
      "KL_weight:  5.799900000000589e-06 teacher_forcing_ratio:  0.9999942000995201\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002394134644418955\n",
      "KL_weight:  5.8049000000006e-06 teacher_forcing_ratio:  0.9999941950995197\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0021741942036896944\n",
      "KL_weight:  5.809900000000611e-06 teacher_forcing_ratio:  0.9999941900995193\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0021906618494540453\n",
      "KL_weight:  5.814900000000622e-06 teacher_forcing_ratio:  0.9999941850995189\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0023538225796073675\n",
      "KL_weight:  5.819900000000633e-06 teacher_forcing_ratio:  0.9999941800995185\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0022787933703511953\n",
      "KL_weight:  5.824900000000644e-06 teacher_forcing_ratio:  0.999994175099518\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00210018502548337\n",
      "KL_weight:  5.829900000000655e-06 teacher_forcing_ratio:  0.9999941700995176\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0021173295099288225\n",
      "KL_weight:  5.834900000000666e-06 teacher_forcing_ratio:  0.9999941650995172\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.001996424049139023\n",
      "KL_weight:  5.8399000000006765e-06 teacher_forcing_ratio:  0.9999941600995168\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0020077982917428017\n",
      "KL_weight:  5.8449000000006875e-06 teacher_forcing_ratio:  0.9999941550995164\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002088085748255253\n",
      "KL_weight:  5.8499000000006985e-06 teacher_forcing_ratio:  0.999994150099516\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fastranceding \tScore:  0.05142\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  festabiting \tScore:  0.29982\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  fessignated \tScore:  0.02819\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     deplerks \tScore:  0.04154\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  smistendure \tScore:  0.10600\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  slispotsing \tScore:  0.14178\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flasperide \tScore:  0.11868\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: consuftianging \tScore:  0.05080\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fincountiswing \tScore:  0.05622\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: cheashinates \tScore:  0.09059\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0022204024717211723\n",
      "KL_weight:  5.856900000000714e-06 teacher_forcing_ratio:  0.9999941430995154\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00195775437168777\n",
      "KL_weight:  5.861900000000725e-06 teacher_forcing_ratio:  0.999994138099515\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0019681421108543873\n",
      "KL_weight:  5.866900000000736e-06 teacher_forcing_ratio:  0.9999941330995146\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0021667799446731806\n",
      "KL_weight:  5.871900000000747e-06 teacher_forcing_ratio:  0.9999941280995142\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0020572480279952288\n",
      "KL_weight:  5.876900000000758e-06 teacher_forcing_ratio:  0.9999941230995137\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 300 char-loss:  0.0018044820753857493\n",
      "KL_weight:  5.881900000000769e-06 teacher_forcing_ratio:  0.9999941180995133\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0018603448988869786\n",
      "KL_weight:  5.88690000000078e-06 teacher_forcing_ratio:  0.9999941130995129\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0017959423130378127\n",
      "KL_weight:  5.8919000000007906e-06 teacher_forcing_ratio:  0.9999941080995125\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0018657669425010681\n",
      "KL_weight:  5.8969000000008015e-06 teacher_forcing_ratio:  0.9999941030995121\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0032377210445702076\n",
      "KL_weight:  5.9019000000008125e-06 teacher_forcing_ratio:  0.9999940980995117\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0021290264558047056\n",
      "KL_weight:  5.9069000000008235e-06 teacher_forcing_ratio:  0.9999940930995113\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.011246566660702229\n",
      "KL_weight:  5.9119000000008344e-06 teacher_forcing_ratio:  0.9999940880995108\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.009093445725739002\n",
      "KL_weight:  5.916900000000845e-06 teacher_forcing_ratio:  0.9999940830995104\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.012807869352400303\n",
      "KL_weight:  5.921900000000856e-06 teacher_forcing_ratio:  0.99999407809951\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0045814476907253265\n",
      "KL_weight:  5.926900000000867e-06 teacher_forcing_ratio:  0.9999940730995096\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: doanfolasting \tScore:  0.05142\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    festaying \tScore:  0.14114\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  jestounding \tScore:  0.05013\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   penderates \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snetrated \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  sntirleming \tScore:  0.12761\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: flasteraching \tScore:  0.08737\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: confuttening \tScore:  0.06058\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: confuttizing \tScore:  0.06704\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   cheaduling \tScore:  0.11224\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.003662898438051343\n",
      "KL_weight:  5.933900000000883e-06 teacher_forcing_ratio:  0.999994066099509\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0038655234966427088\n",
      "KL_weight:  5.938900000000894e-06 teacher_forcing_ratio:  0.9999940610995086\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0032808836549520493\n",
      "KL_weight:  5.943900000000905e-06 teacher_forcing_ratio:  0.9999940560995082\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002736976370215416\n",
      "KL_weight:  5.9489000000009156e-06 teacher_forcing_ratio:  0.9999940510995078\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002575237536802888\n",
      "KL_weight:  5.9539000000009265e-06 teacher_forcing_ratio:  0.9999940460995074\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002411977620795369\n",
      "KL_weight:  5.9589000000009375e-06 teacher_forcing_ratio:  0.999994041099507\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002656659809872508\n",
      "KL_weight:  5.9639000000009484e-06 teacher_forcing_ratio:  0.9999940360995065\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0024403866846114397\n",
      "KL_weight:  5.968900000000959e-06 teacher_forcing_ratio:  0.9999940310995061\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002564656315371394\n",
      "KL_weight:  5.97390000000097e-06 teacher_forcing_ratio:  0.9999940260995057\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002442756434902549\n",
      "KL_weight:  5.978900000000981e-06 teacher_forcing_ratio:  0.9999940210995053\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0021025114692747593\n",
      "KL_weight:  5.983900000000992e-06 teacher_forcing_ratio:  0.9999940160995049\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002253409940749407\n",
      "KL_weight:  5.988900000001003e-06 teacher_forcing_ratio:  0.9999940110995045\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0022119644563645124\n",
      "KL_weight:  5.993900000001014e-06 teacher_forcing_ratio:  0.9999940060995041\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0020795443560928106\n",
      "KL_weight:  5.998900000001025e-06 teacher_forcing_ratio:  0.9999940010995036\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0021472093649208546\n",
      "KL_weight:  6.003900000001036e-06 teacher_forcing_ratio:  0.9999939960995032\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  doanfasting \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   fasterbing \tScore:  0.12910\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  festurished \tScore:  0.02481\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  deplentings \tScore:  0.05246\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snousters \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   slimpating \tScore:  0.33569\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    firnawere \tScore:  0.06031\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionating \tScore:  0.55937\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  chalingated \tScore:  0.04741\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0020268424414098263\n",
      "KL_weight:  6.0109000000010515e-06 teacher_forcing_ratio:  0.9999939890995027\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002118863631039858\n",
      "KL_weight:  6.0159000000010625e-06 teacher_forcing_ratio:  0.9999939840995022\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002283951500430703\n",
      "KL_weight:  6.0209000000010734e-06 teacher_forcing_ratio:  0.9999939790995018\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0022960403002798557\n",
      "KL_weight:  6.025900000001084e-06 teacher_forcing_ratio:  0.9999939740995014\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0021925470791757107\n",
      "KL_weight:  6.030900000001095e-06 teacher_forcing_ratio:  0.999993969099501\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0021300390362739563\n",
      "KL_weight:  6.035900000001106e-06 teacher_forcing_ratio:  0.9999939640995006\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.001957640750333667\n",
      "KL_weight:  6.040900000001117e-06 teacher_forcing_ratio:  0.9999939590995002\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002123495563864708\n",
      "KL_weight:  6.045900000001128e-06 teacher_forcing_ratio:  0.9999939540994998\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.00214059348218143\n",
      "KL_weight:  6.050900000001139e-06 teacher_forcing_ratio:  0.9999939490994993\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0019078508485108614\n",
      "KL_weight:  6.05590000000115e-06 teacher_forcing_ratio:  0.9999939440994989\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0017784475348889828\n",
      "KL_weight:  6.060900000001161e-06 teacher_forcing_ratio:  0.9999939390994985\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002224211348220706\n",
      "KL_weight:  6.065900000001172e-06 teacher_forcing_ratio:  0.9999939340994981\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002027371432632208\n",
      "KL_weight:  6.070900000001183e-06 teacher_forcing_ratio:  0.9999939290994977\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0019345467444509268\n",
      "KL_weight:  6.075900000001194e-06 teacher_forcing_ratio:  0.9999939240994973\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.001782609149813652\n",
      "KL_weight:  6.080900000001205e-06 teacher_forcing_ratio:  0.9999939190994969\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  fadonsaping \tScore:  0.11095\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   featusting \tScore:  0.30214\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   desightens \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pendelatings \tScore:  0.23462\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snousteres \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    slousting \tScore:  0.33032\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flareshone \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: confustianging \tScore:  0.05622\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: confustianging \tScore:  0.05622\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: cheashateling \tScore:  0.08737\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.00200884067453444\n",
      "KL_weight:  6.08790000000122e-06 teacher_forcing_ratio:  0.9999939120994963\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.009508658200502396\n",
      "KL_weight:  6.092900000001231e-06 teacher_forcing_ratio:  0.9999939070994959\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.010688099078834057\n",
      "KL_weight:  6.097900000001242e-06 teacher_forcing_ratio:  0.9999939020994955\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.009542755782604218\n",
      "KL_weight:  6.102900000001253e-06 teacher_forcing_ratio:  0.999993897099495\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.004379293881356716\n",
      "KL_weight:  6.107900000001264e-06 teacher_forcing_ratio:  0.9999938920994946\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00403639255091548\n",
      "KL_weight:  6.112900000001275e-06 teacher_forcing_ratio:  0.9999938870994942\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.003729958785697818\n",
      "KL_weight:  6.117900000001286e-06 teacher_forcing_ratio:  0.9999938820994938\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.003117204178124666\n",
      "KL_weight:  6.122900000001297e-06 teacher_forcing_ratio:  0.9999938770994934\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0027465985622256994\n",
      "KL_weight:  6.127900000001308e-06 teacher_forcing_ratio:  0.999993872099493\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0028049247339367867\n",
      "KL_weight:  6.132900000001319e-06 teacher_forcing_ratio:  0.9999938670994926\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002984281163662672\n",
      "KL_weight:  6.13790000000133e-06 teacher_forcing_ratio:  0.9999938620994921\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002591135445982218\n",
      "KL_weight:  6.142900000001341e-06 teacher_forcing_ratio:  0.9999938570994917\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0025571587029844522\n",
      "KL_weight:  6.147900000001352e-06 teacher_forcing_ratio:  0.9999938520994913\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0026035404298454523\n",
      "KL_weight:  6.152900000001363e-06 teacher_forcing_ratio:  0.9999938470994909\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.00279027852229774\n",
      "KL_weight:  6.157900000001374e-06 teacher_forcing_ratio:  0.9999938420994905\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   desaroking \tScore:  0.03156\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     jabertes \tScore:  0.14772\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   bestirming \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   depuresing \tScore:  0.03303\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      stersun \tScore:  0.04671\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     splister \tScore:  0.32260\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   florsesing \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   consifting \tScore:  0.07260\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   consifting \tScore:  0.07260\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     cheaster \tScore:  0.14772\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0026343590579926968\n",
      "KL_weight:  6.164900000001389e-06 teacher_forcing_ratio:  0.9999938350994899\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0024283798411488533\n",
      "KL_weight:  6.1699000000014e-06 teacher_forcing_ratio:  0.9999938300994895\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002561267465353012\n",
      "KL_weight:  6.174900000001411e-06 teacher_forcing_ratio:  0.9999938250994891\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0024801145773380995\n",
      "KL_weight:  6.179900000001422e-06 teacher_forcing_ratio:  0.9999938200994887\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0027361006941646338\n",
      "KL_weight:  6.184900000001433e-06 teacher_forcing_ratio:  0.9999938150994883\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023330822587013245\n",
      "KL_weight:  6.189900000001444e-06 teacher_forcing_ratio:  0.9999938100994878\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0025231726467609406\n",
      "KL_weight:  6.194900000001455e-06 teacher_forcing_ratio:  0.9999938050994874\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 400 char-loss:  0.0021197262685745955\n",
      "KL_weight:  6.199900000001466e-06 teacher_forcing_ratio:  0.999993800099487\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0022202397231012583\n",
      "KL_weight:  6.204900000001477e-06 teacher_forcing_ratio:  0.9999937950994866\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002100443933159113\n",
      "KL_weight:  6.209900000001488e-06 teacher_forcing_ratio:  0.9999937900994862\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002358711324632168\n",
      "KL_weight:  6.214900000001499e-06 teacher_forcing_ratio:  0.9999937850994858\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0021882718428969383\n",
      "KL_weight:  6.21990000000151e-06 teacher_forcing_ratio:  0.9999937800994854\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002751940628513694\n",
      "KL_weight:  6.224900000001521e-06 teacher_forcing_ratio:  0.999993775099485\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0024723531678318977\n",
      "KL_weight:  6.229900000001532e-06 teacher_forcing_ratio:  0.9999937700994845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0023501922842115164\n",
      "KL_weight:  6.234900000001543e-06 teacher_forcing_ratio:  0.9999937650994841\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   macydening \tScore:  0.03156\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   cobstering \tScore:  0.12422\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     jersting \tScore:  0.07386\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      despore \tScore:  0.04939\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sterming \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     spirting \tScore:  0.37708\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  lisopresent \tScore:  0.04412\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  considuting \tScore:  0.06484\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    consifter \tScore:  0.06207\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    chershing \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.004659878555685282\n",
      "KL_weight:  6.241900000001558e-06 teacher_forcing_ratio:  0.9999937580994835\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0035775559954345226\n",
      "KL_weight:  6.246900000001569e-06 teacher_forcing_ratio:  0.9999937530994831\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.004345185123383999\n",
      "KL_weight:  6.25190000000158e-06 teacher_forcing_ratio:  0.9999937480994827\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.014079400338232517\n",
      "KL_weight:  6.256900000001591e-06 teacher_forcing_ratio:  0.9999937430994823\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0035879015922546387\n",
      "KL_weight:  6.261900000001602e-06 teacher_forcing_ratio:  0.9999937380994819\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0034904764033854008\n",
      "KL_weight:  6.266900000001613e-06 teacher_forcing_ratio:  0.9999937330994815\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0028041861951351166\n",
      "KL_weight:  6.271900000001624e-06 teacher_forcing_ratio:  0.9999937280994811\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0027174283750355244\n",
      "KL_weight:  6.276900000001635e-06 teacher_forcing_ratio:  0.9999937230994806\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.003034926252439618\n",
      "KL_weight:  6.281900000001646e-06 teacher_forcing_ratio:  0.9999937180994802\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0024068180937319994\n",
      "KL_weight:  6.286900000001657e-06 teacher_forcing_ratio:  0.9999937130994798\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002464028773829341\n",
      "KL_weight:  6.291900000001668e-06 teacher_forcing_ratio:  0.9999937080994794\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0024071671068668365\n",
      "KL_weight:  6.296900000001679e-06 teacher_forcing_ratio:  0.999993703099479\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0022906644735485315\n",
      "KL_weight:  6.30190000000169e-06 teacher_forcing_ratio:  0.9999936980994786\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0022561289370059967\n",
      "KL_weight:  6.3069000000017005e-06 teacher_forcing_ratio:  0.9999936930994782\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0020947803277522326\n",
      "KL_weight:  6.3119000000017115e-06 teacher_forcing_ratio:  0.9999936880994778\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   manderying \tScore:  0.11868\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      ferbast \tScore:  0.04050\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      destize \tScore:  0.04347\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      desping \tScore:  0.04939\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      smerted \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:       mplist \tScore:  0.13924\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flosser \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: mickersponting \tScore:  0.04728\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    consifter \tScore:  0.06207\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:       kishel \tScore:  0.10267\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0022689809557050467\n",
      "KL_weight:  6.318900000001727e-06 teacher_forcing_ratio:  0.9999936810994772\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021037249825894833\n",
      "KL_weight:  6.323900000001738e-06 teacher_forcing_ratio:  0.9999936760994768\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002064724452793598\n",
      "KL_weight:  6.328900000001749e-06 teacher_forcing_ratio:  0.9999936710994763\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0021026856265962124\n",
      "KL_weight:  6.33390000000176e-06 teacher_forcing_ratio:  0.9999936660994759\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002040894702076912\n",
      "KL_weight:  6.338900000001771e-06 teacher_forcing_ratio:  0.9999936610994755\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002384612802416086\n",
      "KL_weight:  6.343900000001782e-06 teacher_forcing_ratio:  0.9999936560994751\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0022838145960122347\n",
      "KL_weight:  6.348900000001793e-06 teacher_forcing_ratio:  0.9999936510994747\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0022570283617824316\n",
      "KL_weight:  6.353900000001804e-06 teacher_forcing_ratio:  0.9999936460994743\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 450 char-loss:  0.0021594627760350704\n",
      "KL_weight:  6.3589000000018146e-06 teacher_forcing_ratio:  0.9999936410994739\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002003568224608898\n",
      "KL_weight:  6.3639000000018255e-06 teacher_forcing_ratio:  0.9999936360994734\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002089823130518198\n",
      "KL_weight:  6.3689000000018365e-06 teacher_forcing_ratio:  0.999993631099473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0020657540298998356\n",
      "KL_weight:  6.3739000000018475e-06 teacher_forcing_ratio:  0.9999936260994726\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0021961454767733812\n",
      "KL_weight:  6.378900000001858e-06 teacher_forcing_ratio:  0.9999936210994722\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0021540208254009485\n",
      "KL_weight:  6.383900000001869e-06 teacher_forcing_ratio:  0.9999936160994718\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.004572742618620396\n",
      "KL_weight:  6.38890000000188e-06 teacher_forcing_ratio:  0.9999936110994714\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:      faspled \tScore:  0.05809\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     bestared \tScore:  0.06985\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: berispenting \tScore:  0.05638\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   depressing \tScore:  0.03303\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     smerting \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     misprest \tScore:  0.06165\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      floresp \tScore:  0.09879\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   consiprest \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: consipreting \tScore:  0.05859\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     holerish \tScore:  0.03928\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.010984956286847591\n",
      "KL_weight:  6.395900000001896e-06 teacher_forcing_ratio:  0.9999936040994708\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.005893383640795946\n",
      "KL_weight:  6.400900000001907e-06 teacher_forcing_ratio:  0.9999935990994704\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0035358895547688007\n",
      "KL_weight:  6.405900000001918e-06 teacher_forcing_ratio:  0.99999359409947\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0032499295193701982\n",
      "KL_weight:  6.410900000001929e-06 teacher_forcing_ratio:  0.9999935890994696\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0031874754931777716\n",
      "KL_weight:  6.4159000000019396e-06 teacher_forcing_ratio:  0.9999935840994691\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00281959748826921\n",
      "KL_weight:  6.4209000000019505e-06 teacher_forcing_ratio:  0.9999935790994687\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002769601996988058\n",
      "KL_weight:  6.4259000000019615e-06 teacher_forcing_ratio:  0.9999935740994683\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0026105905417352915\n",
      "KL_weight:  6.4309000000019724e-06 teacher_forcing_ratio:  0.9999935690994679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0024512456730008125\n",
      "KL_weight:  6.435900000001983e-06 teacher_forcing_ratio:  0.9999935640994675\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002615898149088025\n",
      "KL_weight:  6.440900000001994e-06 teacher_forcing_ratio:  0.9999935590994671\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00253803632222116\n",
      "KL_weight:  6.445900000002005e-06 teacher_forcing_ratio:  0.9999935540994667\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0037794075906276703\n",
      "KL_weight:  6.450900000002016e-06 teacher_forcing_ratio:  0.9999935490994663\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0026019720826298\n",
      "KL_weight:  6.455900000002027e-06 teacher_forcing_ratio:  0.9999935440994658\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0024611742701381445\n",
      "KL_weight:  6.460900000002038e-06 teacher_forcing_ratio:  0.9999935390994654\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002427537925541401\n",
      "KL_weight:  6.465900000002049e-06 teacher_forcing_ratio:  0.999993534099465\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    counglade \tScore:  0.03586\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  chaberisted \tScore:  0.10600\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:        jerks \tScore:  0.05231\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     perdused \tScore:  0.07386\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     misspend \tScore:  0.15620\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      misplot \tScore:  0.13959\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flosser \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  clisponting \tScore:  0.06239\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  clispanting \tScore:  0.05013\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    holeching \tScore:  0.03156\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0021834231447428465\n",
      "KL_weight:  6.4729000000020645e-06 teacher_forcing_ratio:  0.9999935270994644\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0023323397617787123\n",
      "KL_weight:  6.4779000000020755e-06 teacher_forcing_ratio:  0.999993522099464\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0021325370762497187\n",
      "KL_weight:  6.4829000000020865e-06 teacher_forcing_ratio:  0.9999935170994636\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0023228321224451065\n",
      "KL_weight:  6.4879000000020974e-06 teacher_forcing_ratio:  0.9999935120994632\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0021933158859610558\n",
      "KL_weight:  6.492900000002108e-06 teacher_forcing_ratio:  0.9999935070994628\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.003484051674604416\n",
      "KL_weight:  6.497900000002119e-06 teacher_forcing_ratio:  0.9999935020994624\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.01060230378061533\n",
      "KL_weight:  6.50290000000213e-06 teacher_forcing_ratio:  0.999993497099462\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.009560797363519669\n",
      "KL_weight:  6.507900000002141e-06 teacher_forcing_ratio:  0.9999934920994615\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.006044360809028149\n",
      "KL_weight:  6.512900000002152e-06 teacher_forcing_ratio:  0.9999934870994611\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500 char-loss:  0.0032737795263528824\n",
      "KL_weight:  6.517900000002163e-06 teacher_forcing_ratio:  0.9999934820994607\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002711266279220581\n",
      "KL_weight:  6.522900000002174e-06 teacher_forcing_ratio:  0.9999934770994603\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002715082373470068\n",
      "KL_weight:  6.527900000002185e-06 teacher_forcing_ratio:  0.9999934720994599\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002634297125041485\n",
      "KL_weight:  6.532900000002196e-06 teacher_forcing_ratio:  0.9999934670994595\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0025461181066930294\n",
      "KL_weight:  6.537900000002207e-06 teacher_forcing_ratio:  0.999993462099459\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.002406613901257515\n",
      "KL_weight:  6.542900000002218e-06 teacher_forcing_ratio:  0.9999934570994586\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  dealemposed \tScore:  0.05013\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     bestayed \tScore:  0.06985\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      merduse \tScore:  0.03928\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      pexched \tScore:  0.10446\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:       misser \tScore:  0.09554\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    misprying \tScore:  0.15620\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       jaster \tScore:  0.05373\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    clunsited \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fickrespling \tScore:  0.02547\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      hercled \tScore:  0.07731\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002390874084085226\n",
      "KL_weight:  6.549900000002233e-06 teacher_forcing_ratio:  0.9999934500994581\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0024771851021796465\n",
      "KL_weight:  6.554900000002244e-06 teacher_forcing_ratio:  0.9999934450994576\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0025243451818823814\n",
      "KL_weight:  6.559900000002255e-06 teacher_forcing_ratio:  0.9999934400994572\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002940058009698987\n",
      "KL_weight:  6.564900000002266e-06 teacher_forcing_ratio:  0.9999934350994568\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002729566302150488\n",
      "KL_weight:  6.569900000002277e-06 teacher_forcing_ratio:  0.9999934300994564\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0026148457545787096\n",
      "KL_weight:  6.574900000002288e-06 teacher_forcing_ratio:  0.999993425099456\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0023177731782197952\n",
      "KL_weight:  6.579900000002299e-06 teacher_forcing_ratio:  0.9999934200994556\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002279316307976842\n",
      "KL_weight:  6.58490000000231e-06 teacher_forcing_ratio:  0.9999934150994552\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002352129202336073\n",
      "KL_weight:  6.589900000002321e-06 teacher_forcing_ratio:  0.9999934100994547\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0020398269407451153\n",
      "KL_weight:  6.594900000002332e-06 teacher_forcing_ratio:  0.9999934050994543\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0021590581163764\n",
      "KL_weight:  6.599900000002343e-06 teacher_forcing_ratio:  0.9999934000994539\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002222104463726282\n",
      "KL_weight:  6.604900000002354e-06 teacher_forcing_ratio:  0.9999933950994535\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002108553424477577\n",
      "KL_weight:  6.609900000002365e-06 teacher_forcing_ratio:  0.9999933900994531\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0019431505352258682\n",
      "KL_weight:  6.614900000002376e-06 teacher_forcing_ratio:  0.9999933850994527\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.01304512657225132\n",
      "KL_weight:  6.619900000002387e-06 teacher_forcing_ratio:  0.9999933800994523\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    parolized \tScore:  0.06031\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    cheastray \tScore:  0.03156\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      bredize \tScore:  0.04347\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexstranying \tScore:  0.05386\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   missenting \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    misrypled \tScore:  0.06031\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flouser \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     clingued \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:      chinfer \tScore:  0.03218\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     herching \tScore:  0.05874\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.01006023958325386\n",
      "KL_weight:  6.626900000002402e-06 teacher_forcing_ratio:  0.9999933730994517\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.006494020111858845\n",
      "KL_weight:  6.631900000002413e-06 teacher_forcing_ratio:  0.9999933680994513\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.006918853148818016\n",
      "KL_weight:  6.636900000002424e-06 teacher_forcing_ratio:  0.9999933630994509\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.003258817596361041\n",
      "KL_weight:  6.641900000002435e-06 teacher_forcing_ratio:  0.9999933580994504\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.004452123306691647\n",
      "KL_weight:  6.646900000002446e-06 teacher_forcing_ratio:  0.99999335309945\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0030424133874475956\n",
      "KL_weight:  6.651900000002457e-06 teacher_forcing_ratio:  0.9999933480994496\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0030074981041252613\n",
      "KL_weight:  6.656900000002468e-06 teacher_forcing_ratio:  0.9999933430994492\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.003068231511861086\n",
      "KL_weight:  6.661900000002479e-06 teacher_forcing_ratio:  0.9999933380994488\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0027381563559174538\n",
      "KL_weight:  6.66690000000249e-06 teacher_forcing_ratio:  0.9999933330994484\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0027145463973283768\n",
      "KL_weight:  6.671900000002501e-06 teacher_forcing_ratio:  0.999993328099448\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 550 char-loss:  0.002579387277364731\n",
      "KL_weight:  6.676900000002512e-06 teacher_forcing_ratio:  0.9999933230994476\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002467990852892399\n",
      "KL_weight:  6.681900000002523e-06 teacher_forcing_ratio:  0.9999933180994471\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0023771387059241533\n",
      "KL_weight:  6.686900000002534e-06 teacher_forcing_ratio:  0.9999933130994467\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002345508662983775\n",
      "KL_weight:  6.691900000002545e-06 teacher_forcing_ratio:  0.9999933080994463\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0026102191768586636\n",
      "KL_weight:  6.696900000002556e-06 teacher_forcing_ratio:  0.9999933030994459\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     disenble \tScore:  0.03467\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    mayerting \tScore:  0.33032\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   serjoyring \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      perdise \tScore:  0.08784\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sminery \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splidering \tScore:  0.37992\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      jloster \tScore:  0.04347\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    consulied \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   consulited \tScore:  0.07506\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: misrelenying \tScore:  0.02242\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0024247891269624233\n",
      "KL_weight:  6.703900000002571e-06 teacher_forcing_ratio:  0.9999932960994453\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002406622748821974\n",
      "KL_weight:  6.708900000002582e-06 teacher_forcing_ratio:  0.9999932910994449\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.00223881215788424\n",
      "KL_weight:  6.713900000002593e-06 teacher_forcing_ratio:  0.9999932860994445\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002212763298302889\n",
      "KL_weight:  6.718900000002604e-06 teacher_forcing_ratio:  0.9999932810994441\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0022590244188904762\n",
      "KL_weight:  6.723900000002615e-06 teacher_forcing_ratio:  0.9999932760994437\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0022990533616393805\n",
      "KL_weight:  6.728900000002626e-06 teacher_forcing_ratio:  0.9999932710994432\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0022184597328305244\n",
      "KL_weight:  6.733900000002637e-06 teacher_forcing_ratio:  0.9999932660994428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0021444191224873066\n",
      "KL_weight:  6.738900000002648e-06 teacher_forcing_ratio:  0.9999932610994424\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0022859361488372087\n",
      "KL_weight:  6.743900000002659e-06 teacher_forcing_ratio:  0.999993256099442\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002251953352242708\n",
      "KL_weight:  6.74890000000267e-06 teacher_forcing_ratio:  0.9999932510994416\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.020568080246448517\n",
      "KL_weight:  6.753900000002681e-06 teacher_forcing_ratio:  0.9999932460994412\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.003808530978858471\n",
      "KL_weight:  6.758900000002692e-06 teacher_forcing_ratio:  0.9999932410994408\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.010981624014675617\n",
      "KL_weight:  6.763900000002703e-06 teacher_forcing_ratio:  0.9999932360994404\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0029570069164037704\n",
      "KL_weight:  6.768900000002714e-06 teacher_forcing_ratio:  0.9999932310994399\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0031009020749479532\n",
      "KL_weight:  6.7739000000027245e-06 teacher_forcing_ratio:  0.9999932260994395\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:      dauster \tScore:  0.03267\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:       jaster \tScore:  0.03850\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:       mersed \tScore:  0.04855\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      depures \tScore:  0.04939\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      smister \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      splider \tScore:  0.30896\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     jarested \tScore:  0.13747\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  consuterish \tScore:  0.05246\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    cutserked \tScore:  0.05706\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    misrepled \tScore:  0.03156\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0027975603006780148\n",
      "KL_weight:  6.78090000000274e-06 teacher_forcing_ratio:  0.999993219099439\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0028899074532091618\n",
      "KL_weight:  6.785900000002751e-06 teacher_forcing_ratio:  0.9999932140994385\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0025643487460911274\n",
      "KL_weight:  6.790900000002762e-06 teacher_forcing_ratio:  0.9999932090994381\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0024851765483617783\n",
      "KL_weight:  6.795900000002773e-06 teacher_forcing_ratio:  0.9999932040994377\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002366132801398635\n",
      "KL_weight:  6.800900000002784e-06 teacher_forcing_ratio:  0.9999931990994373\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0024908939376473427\n",
      "KL_weight:  6.805900000002795e-06 teacher_forcing_ratio:  0.9999931940994369\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002325457287952304\n",
      "KL_weight:  6.810900000002806e-06 teacher_forcing_ratio:  0.9999931890994365\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0023289495147764683\n",
      "KL_weight:  6.815900000002817e-06 teacher_forcing_ratio:  0.999993184099436\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002243436872959137\n",
      "KL_weight:  6.820900000002828e-06 teacher_forcing_ratio:  0.9999931790994356\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002213976113125682\n",
      "KL_weight:  6.8259000000028386e-06 teacher_forcing_ratio:  0.9999931740994352\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002204081043601036\n",
      "KL_weight:  6.8309000000028495e-06 teacher_forcing_ratio:  0.9999931690994348\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 600 char-loss:  0.0020943800918757915\n",
      "KL_weight:  6.8359000000028605e-06 teacher_forcing_ratio:  0.9999931640994344\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0020046283025294542\n",
      "KL_weight:  6.8409000000028715e-06 teacher_forcing_ratio:  0.999993159099434\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.003090586746111512\n",
      "KL_weight:  6.845900000002882e-06 teacher_forcing_ratio:  0.9999931540994336\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0027398860547691584\n",
      "KL_weight:  6.850900000002893e-06 teacher_forcing_ratio:  0.9999931490994332\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    dayplemad \tScore:  0.03586\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    disembary \tScore:  0.03391\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      seround \tScore:  0.04347\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:       desper \tScore:  0.09189\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sminered \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      splider \tScore:  0.30896\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     greslead \tScore:  0.06985\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  consuterize \tScore:  0.05246\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   canstigred \tScore:  0.06985\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     mishered \tScore:  0.06501\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.02377001754939556\n",
      "KL_weight:  6.857900000002909e-06 teacher_forcing_ratio:  0.9999931420994326\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.014191456139087677\n",
      "KL_weight:  6.86290000000292e-06 teacher_forcing_ratio:  0.9999931370994322\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.004729741718620062\n",
      "KL_weight:  6.867900000002931e-06 teacher_forcing_ratio:  0.9999931320994317\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0035747927613556385\n",
      "KL_weight:  6.872900000002942e-06 teacher_forcing_ratio:  0.9999931270994313\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0030235182493925095\n",
      "KL_weight:  6.877900000002953e-06 teacher_forcing_ratio:  0.9999931220994309\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0033999572042375803\n",
      "KL_weight:  6.8829000000029635e-06 teacher_forcing_ratio:  0.9999931170994305\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002763846656307578\n",
      "KL_weight:  6.8879000000029745e-06 teacher_forcing_ratio:  0.9999931120994301\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0030570724047720432\n",
      "KL_weight:  6.8929000000029855e-06 teacher_forcing_ratio:  0.9999931070994297\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002815281506627798\n",
      "KL_weight:  6.8979000000029964e-06 teacher_forcing_ratio:  0.9999931020994293\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0026757228188216686\n",
      "KL_weight:  6.902900000003007e-06 teacher_forcing_ratio:  0.9999930970994289\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0024494677782058716\n",
      "KL_weight:  6.907900000003018e-06 teacher_forcing_ratio:  0.9999930920994284\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.00240027392283082\n",
      "KL_weight:  6.912900000003029e-06 teacher_forcing_ratio:  0.999993087099428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.00244456110522151\n",
      "KL_weight:  6.91790000000304e-06 teacher_forcing_ratio:  0.9999930820994276\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002436724491417408\n",
      "KL_weight:  6.922900000003051e-06 teacher_forcing_ratio:  0.9999930770994272\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0026201927103102207\n",
      "KL_weight:  6.927900000003062e-06 teacher_forcing_ratio:  0.9999930720994268\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     dashiner \tScore:  0.06165\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    jastering \tScore:  0.14114\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     sestured \tScore:  0.03303\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    depherish \tScore:  0.03586\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     smerting \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      splider \tScore:  0.30896\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   maspreying \tScore:  0.04939\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fictersuing \tScore:  0.05246\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    consulted \tScore:  0.07381\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      mashier \tScore:  0.04671\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.002401066478341818\n",
      "KL_weight:  6.9349000000030776e-06 teacher_forcing_ratio:  0.9999930650994262\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021728083956986666\n",
      "KL_weight:  6.9399000000030885e-06 teacher_forcing_ratio:  0.9999930600994258\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002266645198687911\n",
      "KL_weight:  6.9449000000030995e-06 teacher_forcing_ratio:  0.9999930550994254\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0022677150554955006\n",
      "KL_weight:  6.9499000000031105e-06 teacher_forcing_ratio:  0.999993050099425\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0021677620243281126\n",
      "KL_weight:  6.954900000003121e-06 teacher_forcing_ratio:  0.9999930450994245\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.009096987545490265\n",
      "KL_weight:  6.959900000003132e-06 teacher_forcing_ratio:  0.9999930400994241\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.006311260163784027\n",
      "KL_weight:  6.964900000003143e-06 teacher_forcing_ratio:  0.9999930350994237\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.007707501761615276\n",
      "KL_weight:  6.969900000003154e-06 teacher_forcing_ratio:  0.9999930300994233\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.007096525747328997\n",
      "KL_weight:  6.974900000003165e-06 teacher_forcing_ratio:  0.9999930250994229\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.003702628891915083\n",
      "KL_weight:  6.979900000003176e-06 teacher_forcing_ratio:  0.9999930200994225\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0036643920466303825\n",
      "KL_weight:  6.984900000003187e-06 teacher_forcing_ratio:  0.9999930150994221\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0032290960662066936\n",
      "KL_weight:  6.989900000003198e-06 teacher_forcing_ratio:  0.9999930100994217\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 650 char-loss:  0.003035592846572399\n",
      "KL_weight:  6.994900000003209e-06 teacher_forcing_ratio:  0.9999930050994212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0027556479908525944\n",
      "KL_weight:  6.99990000000322e-06 teacher_forcing_ratio:  0.9999930000994208\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.003158897627145052\n",
      "KL_weight:  7.004900000003231e-06 teacher_forcing_ratio:  0.9999929950994204\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   farondused \tScore:  0.07731\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:       festay \tScore:  0.03850\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      seorked \tScore:  0.03928\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:      depures \tScore:  0.04939\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sminery \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     skistred \tScore:  0.03226\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flisher \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     fincured \tScore:  0.07386\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:     fincured \tScore:  0.07441\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      shelted \tScore:  0.08307\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0030607532244175673\n",
      "KL_weight:  7.011900000003246e-06 teacher_forcing_ratio:  0.9999929880994198\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0026668692007660866\n",
      "KL_weight:  7.016900000003257e-06 teacher_forcing_ratio:  0.9999929830994194\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002580521162599325\n",
      "KL_weight:  7.021900000003268e-06 teacher_forcing_ratio:  0.999992978099419\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002488540019840002\n",
      "KL_weight:  7.026900000003279e-06 teacher_forcing_ratio:  0.9999929730994186\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0023886640556156635\n",
      "KL_weight:  7.03190000000329e-06 teacher_forcing_ratio:  0.9999929680994182\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0023483457043766975\n",
      "KL_weight:  7.036900000003301e-06 teacher_forcing_ratio:  0.9999929630994178\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0032903305254876614\n",
      "KL_weight:  7.041900000003312e-06 teacher_forcing_ratio:  0.9999929580994174\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0029417527839541435\n",
      "KL_weight:  7.046900000003323e-06 teacher_forcing_ratio:  0.9999929530994169\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.029782161116600037\n",
      "KL_weight:  7.051900000003334e-06 teacher_forcing_ratio:  0.9999929480994165\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.005571693181991577\n",
      "KL_weight:  7.056900000003345e-06 teacher_forcing_ratio:  0.9999929430994161\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.003749566851183772\n",
      "KL_weight:  7.061900000003356e-06 teacher_forcing_ratio:  0.9999929380994157\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.005113442428410053\n",
      "KL_weight:  7.066900000003367e-06 teacher_forcing_ratio:  0.9999929330994153\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0037364123854786158\n",
      "KL_weight:  7.071900000003378e-06 teacher_forcing_ratio:  0.9999929280994149\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0029876772314310074\n",
      "KL_weight:  7.076900000003389e-06 teacher_forcing_ratio:  0.9999929230994145\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0026426268741488457\n",
      "KL_weight:  7.0819000000034e-06 teacher_forcing_ratio:  0.999992918099414\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  fadmanyingo \tScore:  0.05246\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: fasteridging \tScore:  0.10025\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     jobeding \tScore:  0.08784\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: deppisenting \tScore:  0.04741\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snertisked \tScore:  0.03156\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     skisplit \tScore:  0.47750\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flished \tScore:  0.07731\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fundisching \tScore:  0.11095\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   finchorged \tScore:  0.07260\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     mispeled \tScore:  0.03656\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0025627806317061186\n",
      "KL_weight:  7.088900000003415e-06 teacher_forcing_ratio:  0.9999929110994135\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0024630180560052395\n",
      "KL_weight:  7.093900000003426e-06 teacher_forcing_ratio:  0.999992906099413\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0026137197855859995\n",
      "KL_weight:  7.098900000003437e-06 teacher_forcing_ratio:  0.9999929010994126\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002629133639857173\n",
      "KL_weight:  7.103900000003448e-06 teacher_forcing_ratio:  0.9999928960994122\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0026715907733887434\n",
      "KL_weight:  7.108900000003459e-06 teacher_forcing_ratio:  0.9999928910994118\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002333024051040411\n",
      "KL_weight:  7.11390000000347e-06 teacher_forcing_ratio:  0.9999928860994114\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002531007630750537\n",
      "KL_weight:  7.118900000003481e-06 teacher_forcing_ratio:  0.999992881099411\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0022920488845556974\n",
      "KL_weight:  7.123900000003492e-06 teacher_forcing_ratio:  0.9999928760994106\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002259520348161459\n",
      "KL_weight:  7.128900000003503e-06 teacher_forcing_ratio:  0.9999928710994102\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0023149466142058372\n",
      "KL_weight:  7.133900000003514e-06 teacher_forcing_ratio:  0.9999928660994097\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002134687267243862\n",
      "KL_weight:  7.138900000003525e-06 teacher_forcing_ratio:  0.9999928610994093\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0021958656143397093\n",
      "KL_weight:  7.143900000003536e-06 teacher_forcing_ratio:  0.9999928560994089\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0021668316330760717\n",
      "KL_weight:  7.148900000003547e-06 teacher_forcing_ratio:  0.9999928510994085\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 700 char-loss:  0.0021024313755333424\n",
      "KL_weight:  7.153900000003558e-06 teacher_forcing_ratio:  0.9999928460994081\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0021933354437351227\n",
      "KL_weight:  7.158900000003569e-06 teacher_forcing_ratio:  0.9999928410994077\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  fasploanied \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:      festigh \tScore:  0.07201\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     gespited \tScore:  0.03928\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:     pedigner \tScore:  0.07386\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     smisters \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:      dippres \tScore:  0.03267\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    fladisher \tScore:  0.13485\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   functished \tScore:  0.51697\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   finforsted \tScore:  0.06105\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      misheld \tScore:  0.08307\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0020108292810618877\n",
      "KL_weight:  7.165900000003584e-06 teacher_forcing_ratio:  0.9999928340994071\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0021202629432082176\n",
      "KL_weight:  7.170900000003595e-06 teacher_forcing_ratio:  0.9999928290994067\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.003929647617042065\n",
      "KL_weight:  7.175900000003606e-06 teacher_forcing_ratio:  0.9999928240994063\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.019257113337516785\n",
      "KL_weight:  7.180900000003617e-06 teacher_forcing_ratio:  0.9999928190994058\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.007055795751512051\n",
      "KL_weight:  7.185900000003628e-06 teacher_forcing_ratio:  0.9999928140994054\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0038497834466397762\n",
      "KL_weight:  7.190900000003639e-06 teacher_forcing_ratio:  0.999992809099405\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0037828441709280014\n",
      "KL_weight:  7.19590000000365e-06 teacher_forcing_ratio:  0.9999928040994046\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0032039396464824677\n",
      "KL_weight:  7.200900000003661e-06 teacher_forcing_ratio:  0.9999927990994042\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0029533863998949528\n",
      "KL_weight:  7.205900000003672e-06 teacher_forcing_ratio:  0.9999927940994038\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0027213951107114553\n",
      "KL_weight:  7.210900000003683e-06 teacher_forcing_ratio:  0.9999927890994034\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002570651238784194\n",
      "KL_weight:  7.215900000003694e-06 teacher_forcing_ratio:  0.999992784099403\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0025010881945490837\n",
      "KL_weight:  7.220900000003705e-06 teacher_forcing_ratio:  0.9999927790994025\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0026300358586013317\n",
      "KL_weight:  7.225900000003716e-06 teacher_forcing_ratio:  0.9999927740994021\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002448691288009286\n",
      "KL_weight:  7.230900000003727e-06 teacher_forcing_ratio:  0.9999927690994017\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0025040009059011936\n",
      "KL_weight:  7.2359000000037376e-06 teacher_forcing_ratio:  0.9999927640994013\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   fasphandon \tScore:  0.41113\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     festabed \tScore:  0.14772\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    jiskeding \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  pedusenting \tScore:  0.06239\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snetcures \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  skpistlying \tScore:  0.11922\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flaspeding \tScore:  0.11224\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: finfurcishing \tScore:  0.04324\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     mispenys \tScore:  0.03303\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0025151814334094524\n",
      "KL_weight:  7.242900000003753e-06 teacher_forcing_ratio:  0.9999927570994007\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0024008287582546473\n",
      "KL_weight:  7.247900000003764e-06 teacher_forcing_ratio:  0.9999927520994003\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0021127567160874605\n",
      "KL_weight:  7.252900000003775e-06 teacher_forcing_ratio:  0.9999927470993999\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002020315732806921\n",
      "KL_weight:  7.257900000003786e-06 teacher_forcing_ratio:  0.9999927420993995\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.028120266273617744\n",
      "KL_weight:  7.262900000003797e-06 teacher_forcing_ratio:  0.9999927370993991\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0039001116529107094\n",
      "KL_weight:  7.267900000003808e-06 teacher_forcing_ratio:  0.9999927320993987\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.004553426057100296\n",
      "KL_weight:  7.272900000003819e-06 teacher_forcing_ratio:  0.9999927270993982\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.003266687970608473\n",
      "KL_weight:  7.27790000000383e-06 teacher_forcing_ratio:  0.9999927220993978\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0029619098640978336\n",
      "KL_weight:  7.282900000003841e-06 teacher_forcing_ratio:  0.9999927170993974\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002862926572561264\n",
      "KL_weight:  7.287900000003852e-06 teacher_forcing_ratio:  0.999992712099397\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002756214002147317\n",
      "KL_weight:  7.2929000000038626e-06 teacher_forcing_ratio:  0.9999927070993966\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002440480515360832\n",
      "KL_weight:  7.2979000000038735e-06 teacher_forcing_ratio:  0.9999927020993962\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002356065670028329\n",
      "KL_weight:  7.3029000000038845e-06 teacher_forcing_ratio:  0.9999926970993958\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.002283001784235239\n",
      "KL_weight:  7.3079000000038955e-06 teacher_forcing_ratio:  0.9999926920993953\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 750 char-loss:  0.002519246656447649\n",
      "KL_weight:  7.312900000003906e-06 teacher_forcing_ratio:  0.9999926870993949\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fasdonaltening \tScore:  0.08737\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    festabbed \tScore:  0.07172\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   jembingled \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  pendempised \tScore:  0.25965\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    smistents \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   skisplying \tScore:  0.18257\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: flasherishing \tScore:  0.08737\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: funtisfoning \tScore:  0.12390\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funtisfoning \tScore:  0.12390\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hoalechared \tScore:  0.04741\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.004677384160459042\n",
      "KL_weight:  7.319900000003922e-06 teacher_forcing_ratio:  0.9999926800993943\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0031349339988082647\n",
      "KL_weight:  7.324900000003933e-06 teacher_forcing_ratio:  0.9999926750993939\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0036048481706529856\n",
      "KL_weight:  7.329900000003944e-06 teacher_forcing_ratio:  0.9999926700993935\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0027021989226341248\n",
      "KL_weight:  7.334900000003955e-06 teacher_forcing_ratio:  0.9999926650993931\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0026843242812901735\n",
      "KL_weight:  7.339900000003966e-06 teacher_forcing_ratio:  0.9999926600993927\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0026063434779644012\n",
      "KL_weight:  7.344900000003977e-06 teacher_forcing_ratio:  0.9999926550993923\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0024292056914418936\n",
      "KL_weight:  7.3499000000039875e-06 teacher_forcing_ratio:  0.9999926500993919\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002316918922588229\n",
      "KL_weight:  7.3549000000039985e-06 teacher_forcing_ratio:  0.9999926450993915\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0024631773121654987\n",
      "KL_weight:  7.3599000000040095e-06 teacher_forcing_ratio:  0.999992640099391\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002159212250262499\n",
      "KL_weight:  7.3649000000040204e-06 teacher_forcing_ratio:  0.9999926350993906\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00849965214729309\n",
      "KL_weight:  7.369900000004031e-06 teacher_forcing_ratio:  0.9999926300993902\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.007938001304864883\n",
      "KL_weight:  7.374900000004042e-06 teacher_forcing_ratio:  0.9999926250993898\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.003922239411622286\n",
      "KL_weight:  7.379900000004053e-06 teacher_forcing_ratio:  0.9999926200993894\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0033638738095760345\n",
      "KL_weight:  7.384900000004064e-06 teacher_forcing_ratio:  0.999992615099389\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.003226733533665538\n",
      "KL_weight:  7.389900000004075e-06 teacher_forcing_ratio:  0.9999926100993886\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  fasthanding \tScore:  0.10600\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: festabbeding \tScore:  0.12390\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     jembinys \tScore:  0.07386\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  depemphined \tScore:  0.05013\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentersats \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  skispliting \tScore:  0.57067\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flasherk \tScore:  0.15620\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functisoning \tScore:  0.46925\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: confurtinating \tScore:  0.05622\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  hestalinged \tScore:  0.05961\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0027505233883857727\n",
      "KL_weight:  7.396900000004091e-06 teacher_forcing_ratio:  0.999992603099388\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.002646374749019742\n",
      "KL_weight:  7.4019000000041016e-06 teacher_forcing_ratio:  0.9999925980993876\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0030474623199552298\n",
      "KL_weight:  7.4069000000041125e-06 teacher_forcing_ratio:  0.9999925930993872\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0027121766470372677\n",
      "KL_weight:  7.4119000000041235e-06 teacher_forcing_ratio:  0.9999925880993867\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.002448461949825287\n",
      "KL_weight:  7.4169000000041345e-06 teacher_forcing_ratio:  0.9999925830993863\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0024083151947706938\n",
      "KL_weight:  7.421900000004145e-06 teacher_forcing_ratio:  0.9999925780993859\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0024402060080319643\n",
      "KL_weight:  7.426900000004156e-06 teacher_forcing_ratio:  0.9999925730993855\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002347965259104967\n",
      "KL_weight:  7.431900000004167e-06 teacher_forcing_ratio:  0.9999925680993851\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0023659919388592243\n",
      "KL_weight:  7.436900000004178e-06 teacher_forcing_ratio:  0.9999925630993847\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.002208851743489504\n",
      "KL_weight:  7.441900000004189e-06 teacher_forcing_ratio:  0.9999925580993843\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002160227857530117\n",
      "KL_weight:  7.4469000000042e-06 teacher_forcing_ratio:  0.9999925530993838\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.002072354545816779\n",
      "KL_weight:  7.451900000004211e-06 teacher_forcing_ratio:  0.9999925480993834\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.0021104912739247084\n",
      "KL_weight:  7.456900000004222e-06 teacher_forcing_ratio:  0.999992543099383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.004347326699644327\n",
      "KL_weight:  7.461900000004233e-06 teacher_forcing_ratio:  0.9999925380993826\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.0031868445221334696\n",
      "KL_weight:  7.466900000004244e-06 teacher_forcing_ratio:  0.9999925330993822\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fastandonking \tScore:  0.30266\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: jabestanking \tScore:  0.14735\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  jembingated \tScore:  0.05013\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  deploingers \tScore:  0.02950\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  stestingles \tScore:  0.02666\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: skestiluching \tScore:  0.10518\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flashorgate \tScore:  0.10600\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fuctisonoun \tScore:  0.14991\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fuctinoningo \tScore:  0.12811\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  seholanizes \tScore:  0.02819\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.003921940922737122\n",
      "KL_weight:  7.4739000000042594e-06 teacher_forcing_ratio:  0.9999925260993816\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.003681554924696684\n",
      "KL_weight:  7.47890000000427e-06 teacher_forcing_ratio:  0.9999925210993812\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.007556538097560406\n",
      "KL_weight:  7.483900000004281e-06 teacher_forcing_ratio:  0.9999925160993808\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0032350143883377314\n",
      "KL_weight:  7.488900000004292e-06 teacher_forcing_ratio:  0.9999925110993804\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.003155590733513236\n",
      "KL_weight:  7.493900000004303e-06 teacher_forcing_ratio:  0.99999250609938\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002892817137762904\n",
      "KL_weight:  7.498900000004314e-06 teacher_forcing_ratio:  0.9999925010993795\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002607495989650488\n",
      "KL_weight:  7.503900000004325e-06 teacher_forcing_ratio:  0.9999924960993791\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0024306271225214005\n",
      "KL_weight:  7.508900000004336e-06 teacher_forcing_ratio:  0.9999924910993787\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.0024342972319573164\n",
      "KL_weight:  7.513900000004347e-06 teacher_forcing_ratio:  0.9999924860993783\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0024062057491391897\n",
      "KL_weight:  7.518900000004358e-06 teacher_forcing_ratio:  0.9999924810993779\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.00306656863540411\n",
      "KL_weight:  7.523900000004369e-06 teacher_forcing_ratio:  0.9999924760993775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.004454105161130428\n",
      "KL_weight:  7.52890000000438e-06 teacher_forcing_ratio:  0.9999924710993771\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.005853578448295593\n",
      "KL_weight:  7.533900000004391e-06 teacher_forcing_ratio:  0.9999924660993766\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.00389695493504405\n",
      "KL_weight:  7.538900000004402e-06 teacher_forcing_ratio:  0.9999924610993762\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.003509032540023327\n",
      "KL_weight:  7.543900000004413e-06 teacher_forcing_ratio:  0.9999924560993758\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  casonwassed \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    bestaying \tScore:  0.16233\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     geshifys \tScore:  0.03928\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: pexhendersing \tScore:  0.11302\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  smenistures \tScore:  0.04741\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splishtering \tScore:  0.31702\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: flasherished \tScore:  0.09578\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functersing \tScore:  0.38163\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: cuntisfering \tScore:  0.06058\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  heshaliners \tScore:  0.05961\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0065496573224663734\n",
      "KL_weight:  7.550900000004428e-06 teacher_forcing_ratio:  0.9999924490993752\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00871981866657734\n",
      "KL_weight:  7.555900000004439e-06 teacher_forcing_ratio:  0.9999924440993748\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.003843312617391348\n",
      "KL_weight:  7.56090000000445e-06 teacher_forcing_ratio:  0.9999924390993744\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0044444953091442585\n",
      "KL_weight:  7.565900000004461e-06 teacher_forcing_ratio:  0.999992434099374\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0031503960490226746\n",
      "KL_weight:  7.570900000004472e-06 teacher_forcing_ratio:  0.9999924290993736\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0029200008139014244\n",
      "KL_weight:  7.575900000004483e-06 teacher_forcing_ratio:  0.9999924240993732\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002935150871053338\n",
      "KL_weight:  7.580900000004494e-06 teacher_forcing_ratio:  0.9999924190993728\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.002625567140057683\n",
      "KL_weight:  7.585900000004505e-06 teacher_forcing_ratio:  0.9999924140993723\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002618798753246665\n",
      "KL_weight:  7.590900000004516e-06 teacher_forcing_ratio:  0.9999924090993719\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0025959606282413006\n",
      "KL_weight:  7.595900000004527e-06 teacher_forcing_ratio:  0.9999924040993715\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.002638421021401882\n",
      "KL_weight:  7.600900000004538e-06 teacher_forcing_ratio:  0.9999923990993711\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.0024165913928300142\n",
      "KL_weight:  7.605900000004549e-06 teacher_forcing_ratio:  0.9999923940993707\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.002603590954095125\n",
      "KL_weight:  7.61090000000456e-06 teacher_forcing_ratio:  0.9999923890993703\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.0033386368304491043\n",
      "KL_weight:  7.615900000004571e-06 teacher_forcing_ratio:  0.9999923840993699\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.003035997273400426\n",
      "KL_weight:  7.620900000004582e-06 teacher_forcing_ratio:  0.9999923790993694\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    fouswands \tScore:  0.12753\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   bestirying \tScore:  0.14772\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    gestirked \tScore:  0.03391\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  perdempting \tScore:  0.05013\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sestinfured \tScore:  0.05013\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     spistled \tScore:  0.06518\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flaspers \tScore:  0.15620\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functerding \tScore:  0.38163\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functisforning \tScore:  0.37597\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     hespling \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.0034575420431792736\n",
      "KL_weight:  7.627900000004597e-06 teacher_forcing_ratio:  0.9999923720993689\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.003133469959720969\n",
      "KL_weight:  7.632900000004607e-06 teacher_forcing_ratio:  0.9999923670993685\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.002407117048278451\n",
      "KL_weight:  7.637900000004618e-06 teacher_forcing_ratio:  0.999992362099368\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.002439062809571624\n",
      "KL_weight:  7.64290000000463e-06 teacher_forcing_ratio:  0.9999923570993676\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0022960626520216465\n",
      "KL_weight:  7.64790000000464e-06 teacher_forcing_ratio:  0.9999923520993672\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0022640724200755358\n",
      "KL_weight:  7.652900000004651e-06 teacher_forcing_ratio:  0.9999923470993668\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002203713171184063\n",
      "KL_weight:  7.657900000004662e-06 teacher_forcing_ratio:  0.9999923420993664\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 400 char-loss:  0.0021545416675508022\n",
      "KL_weight:  7.662900000004673e-06 teacher_forcing_ratio:  0.999992337099366\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 450 char-loss:  0.002403026446700096\n",
      "KL_weight:  7.667900000004684e-06 teacher_forcing_ratio:  0.9999923320993656\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 500 char-loss:  0.0036247908137738705\n",
      "KL_weight:  7.672900000004695e-06 teacher_forcing_ratio:  0.9999923270993651\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 550 char-loss:  0.0030080019496381283\n",
      "KL_weight:  7.677900000004706e-06 teacher_forcing_ratio:  0.9999923220993647\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 600 char-loss:  0.009879285469651222\n",
      "KL_weight:  7.682900000004717e-06 teacher_forcing_ratio:  0.9999923170993643\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 650 char-loss:  0.005162224173545837\n",
      "KL_weight:  7.687900000004728e-06 teacher_forcing_ratio:  0.9999923120993639\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 700 char-loss:  0.003584165358915925\n",
      "KL_weight:  7.692900000004739e-06 teacher_forcing_ratio:  0.9999923070993635\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Step: 750 char-loss:  0.00567583367228508\n",
      "KL_weight:  7.69790000000475e-06 teacher_forcing_ratio:  0.9999923020993631\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: absonderling \tScore:  0.06484\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     bestight \tScore:  0.09193\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beshignt \tScore:  0.07731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: dependersing \tScore:  0.23462\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sphenting \tScore:  0.05612\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  spiltinging \tScore:  0.29982\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  disaplering \tScore:  0.02666\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: confinterizing \tScore:  0.04132\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   snhotching \tScore:  0.03303\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    shelaring \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.notebook.tqdm(range(100)):\n",
    "    trainer.train(num_epochs=10, batch_size=64, pretrained=False)\n",
    "#     torch.save(seq2seq.state_dict(), \"Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout)_{}epoch.pt\".format(epoch))\n",
    "\n",
    "    ## eval\n",
    "    print(\"========================================Evaluating========================================\")  \n",
    "    total_score = 0.0\n",
    "    for i in range(len(test_src)):\n",
    "        word = train_loader.vocab.indices_to_sequence(test_src[i])\n",
    "        trg_true = train_loader.vocab.indices_to_sequence(test_trg[i])\n",
    "        results = trainer.evaluate(word, test_c_src[i].view(1, -1), test_c_trg[i].view(1, -1))[0]\n",
    "        score = trainer.compute_bleu(results, trg_true)\n",
    "        print(\"Src_true: {:>12}\".format(word), \"\\tTrg_true:{:>12}\".format(trg_true), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "        total_score += score\n",
    "    total_score /= len(test_src)\n",
    "    trainer.score.append(total_score)\n",
    "    print(\"==========================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    acc = np.load(loss_file)\n",
    "    entropy = acc['entropy']\n",
    "    kld = acc['kld']\n",
    "    kl_weight = acc['kl_weight']\n",
    "    teacher_forcing_ratio = acc['teacher_forcing_ratio']\n",
    "    score = acc['score']\n",
    "    \n",
    "# plt.title(\"Activation Function comparision(EEGNet)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(entropy)+1)\n",
    "plt.plot(x, entropy, label=\"CrossEntropy\")\n",
    "plt.plot(x, kld, label=\"kld\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.ylabel(\"KL_weight & teacher_forcing_ratio\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(kl_weight)+1)\n",
    "plt.plot(x, kl_weight, label=\"kl_weight\")\n",
    "plt.plot(x, teacher_forcing_ratio, label=\"teacher_forcing_ratio\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.linspace(1, len(kl_weight)+1, len(score))\n",
    "plt.plot(x, score, label=\"score\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['derize', 'dercap', 'dercap', 'dercap'], ['endir', 'renact', 'weasi', 'endiat'], ['stering', 'stering', 'stering', 'stering'], ['westing', 'westing', 'winse', 'westing'], ['sh', 'shear', 'sh', 'shdear'], ['nage', 'nounding', 'nagun', 'nagun'], ['thering', 'pering', 'bering', 'tering'], ['atend', 'apled', 'anted', 'anted'], ['orment', 'usters', 'uspemban', 'uspearted'], ['tering', 'tering', 'tering', 'tering'], ['belting', 'belling', 'belling', 'belting'], ['rending', 'resen', 'resing', 'restance'], ['muried', 'urcembing', 'muried', 'murien'], ['conser', 'conser', 'consure', 'conser'], ['pealing', 'peling', 'peling', 'peuling'], ['esting', 'esting', 'stance', 'esting'], ['endir', 'endinquo', 'buncis', 'ensting'], ['anter', 'anter', 'anter', 'anter'], ['demany', 'dearing', 'dealing', 'dealing'], ['depjon', 'despon', 'sconge', 'stoerzen'], ['dering', 'derap', 'drepan', 'deraping'], ['ghint', 'ghen', 'ghinfing', 'ghen'], ['dorceam', 'dorceaze', 'docue', 'sorned'], ['corusent', 'counsering', 'counsied', 'counsering'], ['mund', 'mund', 'mund', 'mund'], ['denh', 'send', 'demance', 'send'], ['swing', 'swerked', 'swinker', 'swering'], ['dercan', 'dercan', 'dischear', 'decron'], ['reft', 'reft', 'redut', 'ont'], ['nating', 'pant', 'nating', 'powing'], ['thering', 'thead', 'chande', 'tared'], ['stearn', 'stearn', 'stearn', 'showed'], ['herat', 'glear', 'hiler', 'herat'], ['sobut', 'sobule', 'sobut', 'sobut'], ['bleg', 'blering', 'bleping', 'blearing'], ['dare', 'darce', 'carnt', 'dacter'], ['sopling', 'soner', 'sopling', 'soner'], ['sperit', 'sperit', 'stering', 'stering'], ['mack', 'est', 'swerk', 'estack'], ['bend', 'bend', 'bend', 'bend'], ['mend', 'mend', 'mande', 'mending'], ['gech', 'gechate', 'tazer', 'tazer'], ['ger', 'readit', 'berized', 'geract'], ['marte', 'sorken', 'varte', 'sormun'], ['shent', 'shent', 'shent', 'shent'], ['spering', 'seph', 'spearing', 'sephen'], ['griate', 'greact', 'grode', 'greact'], ['tering', 'sweam', 'stearing', 'tearing'], ['heart', 'hears', 'hears', 'hearts'], ['conter', 'deching', 'conder', 'conder'], ['inder', 'inder', 'inder', 'inder'], ['reding', 'redizen', 'redize', 'reding'], ['molde', 'molus', 'olde', 'arched'], ['tesh', 'tesh', 'teading', 'teading'], ['deman', 'deman', 'deman', 'deman'], ['sending', 'send', 'sorling', 'sending'], ['minguer', 'muspend', 'mingue', 'minguer'], ['sken', 'sent', 'sken', 'sken'], ['redch', 'erack', 'yher', 'edork'], ['soned', 'sonter', 'soned', 'soned'], ['izne', 'ishelt', 'isholed', 'ishent'], ['peus', 'peush', 'bels', 'hending'], ['niner', 'nisper', 'nins', 'nispen'], ['note', 'note', 'nocks', 'note'], ['erking', 'deparing', 'arken', 'endiat'], ['dercize', 'descure', 'decrien', 'dercize'], ['nereding', 'nespore', 'nesping', 'nesting'], ['ster', 'sterk', 'created', 'stering'], ['inter', 'inter', 'inter', 'inter'], ['anceished', 'anted', 'canted', 'canted'], ['fing', 'feman', 'fing', 'fearing'], ['inke', 'anter', 'anter', 'anter'], ['rest', 'erst', 'arsent', 'endir'], ['taning', 'sopeak', 'tanding', 'sopan'], ['leping', 'ledink', 'clinge', 'ledink'], ['blipech', 'blipse', 'blips', 'lechow'], ['sending', 'senge', 'sune', 'senge'], ['pending', 'pending', 'posent', 'pending'], ['demarny', 'demarny', 'demarl', 'demarny'], ['sepon', 'seno', 'sent', 'sent'], ['he', 'hest', 'h', 'hes'], ['reding', 'reding', 'reding', 'reding'], ['diver', 'devire', 'diver', 'diver'], ['souned', 'souned', 'souned', 'sounted'], ['embing', 'ending', 'ending', 'ending'], ['scom', 'scom', 'compan', 'sconjar'], ['leit', 'leiting', 'lating', 'leitated'], ['diver', 'diver', 'diverk', 'diver'], ['ont', 'ront', 'ront', 'ont'], ['fired', 'racted', 'firbed', 'fired'], ['sken', 'stend', 'skend', 'senting'], ['dive', 'deach', 'dicate', 'dinat'], ['ted', 'ted', 'ted', 'ted'], ['tering', 'tering', 'tering', 'tering'], ['gechire', 'gecharing', 'gechire', 'gecharing'], ['end', 'end', 'bend', 'end'], ['speat', 'speat', 'sple', 'speat'], ['fern', 'pendiring', 'conger', 'pendiring'], ['coster', 'costren', 'coster', 'singued'], ['nstio', 'nstare', 'nstare', 'nercat']]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def reparaterization_trick(mean, logv):\n",
    "        std = torch.exp(0.5*logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return  mean + eps * std\n",
    "    \n",
    "def Gaussian_score(words):\n",
    "    words_list = []\n",
    "    score = 0\n",
    "    yourpath = './train.txt'#should be your directory of train.txt\n",
    "    with open(yourpath,'r') as fp:\n",
    "        for line in fp:\n",
    "            word = line.split(' ')\n",
    "            word[3] = word[3].strip('\\n')\n",
    "            words_list.extend([word])\n",
    "        for t in words:\n",
    "            for i in words_list:\n",
    "                if t == i:\n",
    "                    score += 1\n",
    "    return score/len(words)\n",
    "\n",
    "    \n",
    "label = torch.LongTensor([[1, 0, 0, 0],\n",
    "                       [0, 1, 0, 0],\n",
    "                       [0, 0, 1, 0],\n",
    "                       [0, 0, 0, 1]]).to(device)\n",
    "\n",
    "decoder.eval()\n",
    "words = []\n",
    "for i in range(100):        \n",
    "\n",
    "    hidden_mean = torch.randn([1, 1, 32]).to(device)\n",
    "    hidden_logv = torch.randn([1, 1, 32]).to(device)\n",
    "    cell_mean = torch.randn([1, 1, 32]).to(device)\n",
    "    cell_logv = torch.randn([1, 1, 32]).to(device)\n",
    "\n",
    "    encoder_hidden = reparaterization_trick(hidden_mean, hidden_logv)\n",
    "    encoder_cell = reparaterization_trick(cell_mean, cell_logv)\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(4):\n",
    "        hidden = torch.cat([encoder_hidden, label[i].view(1, 1, 4)], dim=2)\n",
    "        hidden = decoder.latent2hidden(hidden)\n",
    "        cell = torch.cat([encoder_cell, label[i].view(1, 1, 4)], dim=2)\n",
    "        cell = decoder.latent2hidden(cell)\n",
    "\n",
    "        decoded_indices = decoder.evaluate(context_vector=hidden, decoder_cell=cell)\n",
    "\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(train_loader.vocab.indices_to_sequence(indices))\n",
    "        tmp.append(results[0])\n",
    "    words.append(tmp)\n",
    "print(words)\n",
    "print(Gaussian_score(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: fouschanding \tScore:  0.09578\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: bestirbanying \tScore:  0.11302\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   deshifying \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  nexpledging \tScore:  0.11095\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    senstring \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  snisterking \tScore:  0.11095\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: disanplering \tScore:  0.02409\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functringing \tScore:  0.34484\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  chlistoning \tScore:  0.05246\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: sheldipaning \tScore:  0.04529\n",
      "0.10810458220824519\n"
     ]
    }
   ],
   "source": [
    "total_score = 0.0\n",
    "for i in range(len(test_src)):\n",
    "    word = train_loader.vocab.indices_to_sequence(test_src[i])\n",
    "    trg_true = train_loader.vocab.indices_to_sequence(test_trg[i])\n",
    "    results = trainer.evaluate(word, test_c_src[i].view(1, -1), test_c_trg[i].view(1, -1))[0]\n",
    "    score = trainer.compute_bleu(results, trg_true)\n",
    "    print(\"Src_true: {:>12}\".format(word), \"\\tTrg_true:{:>12}\".format(trg_true), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "    total_score += score\n",
    "total_score /= len(test_src)\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder, \"lstm_decoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
