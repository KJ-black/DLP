{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from Data import *\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import  pack_padded_sequence, pad_packed_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_name = 'Lab4_seq2seq_ae_gru.pt'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = 0\n",
    "tp = 1\n",
    "pg = 2\n",
    "p = 3\n",
    "\n",
    "def split_data(data):\n",
    "    split_data = []\n",
    "    for string in data:\n",
    "        split_space = string.split()\n",
    "        for i, word in enumerate(split_space):\n",
    "            split_data.append(word)\n",
    "    return split_data\n",
    "\n",
    "def y_train_make(n):\n",
    "    np_sp = np.array([sp])\n",
    "    np_tp = np.array([tp])\n",
    "    np_pg = np.array([pg])\n",
    "    np_p = np.array([p])\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np_sp)\n",
    "        y.append(np_tp)\n",
    "        y.append(np_pg)\n",
    "        y.append(np_p)\n",
    "    return np.array(y)\n",
    "\n",
    "def src_trg_split(data):\n",
    "    src = []\n",
    "    trg = []\n",
    "    for i in range(0, len(data), 2):\n",
    "        src.append(data[i])\n",
    "        trg.append(data[i])\n",
    "    return np.array(src), np.array(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = np.squeeze(pd.read_csv('train.txt', header=None))\n",
    "y_train = y_train_make(len(train_data))\n",
    "\n",
    "train_data = split_data(train_data)\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocab(train_data)\n",
    "\n",
    "train_loader = DataTransformer(train_data, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.squeeze(pd.read_csv('test.txt', header=None))\n",
    "test_data = split_data(test_data)\n",
    "test_data = np.array(test_data)\n",
    "src, trg = src_trg_split(test_data)\n",
    "test_src = []\n",
    "test_trg = []\n",
    "\n",
    "for word in src:\n",
    "    test_src.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\n",
    "for word in trg:\n",
    "    test_trg.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\"\"\"\n",
    "sp -> p\n",
    "sp -> pg\n",
    "sp -> tp\n",
    "sp -> tp\n",
    "p  -> tp\n",
    "sp -> pg\n",
    "p  -> sp\n",
    "pg -> sp\n",
    "pg -> p\n",
    "pg -> tp\n",
    "\"\"\"\n",
    "test_c_src = np.array([sp, sp, sp, sp, p, sp, p, pg, pg, pg]).reshape(-1, 1)\n",
    "test_c_trg = np.array([p, pg, tp, tp, tp, pg, sp, sp, p, tp]).reshape(-1, 1)\n",
    "test_c_src = torch.tensor(test_c_src).to(device)\n",
    "test_c_trg = torch.tensor(test_c_trg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():    \n",
    "        src_c = test_src\n",
    "        trg_c = test_trg\n",
    "        optimizer.zero_grad()            \n",
    "        output = model(src, trg, src_c, trg_c, 0) #turn off teacher forcing\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"=========show testing result=========\")\n",
    "            for i in range(output.shape[-1]):\n",
    "                show_result(trg, output, i)\n",
    "                print()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "def show_result(target, output, index):\n",
    "    print(\"Ground true: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        tmp = trg[index, i]\n",
    "        if tmp == 1:\n",
    "            break\n",
    "        elif tmp == 0:\n",
    "            continue\n",
    "        print(chr(trg[index, i]-7+ord('a')), end=\"\")\n",
    "    \n",
    "    print(\" Predict: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        print(chr(np.argmax(o[index, i, 3:])-4+ord('a')), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, output_size):\n",
    "        \"\"\"Define layers for a vanilla rnn encoder\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, output_size)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lengths)\n",
    "        packed_outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, max_length, teacher_forcing_ratio, sos_id, use_cuda):\n",
    "        \"\"\"Define layers for a vanilla rnn decoder\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)  # work with NLLLoss = CrossEntropyLoss\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.sos_id = sos_id\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward_step(self, inputs, hidden):\n",
    "        # inputs: (time_steps=1, batch_size)\n",
    "        batch_size = inputs.size(1)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded.view(1, batch_size, self.hidden_size)  # S = T(1) x B x N\n",
    "        rnn_output, hidden = self.gru(embedded, hidden)  # S = T(1) x B x H\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze the time dimension\n",
    "        output = self.log_softmax(self.out(rnn_output))  # S = B x O\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, context_vector, targets):\n",
    "\n",
    "        # Prepare variable for decoder on time_step_0\n",
    "        target_vars, target_lengths = targets\n",
    "        batch_size = context_vector.size(1)\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "\n",
    "        # Pass the context vector\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            max_target_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(max_target_length):\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_vars[t].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input = self._decode_to_index(decoder_outputs_on_t)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluate(self, context_vector):\n",
    "        batch_size = context_vector.size(1) # get the batch size\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            self.max_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(self.max_length):\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            decoder_input = self._decode_to_index(decoder_outputs_on_t)  # select the former output as input\n",
    "\n",
    "        return self._decode_to_indices(decoder_outputs)\n",
    "\n",
    "    def _decode_to_index(self, decoder_output):\n",
    "        \"\"\"\n",
    "        evaluate on the logits, get the index of top1\n",
    "        :param decoder_output: S = B x V or T x V\n",
    "        \"\"\"\n",
    "        value, index = torch.topk(decoder_output, 1)\n",
    "        index = index.transpose(0, 1)  # S = 1 x B, 1 is the index of top1 class\n",
    "        if self.use_cuda:\n",
    "            index = index.cuda()\n",
    "        return index\n",
    "\n",
    "    def _decode_to_indices(self, decoder_outputs):\n",
    "        \"\"\"\n",
    "        Evaluate on the decoder outputs(logits), find the top 1 indices.\n",
    "        Please confirm that the model is on evaluation mode if dropout/batch_norm layers have been added\n",
    "        :param decoder_outputs: the output sequence from decoder, shape = T x B x V \n",
    "        \"\"\"\n",
    "        decoded_indices = []\n",
    "        batch_size = decoder_outputs.size(1)\n",
    "        decoder_outputs = decoder_outputs.transpose(0, 1)  # S = B x T x V\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            top_ids = self._decode_to_index(decoder_outputs[b])\n",
    "            decoded_indices.append(top_ids.data[0].cpu().numpy())\n",
    "        return decoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        input_vars, input_lengths = inputs\n",
    "        encoder_outputs, encoder_hidden = self.encoder.forward(input_vars, input_lengths)\n",
    "        decoder_outputs, decoder_hidden = self.decoder.forward(context_vector=encoder_hidden, targets=targets)\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluate(self, inputs):\n",
    "        input_vars, input_lengths = inputs\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_vars, input_lengths)\n",
    "        decoded_sentence = self.decoder.evaluate(context_vector=encoder_hidden)\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, data_transformer, learning_rate, use_cuda, checkpoint_name,\n",
    "                 teacher_forcing_ratio=1.0):\n",
    "\n",
    "        self.model = model\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "        self.loss_list = []\n",
    "\n",
    "        # record some information about dataset\n",
    "        self.data_transformer = data_transformer\n",
    "        self.vocab_size = self.data_transformer.vocab_size\n",
    "        self.PAD_ID = self.data_transformer.PAD_ID\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # optimizer setting\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer= torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = torch.nn.NLLLoss(ignore_index=self.PAD_ID, reduction='mean')\n",
    "\n",
    "    def train(self, num_epochs, batch_size, pretrained=False):\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_model()\n",
    "\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            mini_batches = self.data_transformer.mini_batches(batch_size=batch_size)\n",
    "            for input_batch, target_batch in mini_batches:\n",
    "                self.optimizer.zero_grad()\n",
    "                decoder_outputs, decoder_hidden = self.model(input_batch, target_batch)\n",
    "\n",
    "                # calculate the loss and back prop.\n",
    "                cur_loss = self.get_loss(decoder_outputs, target_batch[0])\n",
    "                self.loss_list.append(cur_loss.item())\n",
    "                \n",
    "                # logging\n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Step:\", step, \"char-loss: \", cur_loss.detach().cpu().numpy())\n",
    "                    self.save_model()\n",
    "                cur_loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def masked_nllloss(self):\n",
    "        # Deprecated in PyTorch 2.0, can be replaced by ignore_index\n",
    "        # define the masked NLLoss\n",
    "        weight = torch.ones(self.vocab_size)\n",
    "        weight[self.PAD_ID] = 0\n",
    "        if self.use_cuda:\n",
    "            weight = weight.cuda()\n",
    "        return torch.nn.NLLLoss(weight=weight).cuda()\n",
    "\n",
    "    def get_loss(self, decoder_outputs, targets):\n",
    "        b = decoder_outputs.size(1)\n",
    "        t = decoder_outputs.size(0)\n",
    "        targets = targets.contiguous().view(-1)  # S = (B*T)\n",
    "        decoder_outputs = decoder_outputs.view(b * t, -1)  # S = (B*T) x V\n",
    "        return self.criterion(decoder_outputs, targets)\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_name)\n",
    "        np.savez('loss.npz', train_loss=self.loss_list)\n",
    "        print(\"Model has been saved as %s.\\n\" % self.checkpoint_name)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.checkpoint_name, map_location='cpu'))\n",
    "        print(\"Pretrained model has been loaded.\\n\")\n",
    "\n",
    "    def evaluate(self, words):\n",
    "        # make sure that words is list\n",
    "        if type(words) is not list:\n",
    "            words = [words]\n",
    "\n",
    "        # transform word to index-sequence\n",
    "        eval_var = self.data_transformer.evaluation_batch(words=words)\n",
    "        decoded_indices = self.model.evaluate(eval_var)\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(self.data_transformer.vocab.indices_to_sequence(indices))\n",
    "        return results\n",
    "    \n",
    "    def compute_bleu(self, output, reference):\n",
    "        cc = SmoothingFunction()\n",
    "        if len(reference) == 3:\n",
    "            weights = (0.33,0.33,0.33)\n",
    "        else:\n",
    "            weights = (0.25,0.25,0.25,0.25)\n",
    "        return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  1.681395\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.87712604\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.41584605\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict: abanondaning \tScore:  0.27706\n",
      "True:         abet \tPredict:         abet \tScore:  1.00000\n",
      "True:        begin \tPredict:     begignat \tScore:  0.36556\n",
      "True:       expend \tPredict:     expended \tScore:  0.68037\n",
      "True:         sent \tPredict:       sentes \tScore:  0.50813\n",
      "True:        split \tPredict:       splitt \tScore:  0.75984\n",
      "True:       flared \tPredict:       flared \tScore:  1.00000\n",
      "True:  functioning \tPredict: funcotinging \tScore:  0.35930\n",
      "True:  functioning \tPredict: funcotinging \tScore:  0.35930\n",
      "True:      healing \tPredict:      healing \tScore:  1.00000\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1387878\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.09441696\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07511153\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:     abandoan \tScore:  0.70711\n",
      "True:         abet \tPredict:         abet \tScore:  1.00000\n",
      "True:        begin \tPredict:       beging \tScore:  0.75984\n",
      "True:       expend \tPredict:     expended \tScore:  0.68037\n",
      "True:         sent \tPredict:       senter \tScore:  0.50813\n",
      "True:        split \tPredict:        split \tScore:  1.00000\n",
      "True:       flared \tPredict:       flared \tScore:  1.00000\n",
      "True:  functioning \tPredict:   functoinut \tScore:  0.42268\n",
      "True:  functioning \tPredict:   functoinut \tScore:  0.42268\n",
      "True:      healing \tPredict:      healize \tScore:  0.61479\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.03049099\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.036930952\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.020234503\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:    abandonat \tScore:  0.72598\n",
      "True:         abet \tPredict:         abet \tScore:  1.00000\n",
      "True:        begin \tPredict:       beging \tScore:  0.75984\n",
      "True:       expend \tPredict:     expended \tScore:  0.68037\n",
      "True:         sent \tPredict:        sentt \tScore:  0.66874\n",
      "True:        split \tPredict:        split \tScore:  1.00000\n",
      "True:       flared \tPredict:       flared \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:      healing \tPredict:      healing \tScore:  1.00000\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.01806581\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.014571651\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.008468788\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:    abandonat \tScore:  0.72598\n",
      "True:         abet \tPredict:         abet \tScore:  1.00000\n",
      "True:        begin \tPredict:       beging \tScore:  0.75984\n",
      "True:       expend \tPredict:     expended \tScore:  0.68037\n",
      "True:         sent \tPredict:        sentt \tScore:  0.66874\n",
      "True:        split \tPredict:        split \tScore:  1.00000\n",
      "True:       flared \tPredict:       flared \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:      healing \tPredict:      healize \tScore:  0.61479\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0047299326\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.004608551\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0042003402\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_ae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:    abandonat \tScore:  0.72598\n",
      "True:         abet \tPredict:         abet \tScore:  1.00000\n",
      "True:        begin \tPredict:       beging \tScore:  0.75984\n",
      "True:       expend \tPredict:       expend \tScore:  1.00000\n",
      "True:         sent \tPredict:        sentt \tScore:  0.66874\n",
      "True:        split \tPredict:        split \tScore:  1.00000\n",
      "True:       flared \tPredict:       flared \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:  functioning \tPredict:  functioning \tScore:  1.00000\n",
      "True:      healing \tPredict:     healaing \tScore:  0.50000\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define our models\n",
    "encoder = Encoder(vocab_size=train_loader.vocab_size,\n",
    "                         embedding_size=256,\n",
    "                         output_size=256).to(device)\n",
    "\n",
    "decoder = Decoder(hidden_size=256,\n",
    "                         output_size=train_loader.vocab_size,\n",
    "                         max_length=train_loader.max_length,\n",
    "                         teacher_forcing_ratio=1.,\n",
    "                         sos_id=train_loader.SOS_ID,\n",
    "                         use_cuda=True).to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder=encoder,\n",
    "                  decoder=decoder)\n",
    "\n",
    "trainer = Trainer(seq2seq, train_loader, learning_rate=0.001, use_cuda=True, checkpoint_name=checkpoint_name)\n",
    "\n",
    "for epoch in range(5):\n",
    "    trainer.train(num_epochs=5, batch_size=128, pretrained=False)\n",
    "    \n",
    "    ## eval\n",
    "    print(\"======================Evaluating======================\")  \n",
    "    for src in test_src:\n",
    "        word = vocab.indices_to_sequence(src)\n",
    "        results = trainer.evaluate(word)[0]\n",
    "        score = trainer.compute_bleu(results, word)\n",
    "        print(\"True: {:>12}\".format(word), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "    print(\"======================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    acc = np.load('loss.npz')\n",
    "    train_loss = acc['train_loss']\n",
    "\n",
    "# plt.title(\"Activation Function comparision(EEGNet)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(train_loss)+1)\n",
    "plt.plot(x, train_loss, label=\"train\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
