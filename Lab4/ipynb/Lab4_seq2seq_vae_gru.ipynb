{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from Data import *\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import  pack_padded_sequence, pad_packed_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_name = 'Lab4_seq2seq_vae_gru.pt'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = 0\n",
    "tp = 1\n",
    "pg = 2\n",
    "p = 3\n",
    "\n",
    "def split_data(data):\n",
    "    split_data = []\n",
    "    for string in data:\n",
    "        split_space = string.split()\n",
    "        for i, word in enumerate(split_space):\n",
    "            split_data.append(word)\n",
    "    return split_data\n",
    "\n",
    "def y_train_make(n):\n",
    "    np_sp = np.array([sp])\n",
    "    np_tp = np.array([tp])\n",
    "    np_pg = np.array([pg])\n",
    "    np_p = np.array([p])\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np_sp)\n",
    "        y.append(np_tp)\n",
    "        y.append(np_pg)\n",
    "        y.append(np_p)\n",
    "    return np.array(y)\n",
    "\n",
    "def src_trg_split(data):\n",
    "    src = []\n",
    "    trg = []\n",
    "    for i in range(0, len(data), 2):\n",
    "        src.append(data[i])\n",
    "        trg.append(data[i])\n",
    "    return np.array(src), np.array(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = np.squeeze(pd.read_csv('train.txt', header=None))\n",
    "y_train = y_train_make(len(train_data))\n",
    "\n",
    "train_data = split_data(train_data)\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocab(train_data)\n",
    "\n",
    "train_loader = DataTransformer(train_data, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.squeeze(pd.read_csv('test.txt', header=None))\n",
    "test_data = split_data(test_data)\n",
    "test_data = np.array(test_data)\n",
    "src, trg = src_trg_split(test_data)\n",
    "test_src = []\n",
    "test_trg = []\n",
    "\n",
    "for word in src:\n",
    "    test_src.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\n",
    "for word in trg:\n",
    "    test_trg.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\"\"\"\n",
    "sp -> p\n",
    "sp -> pg\n",
    "sp -> tp\n",
    "sp -> tp\n",
    "p  -> tp\n",
    "sp -> pg\n",
    "p  -> sp\n",
    "pg -> sp\n",
    "pg -> p\n",
    "pg -> tp\n",
    "\"\"\"\n",
    "test_c_src = np.array([sp, sp, sp, sp, p, sp, p, pg, pg, pg]).reshape(-1, 1)\n",
    "test_c_trg = np.array([p, pg, tp, tp, tp, pg, sp, sp, p, tp]).reshape(-1, 1)\n",
    "test_c_src = torch.tensor(test_c_src).to(device)\n",
    "test_c_trg = torch.tensor(test_c_trg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():    \n",
    "        src_c = test_src\n",
    "        trg_c = test_trg\n",
    "        optimizer.zero_grad()            \n",
    "        output = model(src, trg, src_c, trg_c, 0) #turn off teacher forcing\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"=========show testing result=========\")\n",
    "            for i in range(output.shape[-1]):\n",
    "                show_result(trg, output, i)\n",
    "                print()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "def show_result(target, output, index):\n",
    "    print(\"Ground true: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        tmp = trg[index, i]\n",
    "        if tmp == 1:\n",
    "            break\n",
    "        elif tmp == 0:\n",
    "            continue\n",
    "        print(chr(trg[index, i]-7+ord('a')), end=\"\")\n",
    "    \n",
    "    print(\" Predict: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        print(chr(np.argmax(o[index, i, 3:])-4+ord('a')), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, output_size, lat_dim):\n",
    "        \"\"\"Define layers for a vanilla rnn encoder\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, output_size)\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(output_size, lat_dim)\n",
    "        self.hidden2logv = nn.Linear(output_size, lat_dim)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lengths)\n",
    "        packed_outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        means = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        \n",
    "        return outputs, means, logv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, lat_dim, max_length, teacher_forcing_ratio, sos_id, use_cuda):\n",
    "        \"\"\"Define layers for a vanilla rnn decoder\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.latent2hidden = nn.Linear(lat_dim, hidden_size)\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)  # work with NLLLoss = CrossEntropyLoss\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.sos_id = sos_id\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward_step(self, inputs, hidden):\n",
    "        # inputs: (time_steps=1, batch_size)\n",
    "        batch_size = inputs.size(1)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded.view(1, batch_size, self.hidden_size)  # S = T(1) x B x N\n",
    "        rnn_output, hidden = self.gru(embedded, hidden)  # S = T(1) x B x H\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze the time dimension\n",
    "        output = self.log_softmax(self.out(rnn_output))  # S = B x O\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, context_vector, targets):\n",
    "\n",
    "        # Prepare variable for decoder on time_step_0\n",
    "        target_vars, target_lengths = targets\n",
    "        batch_size = context_vector.size(1)\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "\n",
    "        # Pass the context vector\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            max_target_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(max_target_length):\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_vars[t].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input = self._decode_to_index(decoder_outputs_on_t)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluate(self, context_vector):\n",
    "        batch_size = context_vector.size(1) # get the batch size\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            self.max_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(self.max_length):\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            decoder_input = self._decode_to_index(decoder_outputs_on_t)  # select the former output as input\n",
    "\n",
    "        return self._decode_to_indices(decoder_outputs)\n",
    "\n",
    "    def _decode_to_index(self, decoder_output):\n",
    "        \"\"\"\n",
    "        evaluate on the logits, get the index of top1\n",
    "        :param decoder_output: S = B x V or T x V\n",
    "        \"\"\"\n",
    "        value, index = torch.topk(decoder_output, 1)\n",
    "        index = index.transpose(0, 1)  # S = 1 x B, 1 is the index of top1 class\n",
    "        if self.use_cuda:\n",
    "            index = index.cuda()\n",
    "        return index\n",
    "\n",
    "    def _decode_to_indices(self, decoder_outputs):\n",
    "        \"\"\"\n",
    "        Evaluate on the decoder outputs(logits), find the top 1 indices.\n",
    "        Please confirm that the model is on evaluation mode if dropout/batch_norm layers have been added\n",
    "        :param decoder_outputs: the output sequence from decoder, shape = T x B x V \n",
    "        \"\"\"\n",
    "        decoded_indices = []\n",
    "        batch_size = decoder_outputs.size(1)\n",
    "        decoder_outputs = decoder_outputs.transpose(0, 1)  # S = B x T x V\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            top_ids = self._decode_to_index(decoder_outputs[b])\n",
    "            decoded_indices.append(top_ids.data[0].cpu().numpy())\n",
    "        return decoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        input_vars, input_lengths = inputs\n",
    "        encoder_outputs, encoder_means, encoder_logv = self.encoder.forward(input_vars, input_lengths)        \n",
    "        encoder_hidden = self.reparaterization_trick(encoder_means, encoder_logv)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        decoder_outputs, decoder_hidden = self.decoder.forward(context_vector=encoder_hidden, targets=targets)\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluate(self, inputs):\n",
    "        input_vars, input_lengths = inputs\n",
    "        encoder_outputs, encoder_means, encoder_logv = self.encoder(input_vars, input_lengths)\n",
    "        encoder_hidden = self.reparaterization_trick(encoder_means, encoder_logv)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        decoded_sentence = self.decoder.evaluate(context_vector=encoder_hidden)\n",
    "        return decoded_sentence\n",
    "    \n",
    "    def reparaterization_trick(self, mean, logv):\n",
    "        std = torch.exp(0.5*logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return  mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, data_transformer, learning_rate, use_cuda, checkpoint_name,\n",
    "                 teacher_forcing_ratio=1.0):\n",
    "\n",
    "        self.model = model\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "        \n",
    "        # save list\n",
    "        self.loss_list = []\n",
    "        self.score = []\n",
    "\n",
    "        # record some information about dataset\n",
    "        self.data_transformer = data_transformer\n",
    "        self.vocab_size = self.data_transformer.vocab_size\n",
    "        self.PAD_ID = self.data_transformer.PAD_ID\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # optimizer setting\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer= torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = torch.nn.NLLLoss(ignore_index=self.PAD_ID, reduction='mean')\n",
    "\n",
    "    def train(self, num_epochs, batch_size, pretrained=False):\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_model()\n",
    "\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            mini_batches = self.data_transformer.mini_batches(batch_size=batch_size)\n",
    "            for input_batch, target_batch in mini_batches:\n",
    "                self.optimizer.zero_grad()\n",
    "                decoder_outputs, decoder_hidden = self.model(input_batch, target_batch)\n",
    "\n",
    "                # calculate the loss and back prop.\n",
    "                cur_loss = self.get_loss(decoder_outputs, target_batch[0])\n",
    "                self.loss_list.append(cur_loss.item())\n",
    "                \n",
    "                # logging\n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Step:\", step, \"char-loss: \", cur_loss.detach().cpu().numpy())\n",
    "                    self.save_model()\n",
    "                cur_loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def masked_nllloss(self):\n",
    "        # Deprecated in PyTorch 2.0, can be replaced by ignore_index\n",
    "        # define the masked NLLoss\n",
    "        weight = torch.ones(self.vocab_size)\n",
    "        weight[self.PAD_ID] = 0\n",
    "        if self.use_cuda:\n",
    "            weight = weight.cuda()\n",
    "        return torch.nn.NLLLoss(weight=weight).cuda()\n",
    "\n",
    "    def get_loss(self, decoder_outputs, targets):\n",
    "        b = decoder_outputs.size(1)\n",
    "        t = decoder_outputs.size(0)\n",
    "        targets = targets.contiguous().view(-1)  # S = (B*T)\n",
    "        decoder_outputs = decoder_outputs.view(b * t, -1)  # S = (B*T) x V\n",
    "        return self.criterion(decoder_outputs, targets)\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_name)\n",
    "        np.savez('loss.npz', train_loss=self.loss_list, score=self.score)\n",
    "        print(\"Model has been saved as %s.\\n\" % self.checkpoint_name)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.checkpoint_name, map_location='cpu'))\n",
    "        print(\"Pretrained model has been loaded.\\n\")\n",
    "\n",
    "    def evaluate(self, words):\n",
    "        # make sure that words is list\n",
    "        if type(words) is not list:\n",
    "            words = [words]\n",
    "\n",
    "        # transform word to index-sequence\n",
    "        eval_var = self.data_transformer.evaluation_batch(words=words)\n",
    "        decoded_indices = self.model.evaluate(eval_var)\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(self.data_transformer.vocab.indices_to_sequence(indices))\n",
    "        return results\n",
    "    \n",
    "    def compute_bleu(self, output, reference):\n",
    "        cc = SmoothingFunction()\n",
    "        if len(reference) == 3:\n",
    "            weights = (0.33,0.33,0.33)\n",
    "        else:\n",
    "            weights = (0.25,0.25,0.25,0.25)\n",
    "        return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  2.3732402\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  1.9252355\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  1.5030504\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  1.2731693\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  1.133544\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.94207287\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.8997877\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict: aaoondadnned \tScore:  0.05638\n",
      "True:         abet \tPredict:    baataates \tScore:  0.03391\n",
      "True:        begin \tPredict:   beginginng \tScore:  0.39281\n",
      "True:       expend \tPredict:   expenndndd \tScore:  0.43472\n",
      "True:         sent \tPredict:    snsesttns \tScore:  0.06031\n",
      "True:        split \tPredict:    spllilits \tScore:  0.19071\n",
      "True:       flared \tPredict:   faaralledd \tScore:  0.06985\n",
      "True:  functioning \tPredict: fontinuuiiing \tScore:  0.12356\n",
      "True:  functioning \tPredict: fontinuuiiing \tScore:  0.12356\n",
      "True:      healing \tPredict: allalilzingg \tScore:  0.13546\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.58284944\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.70567596\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.3785377\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.3193364\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.2798244\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.34854248\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.19290222\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict: abaonoadannd \tScore:  0.13101\n",
      "True:         abet \tPredict:    abbetaats \tScore:  0.14114\n",
      "True:        begin \tPredict:    beginninn \tScore:  0.44632\n",
      "True:       expend \tPredict:  expendended \tScore:  0.46174\n",
      "True:         sent \tPredict:    snseettnt \tScore:  0.07172\n",
      "True:        split \tPredict:    splitiltt \tScore:  0.44632\n",
      "True:       flared \tPredict:   flarrealed \tScore:  0.33032\n",
      "True:  functioning \tPredict: fonticounining \tScore:  0.27226\n",
      "True:  functioning \tPredict: fonticounining \tScore:  0.27226\n",
      "True:      healing \tPredict:  allaighhing \tScore:  0.12278\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.07804044\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.058118206\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.11759711\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.18109338\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.03148159\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.024052437\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.01929275\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:  abanodaanie \tScore:  0.26986\n",
      "True:         abet \tPredict:    abbetates \tScore:  0.14114\n",
      "True:        begin \tPredict:    beginenin \tScore:  0.44632\n",
      "True:       expend \tPredict:  expendended \tScore:  0.46174\n",
      "True:         sent \tPredict:    sesnettin \tScore:  0.06031\n",
      "True:        split \tPredict:    splimittt \tScore:  0.33913\n",
      "True:       flared \tPredict:   flarreledd \tScore:  0.33032\n",
      "True:  functioning \tPredict: fonctiounining \tScore:  0.49862\n",
      "True:  functioning \tPredict: fonctiounining \tScore:  0.49862\n",
      "True:      healing \tPredict:  aleaighting \tScore:  0.13712\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.013067828\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00877113\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.007195288\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.005884258\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.006441163\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0043576853\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.004782646\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:  abanodanien \tScore:  0.26986\n",
      "True:         abet \tPredict:    abetartes \tScore:  0.29847\n",
      "True:        begin \tPredict:    beginenin \tScore:  0.44632\n",
      "True:       expend \tPredict:  expendended \tScore:  0.46174\n",
      "True:         sent \tPredict:     senstent \tScore:  0.19441\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarreled \tScore:  0.37531\n",
      "True:  functioning \tPredict: fonctiounning \tScore:  0.54238\n",
      "True:  functioning \tPredict: fonctiounning \tScore:  0.54238\n",
      "True:      healing \tPredict:  aleaighting \tScore:  0.13712\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.003381153\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0029703754\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0033611327\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0025730191\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0021400624\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.002650361\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.002379291\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:  abanodanies \tScore:  0.26986\n",
      "True:         abet \tPredict:     abetarte \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginenin \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:     senstent \tScore:  0.19441\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarreled \tScore:  0.37531\n",
      "True:  functioning \tPredict: fonctiounncing \tScore:  0.41374\n",
      "True:  functioning \tPredict: fonctiounncing \tScore:  0.41374\n",
      "True:      healing \tPredict:  aleaighting \tScore:  0.13712\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0017951153\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0018023162\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0017499999\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0015344362\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0013826315\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0012680067\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0012335337\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:  abanodanies \tScore:  0.26986\n",
      "True:         abet \tPredict:     abetarte \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginends \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:     senstent \tScore:  0.19441\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarmered \tScore:  0.41535\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:      healing \tPredict:   aleailhing \tScore:  0.15353\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0010548027\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0010531048\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 150 char-loss:  0.00093418674\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.00093457237\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.00076817564\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0006836713\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0007209144\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:  abanodanies \tScore:  0.26986\n",
      "True:         abet \tPredict:     abetarte \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginends \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:     senstent \tScore:  0.19441\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarkeled \tScore:  0.35495\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:      healing \tPredict:   aleailhing \tScore:  0.15353\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0007232064\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.00056190323\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0005863253\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0005533559\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0005170237\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00050713477\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.00045248808\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:   abanodanat \tScore:  0.30214\n",
      "True:         abet \tPredict:     abetarte \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginends \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:     senstent \tScore:  0.19441\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarmered \tScore:  0.41535\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:      healing \tPredict:   aleailhing \tScore:  0.15353\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0004337357\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0005030248\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.00035055037\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0003718425\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.00034505874\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00037757572\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.00033458296\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:   abanodanat \tScore:  0.30214\n",
      "True:         abet \tPredict:     abetates \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginends \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:      sensten \tScore:  0.17567\n",
      "True:        split \tPredict:   splimittes \tScore:  0.29847\n",
      "True:       flared \tPredict:    flarmered \tScore:  0.41535\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:  functioning \tPredict: functionuling \tScore:  0.67034\n",
      "True:      healing \tPredict:   aleaihting \tScore:  0.15353\n",
      "======================================================\n",
      "\n",
      "Step: 50 char-loss:  0.00032022753\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0003312862\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0002691954\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 200 char-loss:  0.00025073186\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 250 char-loss:  0.00022540613\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 300 char-loss:  0.00022024866\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Step: 350 char-loss:  0.00023668043\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_gru.pt.\n",
      "\n",
      "======================Evaluating======================\n",
      "True:      abandon \tPredict:   abanodanat \tScore:  0.30214\n",
      "True:         abet \tPredict:     abetates \tScore:  0.34572\n",
      "True:        begin \tPredict:    beginends \tScore:  0.44632\n",
      "True:       expend \tPredict:   expendende \tScore:  0.51697\n",
      "True:         sent \tPredict:      sensten \tScore:  0.17567\n",
      "True:        split \tPredict:    splimitts \tScore:  0.33913\n",
      "True:       flared \tPredict:    flarkeled \tScore:  0.35495\n",
      "True:  functioning \tPredict: fonctiounaning \tScore:  0.49862\n",
      "True:  functioning \tPredict: fonctiounaning \tScore:  0.49862\n",
      "True:      healing \tPredict:   aleailhing \tScore:  0.15353\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define our models\n",
    "encoder = Encoder(vocab_size=train_loader.vocab_size,\n",
    "                         embedding_size=256,\n",
    "                         output_size=256,\n",
    "                         lat_dim=32).to(device)\n",
    "\n",
    "decoder = Decoder(hidden_size=256,\n",
    "                         output_size=train_loader.vocab_size,\n",
    "                         lat_dim=32,\n",
    "                         max_length=train_loader.max_length,\n",
    "                         teacher_forcing_ratio=1.,\n",
    "                         sos_id=train_loader.SOS_ID,\n",
    "                         use_cuda=True).to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder=encoder,\n",
    "                  decoder=decoder)\n",
    "\n",
    "trainer = Trainer(seq2seq, train_loader, learning_rate=0.001, use_cuda=True, checkpoint_name=checkpoint_name)\n",
    "\n",
    "for epoch in range(10):\n",
    "    trainer.train(num_epochs=10, batch_size=128, pretrained=False)\n",
    "    \n",
    "    ## eval\n",
    "    print(\"======================Evaluating======================\")  \n",
    "    total_score = 0.0\n",
    "    for src in test_src:\n",
    "        word = vocab.indices_to_sequence(src)\n",
    "        results = trainer.evaluate(word)[0]\n",
    "        score = trainer.compute_bleu(results, word)\n",
    "        print(\"True: {:>12}\".format(word), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "        total_score += score\n",
    "    total_score /= len(test_src)\n",
    "    trainer.score.append(total_score)\n",
    "    print(\"======================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    acc = np.load('loss.npz')\n",
    "    train_loss = acc['train_loss']\n",
    "    score = acc['score']\n",
    "\n",
    "# plt.title(\"Activation Function comparision(EEGNet)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(train_loss)+1)\n",
    "plt.plot(x, train_loss, label=\"train\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(score)+1)\n",
    "plt.plot(x, score, label=\"score\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
