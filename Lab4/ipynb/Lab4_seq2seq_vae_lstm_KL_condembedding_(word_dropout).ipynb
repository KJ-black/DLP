{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from Data import *\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import  pack_padded_sequence, pad_packed_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_name = 'Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt'\n",
    "loss_file = \"Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout)_loss.npz\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = 0\n",
    "tp = 1\n",
    "pg = 2\n",
    "p = 3\n",
    "\n",
    "def split_data(data):\n",
    "    split_data = []\n",
    "    for string in data:\n",
    "        split_space = string.split()\n",
    "        for i, word in enumerate(split_space):\n",
    "            split_data.append(word)\n",
    "    return split_data\n",
    "\n",
    "def y_train_make(n):\n",
    "    np_sp = np.array([sp])\n",
    "    np_tp = np.array([tp])\n",
    "    np_pg = np.array([pg])\n",
    "    np_p = np.array([p])\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np_sp)\n",
    "        y.append(np_tp)\n",
    "        y.append(np_pg)\n",
    "        y.append(np_p)\n",
    "    return np.array(y)\n",
    "\n",
    "def src_trg_split(data):\n",
    "    src = []\n",
    "    trg = []\n",
    "    for i in range(0, len(data), 2):\n",
    "        src.append(data[i])\n",
    "        trg.append(data[i+1])\n",
    "    return np.array(src), np.array(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = np.squeeze(pd.read_csv('train.txt', header=None))\n",
    "\n",
    "y_train = y_train_make(len(train_data))\n",
    "\n",
    "def to_one_hot(label):\n",
    "    one_hot =  np.zeros((len(label), 4))\n",
    "    one_hot[np.arange(len(label)), label[:, 0]] = 1\n",
    "    return one_hot\n",
    "    \n",
    "# y_train = to_one_hot(y_train)\n",
    "train_data = split_data(train_data)\n",
    "train_loader = DataTransformer(train_data, y_train, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.squeeze(pd.read_csv('test.txt', header=None))\n",
    "test_data = split_data(test_data)\n",
    "test_data = np.array(test_data)\n",
    "src, trg = src_trg_split(test_data)\n",
    "test_src = []\n",
    "test_trg = []\n",
    "\n",
    "for word in src:\n",
    "    test_src.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\n",
    "for word in trg:\n",
    "    test_trg.append(train_loader.vocab.sequence_to_indices(word, add_eos=True))\n",
    "\"\"\"\n",
    "sp -> p\n",
    "sp -> pg\n",
    "sp -> tp\n",
    "sp -> tp\n",
    "p  -> tp\n",
    "sp -> pg\n",
    "p  -> sp\n",
    "pg -> sp\n",
    "pg -> p\n",
    "pg -> tp\n",
    "\"\"\"\n",
    "test_c_src = np.array([sp, sp, sp, sp, p, sp, p, pg, pg, pg]).reshape(-1, 1)\n",
    "test_c_trg = np.array([p, pg, tp, tp, tp, pg, sp, sp, p, tp]).reshape(-1, 1)\n",
    "# test_c_src = Variable(torch.LongTensor(to_one_hot(test_c_src))).to(device)\n",
    "test_c_src = Variable(torch.LongTensor(test_c_src)).to(device)\n",
    "# test_c_trg = Variable(torch.LongTensor(to_one_hot(test_c_trg))).to(device)\n",
    "test_c_trg = Variable(torch.LongTensor(test_c_trg)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():    \n",
    "        src_c = test_src\n",
    "        trg_c = test_trg\n",
    "        optimizer.zero_grad()            \n",
    "        output = model(src, trg, src_c, trg_c, 0) #turn off teacher forcing\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"=========show testing result=========\")\n",
    "            for i in range(output.shape[-1]):\n",
    "                show_result(trg, output, i)\n",
    "                print()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "def show_result(target, output, index):\n",
    "    print(\"Ground true: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        tmp = trg[index, i]\n",
    "        if tmp == 1:\n",
    "            break\n",
    "        elif tmp == 0:\n",
    "            continue\n",
    "        print(chr(trg[index, i]-7+ord('a')), end=\"\")\n",
    "    \n",
    "    print(\" Predict: \", end=\"\")\n",
    "    for i in range(max_len):\n",
    "        print(chr(np.argmax(o[index, i, 3:])-4+ord('a')), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, output_size, lat_dim):\n",
    "        \"\"\"Define layers for a vanilla rnn encoder\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.cond_embedding = nn.Embedding(4, 8)\n",
    "        self.fc = nn.Linear(self.embedding_size+8, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, output_size)\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(output_size, lat_dim)\n",
    "        self.hidden2logv = nn.Linear(output_size, lat_dim)\n",
    "        \n",
    "        self.cell2mean = nn.Linear(output_size, lat_dim)\n",
    "        self.cell2logv = nn.Linear(output_size, lat_dim)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, label, hidden=None, cell=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lengths)\n",
    "        label = label.view(1, -1)\n",
    "        label = self.cond_embedding(label)\n",
    "        hidden = torch.cat([hidden, label], dim=2)\n",
    "        hidden = self.fc(hidden)\n",
    "        cell = hidden\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed, (hidden, cell))\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        hidden_means = self.hidden2mean(hidden)\n",
    "        hidden_logv = self.hidden2logv(hidden)\n",
    "        \n",
    "        cell_means = self.cell2mean(cell)\n",
    "        cell_logv = self.cell2logv(cell)\n",
    "        \n",
    "        return outputs, hidden_means, hidden_logv, cell_means, cell_logv\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros([1, batch_size, self.embedding_size]) # (D * num_layers, batch_size, H_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, lat_dim, max_length, teacher_forcing_ratio, sos_id, use_cuda):\n",
    "        \"\"\"Define layers for a vanilla rnn decoder\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.word_dropout_rate = 0\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.cond_embedding = nn.Embedding(4, 8)\n",
    "        self.latent2hidden = nn.Linear(lat_dim+8, hidden_size)\n",
    "        self.latent2cell = nn.Linear(lat_dim+8, hidden_size)\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)  # work with NLLLoss = CrossEntropyLoss\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.sos_id = sos_id\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward_step(self, inputs, hidden, cell):\n",
    "        # inputs: (time_steps=1, batch_size)\n",
    "        batch_size = inputs.size(1)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded.view(1, batch_size, self.hidden_size)  # S = T(1) x B x N\n",
    "        rnn_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))  # S = T(1) x B x H\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze the time dimension\n",
    "        output = self.log_softmax(self.out(rnn_output))  # S = B x O\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def forward(self, context_vector, decoder_cell, targets):\n",
    "\n",
    "        # Prepare variable for decoder on time_step_0\n",
    "        target_vars, target_lengths = targets\n",
    "        batch_size = context_vector.size(1)\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "\n",
    "        # Pass the context vector\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            max_target_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "            \n",
    "        if self.word_dropout_rate:\n",
    "            prob = torch.rand(decoder_input.size()).to(device)\n",
    "            prob[(decoder_input.data - train_loader.vocab.char2idx[\"SOS\"]) * (decoder_input.data - train_loader.vocab.char2idx['PAD']) == 0] = 1\n",
    "            decoder_input[prob < self.word_dropout_rate] = train_loader.vocab.char2idx['UNK']\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(max_target_length):\n",
    "            decoder_outputs_on_t, decoder_hidden, decoder_cell = self.forward_step(decoder_input, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_vars[t].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input = self._decode_to_index(decoder_outputs_on_t)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, decoder_cell\n",
    "\n",
    "    def evaluate(self, context_vector, decoder_cell):\n",
    "        batch_size = context_vector.size(1) # get the batch size\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "        decoder_hidden = context_vector\n",
    "\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            self.max_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(self.max_length):\n",
    "            decoder_outputs_on_t, decoder_hidden, decoder_cell = self.forward_step(decoder_input, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            decoder_input = self._decode_to_index(decoder_outputs_on_t)  # select the former output as input\n",
    "\n",
    "        return self._decode_to_indices(decoder_outputs)\n",
    "\n",
    "    def _decode_to_index(self, decoder_output):\n",
    "        \"\"\"\n",
    "        evaluate on the logits, get the index of top1\n",
    "        :param decoder_output: S = B x V or T x V\n",
    "        \"\"\"\n",
    "        value, index = torch.topk(decoder_output, 1)\n",
    "        index = index.transpose(0, 1)  # S = 1 x B, 1 is the index of top1 class\n",
    "        if self.use_cuda:\n",
    "            index = index.cuda()\n",
    "        return index\n",
    "\n",
    "    def _decode_to_indices(self, decoder_outputs):\n",
    "        \"\"\"\n",
    "        Evaluate on the decoder outputs(logits), find the top 1 indices.\n",
    "        Please confirm that the model is on evaluation mode if dropout/batch_norm layers have been added\n",
    "        :param decoder_outputs: the output sequence from decoder, shape = T x B x V \n",
    "        \"\"\"\n",
    "        decoded_indices = []\n",
    "        batch_size = decoder_outputs.size(1)\n",
    "        decoder_outputs = decoder_outputs.transpose(0, 1)  # S = B x T x V\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            top_ids = self._decode_to_index(decoder_outputs[b])\n",
    "            decoded_indices.append(top_ids.data[0].cpu().numpy())\n",
    "        return decoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs, targets, label):\n",
    "        # variables\n",
    "        input_vars, input_lengths = inputs\n",
    "        batch_size = input_vars.shape[1]\n",
    "        encoder_hidden = self.encoder.initHidden(batch_size).to(device)\n",
    "        encoder_cell = self.encoder.initHidden(batch_size).to(device)\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "            self.encoder.forward(input_vars, input_lengths, label, hidden=encoder_hidden, cell=encoder_cell)  \n",
    "\n",
    "        # reparaterization trick\n",
    "        encoder_hidden = self.reparaterization_trick(hidden_means, hidden_logv)\n",
    "        encoder_cell = self.reparaterization_trick(cell_means, cell_logv)\n",
    "        label = label.view(1, -1)\n",
    "        label = self.decoder.cond_embedding(label)\n",
    "        encoder_hidden = torch.cat([encoder_hidden, label], dim=2)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        encoder_cell = torch.cat([encoder_cell, label], dim=2)\n",
    "        encoder_cell = self.decoder.latent2cell(encoder_cell)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_outputs, decoder_hidden, decoder_cell = self.decoder.forward(context_vector=encoder_hidden, \n",
    "                                                               decoder_cell=encoder_cell, targets=targets)\n",
    "        \n",
    "        return decoder_outputs, decoder_hidden, hidden_means, hidden_logv, cell_means, cell_logv\n",
    "\n",
    "    def evaluate(self, inputs, src_label, trg_label):\n",
    "        # variables\n",
    "        input_vars, input_lengths = inputs\n",
    "        batch_size = input_vars.shape[1]\n",
    "        encoder_hidden = self.encoder.initHidden(batch_size).to(device)\n",
    "        encoder_cell = self.encoder.initHidden(batch_size).to(device)\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "            self.encoder.forward(input_vars, input_lengths, src_label, hidden=encoder_hidden, cell=encoder_cell)  \n",
    "\n",
    "        # reparaterization trick\n",
    "        encoder_hidden = self.reparaterization_trick(hidden_means, hidden_logv)\n",
    "        encoder_cell = self.reparaterization_trick(cell_means, cell_logv)\n",
    "        trg_label = trg_label.view(1, -1)\n",
    "        trg_label = self.decoder.cond_embedding(trg_label)\n",
    "        encoder_hidden = torch.cat([encoder_hidden, trg_label], dim=2)\n",
    "        encoder_hidden = self.decoder.latent2hidden(encoder_hidden)\n",
    "        encoder_cell = torch.cat([encoder_cell, trg_label], dim=2)\n",
    "        encoder_cell = self.decoder.latent2cell(encoder_cell)\n",
    "        \n",
    "        # decoder\n",
    "        decoded_sentence = self.decoder.evaluate(context_vector=encoder_hidden, decoder_cell=encoder_cell)\n",
    "        \n",
    "        return decoded_sentence\n",
    "    \n",
    "    def reparaterization_trick(self, mean, logv):\n",
    "        std = torch.exp(0.5*logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return  mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, data_transformer, label, learning_rate, use_cuda, checkpoint_name,\n",
    "                 teacher_forcing_ratio=1.0, kl_weight=0, word_dropout_rate=0):\n",
    "\n",
    "        self.model = model\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "        self.total_iter = 0\n",
    "        \n",
    "        # save list\n",
    "        self.entropy = []\n",
    "        self.kld = []\n",
    "        self.kl_weight_list = []\n",
    "        self.teacher_forcing_ratio_list = []\n",
    "        self.score = []\n",
    "        \n",
    "        # init hyperparameters\n",
    "        self.kl_weight = kl_weight\n",
    "        self.model.decoder.word_dropout_rate = word_dropout_rate\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.kl_weight_list.append(self.kl_weight)\n",
    "        self.teacher_forcing_ratio_list.append(self.teacher_forcing_ratio)\n",
    "        \n",
    "        # record some information about dataset\n",
    "        self.data_transformer = data_transformer\n",
    "        self.label = label\n",
    "        self.vocab_size = self.data_transformer.vocab_size\n",
    "        self.PAD_ID = self.data_transformer.PAD_ID\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        # optimizer setting\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer= torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "#         self.optimizer= torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = torch.nn.NLLLoss(ignore_index=self.PAD_ID, reduction='mean')\n",
    "\n",
    "    def train(self, num_epochs, batch_size, pretrained=False):\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_model()\n",
    "        \n",
    "        self.model.train()\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            mini_batches = self.data_transformer.mini_batches(batch_size=batch_size)\n",
    "            for input_batch, target_batch, label_batch in mini_batches:\n",
    "                self.total_iter += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                self.model.decoder.teacher_forcing_ratio = self.teacher_forcing_ratio\n",
    "                decoder_outputs, decoder_hidden, hidden_means, hidden_logv, cell_means, cell_logv = \\\n",
    "                    self.model(input_batch, target_batch, label_batch)\n",
    "\n",
    "                # calculate the loss and back prop.\n",
    "                cur_loss = self.get_loss(decoder_outputs, target_batch[0])\n",
    "                kl_loss = self.kl_weight * self.get_kl_loss(hidden_means, hidden_logv)+\\\n",
    "                            self.kl_weight* self.get_kl_loss(cell_means, cell_logv)\n",
    "                loss = cur_loss + kl_loss\n",
    "                \n",
    "                self.entropy.append(cur_loss.item())\n",
    "                self.kld.append(kl_loss.item())\n",
    "                \n",
    "                # logging\n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Step:\", step, \"char-loss: \", loss.item())\n",
    "                    print(\"KL_weight: \", self.kl_weight, \"teacher_forcing_ratio: \", self.teacher_forcing_ratio)\n",
    "                    self.save_model()\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # update hyperparameters\n",
    "                self.kl_weight = self.get_kl_weight(self.kl_weight)\n",
    "                self.model.decoder.word_dropout_rate = self.get_word_dropout_rate(self.model.decoder.word_dropout_rate)\n",
    "                self.teacher_forcing_ratio = self.get_teacher_forcing_ratio(self.teacher_forcing_ratio)\n",
    "                self.kl_weight_list.append(self.kl_weight)\n",
    "                self.teacher_forcing_ratio_list.append(self.teacher_forcing_ratio)\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def get_loss(self, decoder_outputs, targets):\n",
    "        b = decoder_outputs.size(1)\n",
    "        t = decoder_outputs.size(0)\n",
    "        targets = targets.contiguous().view(-1)  # S = (B*T)\n",
    "        decoder_outputs = decoder_outputs.view(b * t, -1)  # S = (B*T) x V\n",
    "        return self.criterion(decoder_outputs, targets)\n",
    "    \n",
    "    def get_kl_loss(self, mean, logvar):\n",
    "        result = -0.5 * torch.sum(logvar - torch.pow(mean, 2) - torch.exp(logvar) + 1, 1)\n",
    "        return result.mean()\n",
    "    \n",
    "    def get_kl_weight(self, kl_weight):\n",
    "#         return 0\n",
    "#         if self.total_iter < 50000:\n",
    "#             return 0\n",
    "#         else:\n",
    "#         return 0\n",
    "        return min(1, kl_weight + 0.0000001)\n",
    "\n",
    "    def get_word_dropout_rate(self, word_dropout_rate):\n",
    "#         if self.total_iter < 50000:\n",
    "#             return 0\n",
    "#         else:\n",
    "#         return 0\n",
    "        return 0\n",
    "#         return min(1, word_dropout_rate + 0.000001)\n",
    "\n",
    "    def get_teacher_forcing_ratio(self, teacher_forcing_ratio):\n",
    "#         if self.total_iter < 100000:\n",
    "#             return 1\n",
    "#         else:\n",
    "        return max(0, teacher_forcing_ratio - 0.00000001)\n",
    "#         return 1\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_name)\n",
    "        np.savez(loss_file, entropy=self.entropy, kld=self.kld, kl_weight=self.kl_weight_list,\\\n",
    "                 teacher_forcing_ratio=self.teacher_forcing_ratio_list, score=self.score)\n",
    "        print(\"Model has been saved as %s.\\n\" % self.checkpoint_name)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.checkpoint_name, map_location=device))\n",
    "        load_file = np.load(loss_file)\n",
    "        self.entropy = load_file['entropy'].tolist()\n",
    "        self.kld = load_file['kld'].tolist()\n",
    "        self.kl_weight_list = load_file['kl_weight'].tolist()\n",
    "        self.teacher_forcing_ratio_list = load_file['teacher_forcing_ratio'].tolist()\n",
    "        self.score = load_file['score'].tolist()\n",
    "        print(\"Pretrained model has been loaded.\\n\")\n",
    "\n",
    "    def evaluate(self, words, src_label, trg_label):\n",
    "        # make sure that words is list\n",
    "        if type(words) is not list:\n",
    "            words = [words]\n",
    "        self.model.eval()\n",
    "        # transform word to index-sequence\n",
    "        eval_var = self.data_transformer.evaluation_batch(words=words)\n",
    "        decoded_indices = self.model.evaluate(eval_var, src_label, trg_label)\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(self.data_transformer.vocab.indices_to_sequence(indices))\n",
    "        return results\n",
    "    \n",
    "    def compute_bleu(self, output, reference):\n",
    "        cc = SmoothingFunction()\n",
    "        if len(reference) == 3:\n",
    "            weights = (0.33,0.33,0.33)\n",
    "        else:\n",
    "            weights = (0.25,0.25,0.25,0.25)\n",
    "        return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our models\n",
    "encoder = Encoder(vocab_size=train_loader.vocab_size,\n",
    "                         embedding_size=256,\n",
    "                         output_size=256,\n",
    "                         lat_dim=32).to(device)\n",
    "\n",
    "decoder = Decoder(hidden_size=256,\n",
    "                         output_size=train_loader.vocab_size,\n",
    "                         lat_dim=32,\n",
    "                         max_length=train_loader.max_length,\n",
    "                         teacher_forcing_ratio=1.,\n",
    "                         sos_id=train_loader.SOS_ID,\n",
    "                         use_cuda=True).to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder=encoder,\n",
    "                  decoder=decoder)\n",
    "\n",
    "trainer = Trainer(seq2seq, train_loader, y_train, learning_rate=0.001, use_cuda=True, checkpoint_name=checkpoint_name, \n",
    "                        teacher_forcing_ratio=1, kl_weight=0, word_dropout_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f7353b75e4c85996c830d7061b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  1.9408141374588013\n",
      "KL_weight:  4.899999999999996e-06 teacher_forcing_ratio:  0.9999995099999975\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  1.344679355621338\n",
      "KL_weight:  9.90000000000001e-06 teacher_forcing_ratio:  0.999999009999995\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.791664183139801\n",
      "KL_weight:  1.4900000000000047e-05 teacher_forcing_ratio:  0.9999985099999925\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.4624713659286499\n",
      "KL_weight:  1.9900000000000006e-05 teacher_forcing_ratio:  0.99999800999999\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.29705867171287537\n",
      "KL_weight:  2.4899999999999958e-05 teacher_forcing_ratio:  0.9999975099999875\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.19081251323223114\n",
      "KL_weight:  2.989999999999991e-05 teacher_forcing_ratio:  0.999997009999985\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.14352202415466309\n",
      "KL_weight:  3.490000000000001e-05 teacher_forcing_ratio:  0.9999965099999825\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abnasched \tScore:  0.07937\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abseltenc \tScore:  0.06377\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    belinages \tScore:  0.07937\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   explencats \tScore:  0.13747\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     snectals \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splechast \tScore:  0.12753\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarelshed \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionules \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funchitounes \tScore:  0.27902\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heallinges \tScore:  0.27776\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.10906705260276794\n",
      "KL_weight:  4.390000000000023e-05 teacher_forcing_ratio:  0.9999956099999779\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.08296433091163635\n",
      "KL_weight:  4.890000000000035e-05 teacher_forcing_ratio:  0.9999951099999754\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07637695968151093\n",
      "KL_weight:  5.390000000000047e-05 teacher_forcing_ratio:  0.9999946099999729\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.07576797157526016\n",
      "KL_weight:  5.890000000000059e-05 teacher_forcing_ratio:  0.9999941099999704\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.059896718710660934\n",
      "KL_weight:  6.390000000000071e-05 teacher_forcing_ratio:  0.9999936099999679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.07067643105983734\n",
      "KL_weight:  6.890000000000083e-05 teacher_forcing_ratio:  0.9999931099999654\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.05779989808797836\n",
      "KL_weight:  7.390000000000096e-05 teacher_forcing_ratio:  0.9999926099999629\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abnocaled \tScore:  0.08249\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  beasletcing \tScore:  0.13712\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   beglinstes \tScore:  0.17567\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   explenceds \tScore:  0.15353\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sneltects \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splletcims \tScore:  0.11868\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  flarreltsed \tScore:  0.26658\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fincurtonek \tScore:  0.06704\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionchied \tScore:  0.61154\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helachizes \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0692126601934433\n",
      "KL_weight:  8.290000000000117e-05 teacher_forcing_ratio:  0.9999917099999583\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06391968578100204\n",
      "KL_weight:  8.79000000000013e-05 teacher_forcing_ratio:  0.9999912099999558\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.05140228569507599\n",
      "KL_weight:  9.290000000000142e-05 teacher_forcing_ratio:  0.9999907099999533\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.057934608310461044\n",
      "KL_weight:  9.790000000000154e-05 teacher_forcing_ratio:  0.9999902099999508\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.05610581487417221\n",
      "KL_weight:  0.00010290000000000166 teacher_forcing_ratio:  0.9999897099999483\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.059513650834560394\n",
      "KL_weight:  0.00010790000000000178 teacher_forcing_ratio:  0.9999892099999458\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.055755965411663055\n",
      "KL_weight:  0.0001129000000000019 teacher_forcing_ratio:  0.9999887099999433\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abnachoreding \tScore:  0.05526\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abseltching \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begliches \tScore:  0.13485\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experclemed \tScore:  0.24808\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sneltces \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   splletcins \tScore:  0.13747\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarelsted \tScore:  0.39281\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functishoning \tScore:  0.42803\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionules \tScore:  0.63156\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  helarifates \tScore:  0.05013\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.059650860726833344\n",
      "KL_weight:  0.00012190000000000212 teacher_forcing_ratio:  0.9999878099999387\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.05905656889081001\n",
      "KL_weight:  0.00012690000000000224 teacher_forcing_ratio:  0.9999873099999362\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.057435184717178345\n",
      "KL_weight:  0.00013190000000000237 teacher_forcing_ratio:  0.9999868099999337\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.06158626079559326\n",
      "KL_weight:  0.0001369000000000025 teacher_forcing_ratio:  0.9999863099999312\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.10779936611652374\n",
      "KL_weight:  0.0001419000000000026 teacher_forcing_ratio:  0.9999858099999287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.06035707890987396\n",
      "KL_weight:  0.00014690000000000273 teacher_forcing_ratio:  0.9999853099999262\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.05543780326843262\n",
      "KL_weight:  0.00015190000000000285 teacher_forcing_ratio:  0.9999848099999237\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abnoacksend \tScore:  0.06704\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  beastlering \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  begloincase \tScore:  0.12278\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expencleds \tScore:  0.45180\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     sentlecs \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   spllutcins \tScore:  0.13747\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flarcheser \tScore:  0.27776\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functoincize \tScore:  0.35655\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funcotincized \tScore:  0.27629\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  helachianes \tScore:  0.05013\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.054919175803661346\n",
      "KL_weight:  0.00016090000000000307 teacher_forcing_ratio:  0.9999839099999192\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06031990051269531\n",
      "KL_weight:  0.0001659000000000032 teacher_forcing_ratio:  0.9999834099999166\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.051801059395074844\n",
      "KL_weight:  0.00017090000000000331 teacher_forcing_ratio:  0.9999829099999141\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.05481356754899025\n",
      "KL_weight:  0.00017590000000000344 teacher_forcing_ratio:  0.9999824099999116\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.06275039911270142\n",
      "KL_weight:  0.00018090000000000356 teacher_forcing_ratio:  0.9999819099999091\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.05909865349531174\n",
      "KL_weight:  0.00018590000000000368 teacher_forcing_ratio:  0.9999814099999066\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.05386655032634735\n",
      "KL_weight:  0.0001909000000000038 teacher_forcing_ratio:  0.9999809099999041\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonfarbed \tScore:  0.07176\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abstelering \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  begloinshes \tScore:  0.15690\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expenchased \tScore:  0.38163\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snetlucses \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  splelturins \tScore:  0.12278\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flersalted \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: functionchie \tScore:  0.61323\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionched \tScore:  0.67042\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helabishes \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.06701560318470001\n",
      "KL_weight:  0.00019990000000000402 teacher_forcing_ratio:  0.9999800099998996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06473176181316376\n",
      "KL_weight:  0.00020490000000000414 teacher_forcing_ratio:  0.999979509999897\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.057560332119464874\n",
      "KL_weight:  0.00020990000000000426 teacher_forcing_ratio:  0.9999790099998945\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.06542842835187912\n",
      "KL_weight:  0.00021490000000000438 teacher_forcing_ratio:  0.999978509999892\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.06231715902686119\n",
      "KL_weight:  0.0002199000000000045 teacher_forcing_ratio:  0.9999780099998895\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.06558263301849365\n",
      "KL_weight:  0.00022490000000000463 teacher_forcing_ratio:  0.999977509999887\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.06406920403242111\n",
      "KL_weight:  0.00022990000000000475 teacher_forcing_ratio:  0.9999770099998845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: ancountareld \tScore:  0.04927\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  adeltuncesh \tScore:  0.02666\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  begerilants \tScore:  0.11095\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expescentered \tScore:  0.23901\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentluctes \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: spletslibing \tScore:  0.16109\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   slrefforme \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionule \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  funticonues \tScore:  0.14601\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: healherating \tScore:  0.21201\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.059411272406578064\n",
      "KL_weight:  0.00023890000000000497 teacher_forcing_ratio:  0.99997610999988\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06984502077102661\n",
      "KL_weight:  0.0002439000000000051 teacher_forcing_ratio:  0.9999756099998774\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.06724364310503006\n",
      "KL_weight:  0.0002489000000000052 teacher_forcing_ratio:  0.9999751099998749\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.07151972502470016\n",
      "KL_weight:  0.0002539000000000053 teacher_forcing_ratio:  0.9999746099998724\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.06293406337499619\n",
      "KL_weight:  0.0002589000000000054 teacher_forcing_ratio:  0.9999741099998699\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.06724397093057632\n",
      "KL_weight:  0.00026390000000000555 teacher_forcing_ratio:  0.9999736099998674\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.06450389325618744\n",
      "KL_weight:  0.00026890000000000567 teacher_forcing_ratio:  0.9999731099998649\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   anforathed \tScore:  0.06985\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: bestallening \tScore:  0.11531\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begreakins \tScore:  0.17567\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expenscertes \tScore:  0.33181\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sentelshing \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splestrifling \tScore:  0.14694\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    fleracuse \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fintcountering \tScore:  0.04272\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funchiotuned \tScore:  0.35084\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helearigns \tScore:  0.06674\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.0692005455493927\n",
      "KL_weight:  0.0002779000000000059 teacher_forcing_ratio:  0.9999722099998604\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0705205500125885\n",
      "KL_weight:  0.000282900000000006 teacher_forcing_ratio:  0.9999717099998578\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.06340228021144867\n",
      "KL_weight:  0.00028790000000000613 teacher_forcing_ratio:  0.9999712099998553\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.06850744783878326\n",
      "KL_weight:  0.00029290000000000625 teacher_forcing_ratio:  0.9999707099998528\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.06511136144399643\n",
      "KL_weight:  0.0002979000000000064 teacher_forcing_ratio:  0.9999702099998503\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.07231045514345169\n",
      "KL_weight:  0.0003029000000000065 teacher_forcing_ratio:  0.9999697099998478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0679216980934143\n",
      "KL_weight:  0.0003079000000000066 teacher_forcing_ratio:  0.9999692099998453\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonformed \tScore:  0.06905\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: abertelching \tScore:  0.14735\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  beglectings \tScore:  0.12278\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expendelses \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   senstremls \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splectlaming \tScore:  0.14735\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict: fresfarmering \tScore:  0.04647\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   functionce \tScore:  0.75984\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functiones \tScore:  0.88011\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helivances \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.06891942769289017\n",
      "KL_weight:  0.00031690000000000684 teacher_forcing_ratio:  0.9999683099998408\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.07087434828281403\n",
      "KL_weight:  0.00032190000000000696 teacher_forcing_ratio:  0.9999678099998383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07007869333028793\n",
      "KL_weight:  0.0003269000000000071 teacher_forcing_ratio:  0.9999673099998357\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.07478136569261551\n",
      "KL_weight:  0.0003319000000000072 teacher_forcing_ratio:  0.9999668099998332\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.07102061063051224\n",
      "KL_weight:  0.0003369000000000073 teacher_forcing_ratio:  0.9999663099998307\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.07077370584011078\n",
      "KL_weight:  0.00034190000000000744 teacher_forcing_ratio:  0.9999658099998282\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0754268690943718\n",
      "KL_weight:  0.00034690000000000756 teacher_forcing_ratio:  0.9999653099998257\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absnobembed \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: exhapterling \tScore:  0.10025\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begenhols \tScore:  0.13485\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expendulest \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  senstroches \tScore:  0.10025\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splemblitding \tScore:  0.17020\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   lerachende \tScore:  0.02985\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionche \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functoinconed \tScore:  0.49736\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  ehhalateses \tScore:  0.05013\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.07295800745487213\n",
      "KL_weight:  0.0003559000000000078 teacher_forcing_ratio:  0.9999644099998212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06923846900463104\n",
      "KL_weight:  0.0003609000000000079 teacher_forcing_ratio:  0.9999639099998187\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07121191918849945\n",
      "KL_weight:  0.000365900000000008 teacher_forcing_ratio:  0.9999634099998161\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.07328947633504868\n",
      "KL_weight:  0.00037090000000000815 teacher_forcing_ratio:  0.9999629099998136\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.06934911012649536\n",
      "KL_weight:  0.00037590000000000827 teacher_forcing_ratio:  0.9999624099998111\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.06790786981582642\n",
      "KL_weight:  0.0003809000000000084 teacher_forcing_ratio:  0.9999619099998086\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.07214337587356567\n",
      "KL_weight:  0.0003859000000000085 teacher_forcing_ratio:  0.9999614099998061\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absonbeando \tScore:  0.31702\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  bespatuling \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: beghesinates \tScore:  0.11095\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expendels \tScore:  0.61047\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  snetermings \tScore:  0.02666\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  sprellating \tScore:  0.28998\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   floreswale \tScore:  0.06674\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functoinate \tScore:  0.39459\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functoinced \tScore:  0.44116\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    exhalanes \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.07407566159963608\n",
      "KL_weight:  0.00039490000000000873 teacher_forcing_ratio:  0.9999605099998016\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.07067793607711792\n",
      "KL_weight:  0.00039990000000000885 teacher_forcing_ratio:  0.9999600099997991\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07284863293170929\n",
      "KL_weight:  0.000404900000000009 teacher_forcing_ratio:  0.9999595099997965\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08126019686460495\n",
      "KL_weight:  0.0004099000000000091 teacher_forcing_ratio:  0.999959009999794\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0780143067240715\n",
      "KL_weight:  0.0004149000000000092 teacher_forcing_ratio:  0.9999585099997915\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08224203437566757\n",
      "KL_weight:  0.00041990000000000934 teacher_forcing_ratio:  0.999958009999789\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.0760427787899971\n",
      "KL_weight:  0.00042490000000000946 teacher_forcing_ratio:  0.9999575099997865\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: abadonounded \tScore:  0.17364\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  absertaking \tScore:  0.12761\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begremins \tScore:  0.19960\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expescendes \tScore:  0.33933\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sentersts \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: splestalling \tScore:  0.15580\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   slayserald \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functiomate \tScore:  0.57067\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  nuffoctined \tScore:  0.17828\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     leavelds \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.07350799441337585\n",
      "KL_weight:  0.0004339000000000097 teacher_forcing_ratio:  0.999956609999782\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.07627599686384201\n",
      "KL_weight:  0.0004389000000000098 teacher_forcing_ratio:  0.9999561099997795\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.06954356282949448\n",
      "KL_weight:  0.0004439000000000099 teacher_forcing_ratio:  0.999955609999777\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.07837851345539093\n",
      "KL_weight:  0.00044890000000001004 teacher_forcing_ratio:  0.9999551099997744\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.07891926914453506\n",
      "KL_weight:  0.00045390000000001017 teacher_forcing_ratio:  0.9999546099997719\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.07749378681182861\n",
      "KL_weight:  0.0004589000000000103 teacher_forcing_ratio:  0.9999541099997694\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.07088780403137207\n",
      "KL_weight:  0.0004639000000000104 teacher_forcing_ratio:  0.9999536099997669\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abstonanyed \tScore:  0.07973\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   adecastink \tScore:  0.11868\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  besephatins \tScore:  0.11731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expespones \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    senstrats \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestilting \tScore:  0.27902\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   selarderat \tScore:  0.11224\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   cuntimbore \tScore:  0.06985\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  nutcoumined \tScore:  0.12278\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helormates \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.07241136580705643\n",
      "KL_weight:  0.00047290000000001063 teacher_forcing_ratio:  0.9999527099997624\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.06973986327648163\n",
      "KL_weight:  0.00047790000000001075 teacher_forcing_ratio:  0.9999522099997599\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0823637917637825\n",
      "KL_weight:  0.00048290000000001087 teacher_forcing_ratio:  0.9999517099997574\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08213578164577484\n",
      "KL_weight:  0.000487900000000011 teacher_forcing_ratio:  0.9999512099997548\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.07691320776939392\n",
      "KL_weight:  0.0004929000000000086 teacher_forcing_ratio:  0.9999507099997523\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.0772378146648407\n",
      "KL_weight:  0.000497900000000006 teacher_forcing_ratio:  0.9999502099997498\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.08068432658910751\n",
      "KL_weight:  0.0005029000000000034 teacher_forcing_ratio:  0.9999497099997473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: absondounged \tScore:  0.13546\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  betradgoing \tScore:  0.16307\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: bercultinges \tScore:  0.05638\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experdences \tScore:  0.28998\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   sentrotses \tScore:  0.11224\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sswelplining \tScore:  0.14735\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    darreagel \tScore:  0.07172\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionate \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: furnicteated \tScore:  0.06704\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heashailes \tScore:  0.11868\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.08322351425886154\n",
      "KL_weight:  0.0005118999999999987 teacher_forcing_ratio:  0.9999488099997428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.07704874873161316\n",
      "KL_weight:  0.0005168999999999961 teacher_forcing_ratio:  0.9999483099997403\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07613858580589294\n",
      "KL_weight:  0.0005218999999999935 teacher_forcing_ratio:  0.9999478099997378\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.07791982591152191\n",
      "KL_weight:  0.000526899999999991 teacher_forcing_ratio:  0.9999473099997352\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.08527127653360367\n",
      "KL_weight:  0.0005318999999999884 teacher_forcing_ratio:  0.9999468099997327\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08481226861476898\n",
      "KL_weight:  0.0005368999999999858 teacher_forcing_ratio:  0.9999463099997302\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.08449311554431915\n",
      "KL_weight:  0.0005418999999999832 teacher_forcing_ratio:  0.9999458099997277\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   absorbayed \tScore:  0.07731\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: bescoftreating \tScore:  0.22719\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  regishaines \tScore:  0.11731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   experedies \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    serisnets \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestillitting \tScore:  0.44285\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  dreallesser \tScore:  0.04741\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fincountorate \tScore:  0.05526\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  frinkoluted \tScore:  0.05638\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: helaormishes \tScore:  0.04529\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.09024262428283691\n",
      "KL_weight:  0.0005508999999999785 teacher_forcing_ratio:  0.9999449099997232\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0789574459195137\n",
      "KL_weight:  0.0005558999999999759 teacher_forcing_ratio:  0.9999444099997207\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0792524665594101\n",
      "KL_weight:  0.0005608999999999734 teacher_forcing_ratio:  0.9999439099997182\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08425720781087875\n",
      "KL_weight:  0.0005658999999999708 teacher_forcing_ratio:  0.9999434099997156\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.08594872802495956\n",
      "KL_weight:  0.0005708999999999682 teacher_forcing_ratio:  0.9999429099997131\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.09093409776687622\n",
      "KL_weight:  0.0005758999999999656 teacher_forcing_ratio:  0.9999424099997106\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.08984589576721191\n",
      "KL_weight:  0.000580899999999963 teacher_forcing_ratio:  0.9999419099997081\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abromanded \tScore:  0.15874\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   badgharing \tScore:  0.11868\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   degreimins \tScore:  0.13135\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   perdeacess \tScore:  0.05612\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   stermashes \tScore:  0.02778\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestalliting \tScore:  0.28656\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   dreasforde \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: furcontimane \tScore:  0.06704\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: furtconmined \tScore:  0.13546\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    tharleals \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.07979686558246613\n",
      "KL_weight:  0.0005898999999999583 teacher_forcing_ratio:  0.9999410099997036\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.08556561917066574\n",
      "KL_weight:  0.0005948999999999558 teacher_forcing_ratio:  0.9999405099997011\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.08803119510412216\n",
      "KL_weight:  0.0005998999999999532 teacher_forcing_ratio:  0.9999400099996986\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08359050005674362\n",
      "KL_weight:  0.0006048999999999506 teacher_forcing_ratio:  0.999939509999696\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.08725138753652573\n",
      "KL_weight:  0.000609899999999948 teacher_forcing_ratio:  0.9999390099996935\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08798586577177048\n",
      "KL_weight:  0.0006148999999999454 teacher_forcing_ratio:  0.999938509999691\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.08815556764602661\n",
      "KL_weight:  0.0006198999999999428 teacher_forcing_ratio:  0.9999380099996885\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: advancoreded \tScore:  0.05859\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   absteating \tScore:  0.33569\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: beglievashes \tScore:  0.09578\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  expereadesh \tScore:  0.25965\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   selintares \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestilating \tScore:  0.25451\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   florateraw \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: fercountinate \tScore:  0.05526\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fincountated \tScore:  0.07089\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    heshayels \tScore:  0.07583\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.08937503397464752\n",
      "KL_weight:  0.0006288999999999381 teacher_forcing_ratio:  0.999937109999684\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.08039108663797379\n",
      "KL_weight:  0.0006338999999999356 teacher_forcing_ratio:  0.9999366099996815\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.07917585223913193\n",
      "KL_weight:  0.000638899999999933 teacher_forcing_ratio:  0.999936109999679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08732981979846954\n",
      "KL_weight:  0.0006438999999999304 teacher_forcing_ratio:  0.9999356099996765\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.09149780869483948\n",
      "KL_weight:  0.0006488999999999278 teacher_forcing_ratio:  0.9999351099996739\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08554095774888992\n",
      "KL_weight:  0.0006538999999999252 teacher_forcing_ratio:  0.9999346099996714\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.08370521664619446\n",
      "KL_weight:  0.0006588999999999226 teacher_forcing_ratio:  0.9999341099996689\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: adorachanied \tScore:  0.06484\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: arestoundering \tScore:  0.08407\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  degliverses \tScore:  0.04741\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  experdiemed \tScore:  0.24808\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  streaknoses \tScore:  0.04741\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sstaltipling \tScore:  0.16590\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    arrascowe \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  ficturomine \tScore:  0.05452\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   fircounted \tScore:  0.07731\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    helisteas \tScore:  0.07583\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.08659455180168152\n",
      "KL_weight:  0.000667899999999918 teacher_forcing_ratio:  0.9999332099996644\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.0835183635354042\n",
      "KL_weight:  0.0006728999999999154 teacher_forcing_ratio:  0.9999327099996619\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.08414177596569061\n",
      "KL_weight:  0.0006778999999999128 teacher_forcing_ratio:  0.9999322099996594\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.0833904817700386\n",
      "KL_weight:  0.0006828999999999102 teacher_forcing_ratio:  0.9999317099996569\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.07876238226890564\n",
      "KL_weight:  0.0006878999999999076 teacher_forcing_ratio:  0.9999312099996543\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.09069289267063141\n",
      "KL_weight:  0.000692899999999905 teacher_forcing_ratio:  0.9999307099996518\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.08366748690605164\n",
      "KL_weight:  0.0006978999999999024 teacher_forcing_ratio:  0.9999302099996493\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abreshonted \tScore:  0.06905\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: actelighting \tScore:  0.24384\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  bechisering \tScore:  0.06239\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   exerpested \tScore:  0.06985\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   snestersts \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestutesing \tScore:  0.10518\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      bracher \tScore:  0.04347\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   furconitch \tScore:  0.07260\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: froutinished \tScore:  0.06058\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   resellates \tScore:  0.02985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.08541303873062134\n",
      "KL_weight:  0.0007068999999998978 teacher_forcing_ratio:  0.9999293099996448\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.08497579395771027\n",
      "KL_weight:  0.0007118999999998952 teacher_forcing_ratio:  0.9999288099996423\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.08406401425600052\n",
      "KL_weight:  0.0007168999999998926 teacher_forcing_ratio:  0.9999283099996398\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.08682703971862793\n",
      "KL_weight:  0.00072189999999989 teacher_forcing_ratio:  0.9999278099996373\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.08721747994422913\n",
      "KL_weight:  0.0007268999999998874 teacher_forcing_ratio:  0.9999273099996348\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08814197778701782\n",
      "KL_weight:  0.0007318999999998848 teacher_forcing_ratio:  0.9999268099996322\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09285226464271545\n",
      "KL_weight:  0.0007368999999998822 teacher_forcing_ratio:  0.9999263099996297\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   absjounced \tScore:  0.06985\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: adveristeing \tScore:  0.10025\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   deperishes \tScore:  0.02778\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   experesses \tScore:  0.27776\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  speresshits \tScore:  0.02481\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: declattiring \tScore:  0.14735\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    sharelver \tScore:  0.12753\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionure \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: funcounisted \tScore:  0.28646\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hesellares \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.09758801013231277\n",
      "KL_weight:  0.0007458999999998776 teacher_forcing_ratio:  0.9999254099996252\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.08705110847949982\n",
      "KL_weight:  0.000750899999999875 teacher_forcing_ratio:  0.9999249099996227\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.08852070569992065\n",
      "KL_weight:  0.0007558999999998724 teacher_forcing_ratio:  0.9999244099996202\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.09486415237188339\n",
      "KL_weight:  0.0007608999999998698 teacher_forcing_ratio:  0.9999239099996177\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0967697948217392\n",
      "KL_weight:  0.0007658999999998672 teacher_forcing_ratio:  0.9999234099996152\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.08303117007017136\n",
      "KL_weight:  0.0007708999999998646 teacher_forcing_ratio:  0.9999229099996126\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09701381623744965\n",
      "KL_weight:  0.000775899999999862 teacher_forcing_ratio:  0.9999224099996101\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   absjourned \tScore:  0.13747\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: besteallinging \tScore:  0.09669\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: denetiglates \tScore:  0.02547\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  deperatends \tScore:  0.27902\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  sespentares \tScore:  0.05638\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    ssporllid \tScore:  0.07172\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    forremale \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     funclime \tScore:  0.36556\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    helaomers \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.09221909195184708\n",
      "KL_weight:  0.0007848999999998574 teacher_forcing_ratio:  0.9999215099996056\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.09119325876235962\n",
      "KL_weight:  0.0007898999999998548 teacher_forcing_ratio:  0.9999210099996031\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.09572156518697739\n",
      "KL_weight:  0.0007948999999998522 teacher_forcing_ratio:  0.9999205099996006\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.09369960427284241\n",
      "KL_weight:  0.0007998999999998496 teacher_forcing_ratio:  0.9999200099995981\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.09293097257614136\n",
      "KL_weight:  0.000804899999999847 teacher_forcing_ratio:  0.9999195099995956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.09137680381536484\n",
      "KL_weight:  0.0008098999999998444 teacher_forcing_ratio:  0.999919009999593\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09222269803285599\n",
      "KL_weight:  0.0008148999999998418 teacher_forcing_ratio:  0.9999185099995905\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  absconjered \tScore:  0.06905\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  adjectining \tScore:  0.14601\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    deguishes \tScore:  0.06031\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expecedes \tScore:  0.33032\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   stelecters \tScore:  0.02778\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sclestepsesting \tScore:  0.19565\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flasherad \tScore:  0.13485\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  friscounter \tScore:  0.05452\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: contresunyed \tScore:  0.06704\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   helarishes \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1044386625289917\n",
      "KL_weight:  0.0008238999999998372 teacher_forcing_ratio:  0.999917609999586\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.09609056264162064\n",
      "KL_weight:  0.0008288999999998346 teacher_forcing_ratio:  0.9999171099995835\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0943451076745987\n",
      "KL_weight:  0.000833899999999832 teacher_forcing_ratio:  0.999916609999581\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.09041959792375565\n",
      "KL_weight:  0.0008388999999998294 teacher_forcing_ratio:  0.9999161099995785\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.09581097960472107\n",
      "KL_weight:  0.0008438999999998268 teacher_forcing_ratio:  0.999915609999576\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.09646914899349213\n",
      "KL_weight:  0.0008488999999998242 teacher_forcing_ratio:  0.9999151099995734\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09748043119907379\n",
      "KL_weight:  0.0008538999999998216 teacher_forcing_ratio:  0.9999146099995709\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  advenheleds \tScore:  0.05013\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abserbelvew \tScore:  0.05246\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   pereasings \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   exparesses \tScore:  0.11868\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    selenters \tScore:  0.07172\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: preloxisting \tScore:  0.25212\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      flearel \tScore:  0.20557\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:      furdent \tScore:  0.07201\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  founchiated \tScore:  0.13588\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    heleavers \tScore:  0.07583\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.09833305329084396\n",
      "KL_weight:  0.000862899999999817 teacher_forcing_ratio:  0.9999137099995664\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10680744051933289\n",
      "KL_weight:  0.0008678999999998144 teacher_forcing_ratio:  0.9999132099995639\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.09514106810092926\n",
      "KL_weight:  0.0008728999999998118 teacher_forcing_ratio:  0.9999127099995614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.09885760396718979\n",
      "KL_weight:  0.0008778999999998092 teacher_forcing_ratio:  0.9999122099995589\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.10089698433876038\n",
      "KL_weight:  0.0008828999999998066 teacher_forcing_ratio:  0.9999117099995564\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.1006818562746048\n",
      "KL_weight:  0.000887899999999804 teacher_forcing_ratio:  0.9999112099995539\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09816829860210419\n",
      "KL_weight:  0.0008928999999998014 teacher_forcing_ratio:  0.9999107099995513\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  advoneraged \tScore:  0.12761\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  avertlening \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  degenerates \tScore:  0.04741\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expresends \tScore:  0.37992\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    spresents \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    splewling \tScore:  0.21105\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      shavery \tScore:  0.04347\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   trundisten \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  fintrounced \tScore:  0.13951\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     helerves \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.09190388768911362\n",
      "KL_weight:  0.0009018999999997968 teacher_forcing_ratio:  0.9999098099995468\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10045286267995834\n",
      "KL_weight:  0.0009068999999997942 teacher_forcing_ratio:  0.9999093099995443\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.0961640253663063\n",
      "KL_weight:  0.0009118999999997916 teacher_forcing_ratio:  0.9999088099995418\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.1027006208896637\n",
      "KL_weight:  0.000916899999999789 teacher_forcing_ratio:  0.9999083099995393\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.10117391496896744\n",
      "KL_weight:  0.0009218999999997864 teacher_forcing_ratio:  0.9999078099995368\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.1050226166844368\n",
      "KL_weight:  0.0009268999999997838 teacher_forcing_ratio:  0.9999073099995343\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.09706367552280426\n",
      "KL_weight:  0.0009318999999997813 teacher_forcing_ratio:  0.9999068099995317\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:      ovenger \tScore:  0.03267\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:       abolig \tScore:  0.07357\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begentires \tScore:  0.12422\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: experespends \tScore:  0.47988\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   dessirases \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:     spristul \tScore:  0.06518\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      leasper \tScore:  0.04671\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionale \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   funtrolted \tScore:  0.14287\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     heallers \tScore:  0.36556\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.09838030487298965\n",
      "KL_weight:  0.0009408999999997766 teacher_forcing_ratio:  0.9999059099995272\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10481971502304077\n",
      "KL_weight:  0.000945899999999774 teacher_forcing_ratio:  0.9999054099995247\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.10712376236915588\n",
      "KL_weight:  0.0009508999999997714 teacher_forcing_ratio:  0.9999049099995222\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.10433194041252136\n",
      "KL_weight:  0.0009558999999997688 teacher_forcing_ratio:  0.9999044099995197\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1070932149887085\n",
      "KL_weight:  0.0009608999999997662 teacher_forcing_ratio:  0.9999039099995172\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10485469549894333\n",
      "KL_weight:  0.0009658999999997636 teacher_forcing_ratio:  0.9999034099995147\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.10078460723161697\n",
      "KL_weight:  0.0009708999999997611 teacher_forcing_ratio:  0.9999029099995121\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abderaged \tScore:  0.07937\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    aberaging \tScore:  0.19960\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     becevels \tScore:  0.06501\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: experesponds \tScore:  0.30661\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:       steals \tScore:  0.05373\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    clettring \tScore:  0.15620\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   lathergare \tScore:  0.12422\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    furtinken \tScore:  0.07937\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  furtinonced \tScore:  0.08914\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     heallers \tScore:  0.36556\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.10605520755052567\n",
      "KL_weight:  0.00097989999999976 teacher_forcing_ratio:  0.9999020099995076\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10223411023616791\n",
      "KL_weight:  0.000984899999999763 teacher_forcing_ratio:  0.9999015099995051\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.11308519542217255\n",
      "KL_weight:  0.0009898999999997658 teacher_forcing_ratio:  0.9999010099995026\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.11644596606492996\n",
      "KL_weight:  0.0009948999999997686 teacher_forcing_ratio:  0.9999005099995001\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.0928163006901741\n",
      "KL_weight:  0.0009998999999997714 teacher_forcing_ratio:  0.9999000099994976\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.11147340387105942\n",
      "KL_weight:  0.0010048999999997742 teacher_forcing_ratio:  0.9998995099994951\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.10441255569458008\n",
      "KL_weight:  0.001009899999999777 teacher_forcing_ratio:  0.9998990099994925\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  astargended \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abettrelled \tScore:  0.35084\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    belefiges \tScore:  0.06377\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    expresems \tScore:  0.13485\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    stespents \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  shrowerting \tScore:  0.24808\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     travelle \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   suntelfect \tScore:  0.06674\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    floutered \tScore:  0.05972\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    hestolles \tScore:  0.06031\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.10366617143154144\n",
      "KL_weight:  0.0010188999999997822 teacher_forcing_ratio:  0.999898109999488\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11137114465236664\n",
      "KL_weight:  0.001023899999999785 teacher_forcing_ratio:  0.9998976099994855\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.10676098614931107\n",
      "KL_weight:  0.0010288999999997878 teacher_forcing_ratio:  0.999897109999483\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.10720886290073395\n",
      "KL_weight:  0.0010338999999997907 teacher_forcing_ratio:  0.9998966099994805\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.10781353712081909\n",
      "KL_weight:  0.0010388999999997935 teacher_forcing_ratio:  0.999896109999478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10672055929899216\n",
      "KL_weight:  0.0010438999999997963 teacher_forcing_ratio:  0.9998956099994755\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.10794477164745331\n",
      "KL_weight:  0.0010488999999997992 teacher_forcing_ratio:  0.999895109999473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   advorneled \tScore:  0.06985\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: obstrabering \tScore:  0.14735\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    demelless \tScore:  0.02852\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: hepresserses \tScore:  0.02409\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    snesteres \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  shiplishing \tScore:  0.16307\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     strelese \tScore:  0.06501\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   funtercose \tScore:  0.12422\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  fulteringed \tScore:  0.06484\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     heleress \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11286364495754242\n",
      "KL_weight:  0.0010578999999998043 teacher_forcing_ratio:  0.9998942099994684\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.09705942869186401\n",
      "KL_weight:  0.001062899999999807 teacher_forcing_ratio:  0.9998937099994659\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1120908185839653\n",
      "KL_weight:  0.00106789999999981 teacher_forcing_ratio:  0.9998932099994634\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.10225247591733932\n",
      "KL_weight:  0.0010728999999998128 teacher_forcing_ratio:  0.9998927099994609\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11270333081483841\n",
      "KL_weight:  0.0010778999999998156 teacher_forcing_ratio:  0.9998922099994584\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10159482061862946\n",
      "KL_weight:  0.0010828999999998184 teacher_forcing_ratio:  0.9998917099994559\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.10376880317926407\n",
      "KL_weight:  0.0010878999999998213 teacher_forcing_ratio:  0.9998912099994534\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     abshaved \tScore:  0.07752\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  asheaturing \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: prelinquishes \tScore:  0.03907\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  reginerests \tScore:  0.02666\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      sespets \tScore:  0.07731\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: sprestalizing \tScore:  0.11686\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      dveller \tScore:  0.04347\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    tuckoning \tScore:  0.06936\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   flistanded \tScore:  0.05874\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     exaseres \tScore:  0.03656\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.10617679357528687\n",
      "KL_weight:  0.0010968999999998264 teacher_forcing_ratio:  0.9998903099994488\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10768075287342072\n",
      "KL_weight:  0.0011018999999998292 teacher_forcing_ratio:  0.9998898099994463\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.10964056849479675\n",
      "KL_weight:  0.001106899999999832 teacher_forcing_ratio:  0.9998893099994438\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.11043025553226471\n",
      "KL_weight:  0.0011118999999998349 teacher_forcing_ratio:  0.9998888099994413\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11251498758792877\n",
      "KL_weight:  0.0011168999999998377 teacher_forcing_ratio:  0.9998883099994388\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10134436190128326\n",
      "KL_weight:  0.0011218999999998405 teacher_forcing_ratio:  0.9998878099994363\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.10327210277318954\n",
      "KL_weight:  0.0011268999999998433 teacher_forcing_ratio:  0.9998873099994338\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   wandergove \tScore:  0.11868\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: bhertavening \tScore:  0.10419\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   pogentines \tScore:  0.05612\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: upperestends \tScore:  0.25212\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    stresents \tScore:  0.12753\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    parsusing \tScore:  0.13485\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      hholler \tScore:  0.04347\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    funtergon \tScore:  0.15620\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    funtlowed \tScore:  0.14526\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healeases \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11046350002288818\n",
      "KL_weight:  0.0011358999999998484 teacher_forcing_ratio:  0.9998864099994292\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10342670232057571\n",
      "KL_weight:  0.0011408999999998513 teacher_forcing_ratio:  0.9998859099994267\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.10837525129318237\n",
      "KL_weight:  0.0011458999999998541 teacher_forcing_ratio:  0.9998854099994242\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.10939927399158478\n",
      "KL_weight:  0.001150899999999857 teacher_forcing_ratio:  0.9998849099994217\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11069355905056\n",
      "KL_weight:  0.0011558999999998598 teacher_forcing_ratio:  0.9998844099994192\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.11211984604597092\n",
      "KL_weight:  0.0011608999999998626 teacher_forcing_ratio:  0.9998839099994167\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.11192953586578369\n",
      "KL_weight:  0.0011658999999998654 teacher_forcing_ratio:  0.9998834099994142\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  adjorriened \tScore:  0.11095\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    abevoting \tScore:  0.43167\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  devinolters \tScore:  0.04741\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: svesperesses \tScore:  0.04284\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict: sesmenterses \tScore:  0.05094\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    swelpling \tScore:  0.19960\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   shrawlered \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   subemblead \tScore:  0.02111\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  thrimunched \tScore:  0.12761\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healadens \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.12585371732711792\n",
      "KL_weight:  0.0011748999999998705 teacher_forcing_ratio:  0.9998825099994096\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.10548725724220276\n",
      "KL_weight:  0.0011798999999998734 teacher_forcing_ratio:  0.9998820099994071\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.11585453152656555\n",
      "KL_weight:  0.0011848999999998762 teacher_forcing_ratio:  0.9998815099994046\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1112702488899231\n",
      "KL_weight:  0.001189899999999879 teacher_forcing_ratio:  0.9998810099994021\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1135801374912262\n",
      "KL_weight:  0.0011948999999998819 teacher_forcing_ratio:  0.9998805099993996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10877396166324615\n",
      "KL_weight:  0.0011998999999998847 teacher_forcing_ratio:  0.9998800099993971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1254291981458664\n",
      "KL_weight:  0.0012048999999998875 teacher_forcing_ratio:  0.9998795099993946\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: advanterhered \tScore:  0.05142\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: abderlattening \tScore:  0.10743\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begulates \tScore:  0.12753\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  exupphatens \tScore:  0.06239\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    sterveles \tScore:  0.03156\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  slaphelling \tScore:  0.12278\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     sharfler \tScore:  0.08784\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    fulfarzen \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: munducatered \tScore:  0.05638\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   heallerses \tScore:  0.27776\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.10709939152002335\n",
      "KL_weight:  0.0012138999999998926 teacher_forcing_ratio:  0.99987860999939\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11099348962306976\n",
      "KL_weight:  0.0012188999999998955 teacher_forcing_ratio:  0.9998781099993875\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1268824338912964\n",
      "KL_weight:  0.0012238999999998983 teacher_forcing_ratio:  0.999877609999385\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1175837442278862\n",
      "KL_weight:  0.0012288999999999011 teacher_forcing_ratio:  0.9998771099993825\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11326879262924194\n",
      "KL_weight:  0.001233899999999904 teacher_forcing_ratio:  0.99987660999938\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.11128754913806915\n",
      "KL_weight:  0.0012388999999999068 teacher_forcing_ratio:  0.9998761099993775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12072478979825974\n",
      "KL_weight:  0.0012438999999999096 teacher_forcing_ratio:  0.999875609999375\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abhorbeeded \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  avelatening \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: distregalles \tScore:  0.04284\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: serperdeases \tScore:  0.04529\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    seleptens \tScore:  0.07172\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: strullipting \tScore:  0.27902\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     squalter \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     thurcken \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functerioned \tScore:  0.63405\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    helaphess \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11824215948581696\n",
      "KL_weight:  0.0012528999999999147 teacher_forcing_ratio:  0.9998747099993704\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11104756593704224\n",
      "KL_weight:  0.0012578999999999175 teacher_forcing_ratio:  0.9998742099993679\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.11120585352182388\n",
      "KL_weight:  0.0012628999999999204 teacher_forcing_ratio:  0.9998737099993654\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.11384081095457077\n",
      "KL_weight:  0.0012678999999999232 teacher_forcing_ratio:  0.9998732099993629\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1157916933298111\n",
      "KL_weight:  0.001272899999999926 teacher_forcing_ratio:  0.9998727099993604\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.11874266713857651\n",
      "KL_weight:  0.0012778999999999289 teacher_forcing_ratio:  0.9998722099993579\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1184568926692009\n",
      "KL_weight:  0.0012828999999999317 teacher_forcing_ratio:  0.9998717099993554\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abshowered \tScore:  0.06674\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  advistering \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  diservestes \tScore:  0.02481\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  resperdeals \tScore:  0.05013\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    srreswers \tScore:  0.03156\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  swriversing \tScore:  0.10600\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    misleader \tScore:  0.03391\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     knotuche \tScore:  0.04154\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  funcherifed \tScore:  0.28998\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      heliers \tScore:  0.08307\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.12076450139284134\n",
      "KL_weight:  0.0012918999999999368 teacher_forcing_ratio:  0.9998708099993509\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11091393977403641\n",
      "KL_weight:  0.0012968999999999396 teacher_forcing_ratio:  0.9998703099993483\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1193857491016388\n",
      "KL_weight:  0.0013018999999999425 teacher_forcing_ratio:  0.9998698099993458\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.1152685135602951\n",
      "KL_weight:  0.0013068999999999453 teacher_forcing_ratio:  0.9998693099993433\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1193150132894516\n",
      "KL_weight:  0.0013118999999999481 teacher_forcing_ratio:  0.9998688099993408\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.10795595496892929\n",
      "KL_weight:  0.001316899999999951 teacher_forcing_ratio:  0.9998683099993383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.118512824177742\n",
      "KL_weight:  0.0013218999999999538 teacher_forcing_ratio:  0.9998678099993358\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     awhorred \tScore:  0.06165\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   outtelling \tScore:  0.13747\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beghells \tScore:  0.14772\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  undereldows \tScore:  0.05013\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      shevels \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: strugglinting \tScore:  0.24712\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     whardere \tScore:  0.07731\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionale \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functionced \tScore:  0.74194\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     heloress \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11567368358373642\n",
      "KL_weight:  0.001330899999999959 teacher_forcing_ratio:  0.9998669099993313\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11691166460514069\n",
      "KL_weight:  0.0013358999999999617 teacher_forcing_ratio:  0.9998664099993287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12524037063121796\n",
      "KL_weight:  0.0013408999999999646 teacher_forcing_ratio:  0.9998659099993262\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.12282814085483551\n",
      "KL_weight:  0.0013458999999999674 teacher_forcing_ratio:  0.9998654099993237\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11581507325172424\n",
      "KL_weight:  0.0013508999999999702 teacher_forcing_ratio:  0.9998649099993212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12211215496063232\n",
      "KL_weight:  0.001355899999999973 teacher_forcing_ratio:  0.9998644099993187\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12387147545814514\n",
      "KL_weight:  0.0013608999999999759 teacher_forcing_ratio:  0.9998639099993162\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  advenceeded \tScore:  0.05013\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   betrelling \tScore:  0.17567\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begesters \tScore:  0.12753\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: depinterates \tScore:  0.02666\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  steeminates \tScore:  0.02666\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  distrelling \tScore:  0.12761\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     fertelle \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     fulchone \tScore:  0.08784\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      healess \tScore:  0.43472\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11508125811815262\n",
      "KL_weight:  0.001369899999999981 teacher_forcing_ratio:  0.9998630099993117\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11602546274662018\n",
      "KL_weight:  0.0013748999999999838 teacher_forcing_ratio:  0.9998625099993091\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.11437300592660904\n",
      "KL_weight:  0.0013798999999999866 teacher_forcing_ratio:  0.9998620099993066\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.11139620095491409\n",
      "KL_weight:  0.0013848999999999895 teacher_forcing_ratio:  0.9998615099993041\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11862506717443466\n",
      "KL_weight:  0.0013898999999999923 teacher_forcing_ratio:  0.9998610099993016\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12286844849586487\n",
      "KL_weight:  0.0013948999999999951 teacher_forcing_ratio:  0.9998605099992991\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.11917722970247269\n",
      "KL_weight:  0.001399899999999998 teacher_forcing_ratio:  0.9998600099992966\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   affordened \tScore:  0.12422\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   wattelling \tScore:  0.14287\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begesters \tScore:  0.12753\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    messerges \tScore:  0.03156\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      steanes \tScore:  0.04671\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  displessing \tScore:  0.16307\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     forterel \tScore:  0.06985\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     function \tScore:  1.00000\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      leashes \tScore:  0.10446\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1167755275964737\n",
      "KL_weight:  0.001408900000000003 teacher_forcing_ratio:  0.9998591099992921\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.11584698408842087\n",
      "KL_weight:  0.001413900000000006 teacher_forcing_ratio:  0.9998586099992895\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12539967894554138\n",
      "KL_weight:  0.0014189000000000087 teacher_forcing_ratio:  0.999858109999287\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.11548025906085968\n",
      "KL_weight:  0.0014239000000000116 teacher_forcing_ratio:  0.9998576099992845\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.12664300203323364\n",
      "KL_weight:  0.0014289000000000144 teacher_forcing_ratio:  0.999857109999282\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.13013750314712524\n",
      "KL_weight:  0.0014339000000000172 teacher_forcing_ratio:  0.9998566099992795\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.12350088357925415\n",
      "KL_weight:  0.00143890000000002 teacher_forcing_ratio:  0.999856109999277\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    hafformed \tScore:  0.06031\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  wantrelling \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befhibles \tScore:  0.06031\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    semenders \tScore:  0.13485\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      shreats \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  distreaking \tScore:  0.11095\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       flower \tScore:  0.10267\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    fundigure \tScore:  0.12753\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   futchioned \tScore:  0.48110\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    healinges \tScore:  0.31560\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.11298604309558868\n",
      "KL_weight:  0.0014479000000000252 teacher_forcing_ratio:  0.9998552099992725\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.12196485698223114\n",
      "KL_weight:  0.001452900000000028 teacher_forcing_ratio:  0.99985470999927\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.134292870759964\n",
      "KL_weight:  0.0014579000000000308 teacher_forcing_ratio:  0.9998542099992674\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.12298721820116043\n",
      "KL_weight:  0.0014629000000000337 teacher_forcing_ratio:  0.9998537099992649\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.11748060584068298\n",
      "KL_weight:  0.0014679000000000365 teacher_forcing_ratio:  0.9998532099992624\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12027068436145782\n",
      "KL_weight:  0.0014729000000000393 teacher_forcing_ratio:  0.9998527099992599\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1204979196190834\n",
      "KL_weight:  0.0014779000000000422 teacher_forcing_ratio:  0.9998522099992574\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  hanterwoved \tScore:  0.05961\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: abhertending \tScore:  0.11531\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   beterhells \tScore:  0.04939\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: extenderages \tScore:  0.11095\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   shetterses \tScore:  0.04939\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  spestelling \tScore:  0.13712\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    sharelver \tScore:  0.12753\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   funtercive \tScore:  0.12422\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   futtinnied \tScore:  0.08307\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      hellays \tScore:  0.08784\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.12149051576852798\n",
      "KL_weight:  0.0014869000000000473 teacher_forcing_ratio:  0.9998513099992529\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.13118258118629456\n",
      "KL_weight:  0.00149190000000005 teacher_forcing_ratio:  0.9998508099992504\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12696722149848938\n",
      "KL_weight:  0.001496900000000053 teacher_forcing_ratio:  0.9998503099992478\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.12193432450294495\n",
      "KL_weight:  0.0015019000000000558 teacher_forcing_ratio:  0.9998498099992453\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1303568184375763\n",
      "KL_weight:  0.0015069000000000586 teacher_forcing_ratio:  0.9998493099992428\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12436597794294357\n",
      "KL_weight:  0.0015119000000000614 teacher_forcing_ratio:  0.9998488099992403\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12111585587263107\n",
      "KL_weight:  0.0015169000000000642 teacher_forcing_ratio:  0.9998483099992378\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   averledged \tScore:  0.05308\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  bablewaring \tScore:  0.12278\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   devievests \tScore:  0.02778\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   overspeels \tScore:  0.05308\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     delivers \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   wledgowing \tScore:  0.11224\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     permiret \tScore:  0.05874\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   furmentile \tScore:  0.06674\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  funcolleded \tScore:  0.28998\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   ehelarases \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1276833564043045\n",
      "KL_weight:  0.0015259000000000693 teacher_forcing_ratio:  0.9998474099992333\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.12243866175413132\n",
      "KL_weight:  0.0015309000000000722 teacher_forcing_ratio:  0.9998469099992308\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.125387042760849\n",
      "KL_weight:  0.001535900000000075 teacher_forcing_ratio:  0.9998464099992282\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.13730889558792114\n",
      "KL_weight:  0.0015409000000000778 teacher_forcing_ratio:  0.9998459099992257\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.12379524856805801\n",
      "KL_weight:  0.0015459000000000807 teacher_forcing_ratio:  0.9998454099992232\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14158333837985992\n",
      "KL_weight:  0.0015509000000000835 teacher_forcing_ratio:  0.9998449099992207\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1298619508743286\n",
      "KL_weight:  0.0015559000000000863 teacher_forcing_ratio:  0.9998444099992182\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  expeicteded \tScore:  0.04412\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: advestigating \tScore:  0.22242\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  boffergases \tScore:  0.02666\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  empheasates \tScore:  0.02666\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     desivels \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: prespitchiving \tScore:  0.10390\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:  despeasires \tScore:  0.04412\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionated \tScore:  0.67042\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     holleads \tScore:  0.07386\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.13866722583770752\n",
      "KL_weight:  0.0015649000000000914 teacher_forcing_ratio:  0.9998435099992137\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.12214764207601547\n",
      "KL_weight:  0.0015699000000000943 teacher_forcing_ratio:  0.9998430099992112\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12599396705627441\n",
      "KL_weight:  0.001574900000000097 teacher_forcing_ratio:  0.9998425099992087\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1259959489107132\n",
      "KL_weight:  0.0015799000000001 teacher_forcing_ratio:  0.9998420099992061\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14412136375904083\n",
      "KL_weight:  0.0015849000000001028 teacher_forcing_ratio:  0.9998415099992036\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12727615237236023\n",
      "KL_weight:  0.0015899000000001056 teacher_forcing_ratio:  0.9998410099992011\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12886637449264526\n",
      "KL_weight:  0.0015949000000001084 teacher_forcing_ratio:  0.9998405099991986\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   awhandored \tScore:  0.32467\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:     abetting \tScore:  1.00000\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict: pexpiectives \tScore:  0.02242\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    underlays \tScore:  0.06031\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:       steems \tScore:  0.05373\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: strewlysping \tScore:  0.11531\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      forforw \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    fignorate \tScore:  0.03586\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    funtlored \tScore:  0.14526\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    helerveys \tScore:  0.06031\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.12917974591255188\n",
      "KL_weight:  0.0016039000000001135 teacher_forcing_ratio:  0.9998396099991941\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.13079844415187836\n",
      "KL_weight:  0.0016089000000001164 teacher_forcing_ratio:  0.9998391099991916\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12847581505775452\n",
      "KL_weight:  0.0016139000000001192 teacher_forcing_ratio:  0.999838609999189\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1489129513502121\n",
      "KL_weight:  0.001618900000000122 teacher_forcing_ratio:  0.9998381099991865\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1318739801645279\n",
      "KL_weight:  0.0016239000000001249 teacher_forcing_ratio:  0.999837609999184\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12726260721683502\n",
      "KL_weight:  0.0016289000000001277 teacher_forcing_ratio:  0.9998371099991815\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12577739357948303\n",
      "KL_weight:  0.0016339000000001305 teacher_forcing_ratio:  0.999836609999179\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  awantrowled \tScore:  0.06239\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  apelietting \tScore:  0.47988\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begessizes \tScore:  0.11868\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  exnestrades \tScore:  0.05246\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      snrawls \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: stwhillingling \tScore:  0.09669\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   thramaller \tScore:  0.02985\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   finchibish \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionsated \tScore:  0.61154\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     herlowls \tScore:  0.08307\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1415453851222992\n",
      "KL_weight:  0.0016429000000001356 teacher_forcing_ratio:  0.9998357099991745\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1274934709072113\n",
      "KL_weight:  0.0016479000000001384 teacher_forcing_ratio:  0.999835209999172\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.12925946712493896\n",
      "KL_weight:  0.0016529000000001413 teacher_forcing_ratio:  0.9998347099991695\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.12552551925182343\n",
      "KL_weight:  0.0016579000000001441 teacher_forcing_ratio:  0.999834209999167\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1373400241136551\n",
      "KL_weight:  0.001662900000000147 teacher_forcing_ratio:  0.9998337099991644\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.13397052884101868\n",
      "KL_weight:  0.0016679000000001498 teacher_forcing_ratio:  0.9998332099991619\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1286047250032425\n",
      "KL_weight:  0.0016729000000001526 teacher_forcing_ratio:  0.9998327099991594\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict: avowhicheped \tScore:  0.04284\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: attrollingling \tScore:  0.09304\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  deliverages \tScore:  0.02666\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: exmenterises \tScore:  0.05386\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  constensits \tScore:  0.04741\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: brishastening \tScore:  0.09145\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flourained \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  fintroulate \tScore:  0.02950\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  fintharized \tScore:  0.05246\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    resealles \tScore:  0.12753\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.14089129865169525\n",
      "KL_weight:  0.0016819000000001577 teacher_forcing_ratio:  0.9998318099991549\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.12618659436702728\n",
      "KL_weight:  0.0016869000000001605 teacher_forcing_ratio:  0.9998313099991524\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.136383518576622\n",
      "KL_weight:  0.0016919000000001634 teacher_forcing_ratio:  0.9998308099991499\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.12851333618164062\n",
      "KL_weight:  0.0016969000000001662 teacher_forcing_ratio:  0.9998303099991473\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.12808574736118317\n",
      "KL_weight:  0.001701900000000169 teacher_forcing_ratio:  0.9998298099991448\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12977364659309387\n",
      "KL_weight:  0.0017069000000001719 teacher_forcing_ratio:  0.9998293099991423\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.12887635827064514\n",
      "KL_weight:  0.0017119000000001747 teacher_forcing_ratio:  0.9998288099991398\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  affordering \tScore:  0.02819\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: adelteldighing \tScore:  0.08407\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  berelatings \tScore:  0.06239\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: exmerrelates \tScore:  0.04284\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     shelutes \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  blacturests \tScore:  0.02666\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    formerlay \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    furminate \tScore:  0.06377\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     hollades \tScore:  0.04154\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.12610436975955963\n",
      "KL_weight:  0.0017209000000001798 teacher_forcing_ratio:  0.9998279099991353\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.13489240407943726\n",
      "KL_weight:  0.0017259000000001826 teacher_forcing_ratio:  0.9998274099991328\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.13601821660995483\n",
      "KL_weight:  0.0017309000000001855 teacher_forcing_ratio:  0.9998269099991303\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1286918669939041\n",
      "KL_weight:  0.0017359000000001883 teacher_forcing_ratio:  0.9998264099991278\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.13482026755809784\n",
      "KL_weight:  0.0017409000000001911 teacher_forcing_ratio:  0.9998259099991252\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.132845938205719\n",
      "KL_weight:  0.001745900000000194 teacher_forcing_ratio:  0.9998254099991227\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.13547921180725098\n",
      "KL_weight:  0.0017509000000001968 teacher_forcing_ratio:  0.9998249099991202\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  abandounted \tScore:  0.53483\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: arrestribing \tScore:  0.10419\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befertions \tScore:  0.06674\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  overterches \tScore:  0.02481\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   deseptives \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: bristressing \tScore:  0.10025\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   thrarlease \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     bunchill \tScore:  0.14772\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionized \tScore:  0.67042\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict: exarestrates \tScore:  0.02242\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.14862646162509918\n",
      "KL_weight:  0.0017599000000002019 teacher_forcing_ratio:  0.9998240099991157\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.13699786365032196\n",
      "KL_weight:  0.0017649000000002047 teacher_forcing_ratio:  0.9998235099991132\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1392483413219452\n",
      "KL_weight:  0.0017699000000002075 teacher_forcing_ratio:  0.9998230099991107\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1469576209783554\n",
      "KL_weight:  0.0017749000000002104 teacher_forcing_ratio:  0.9998225099991082\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.13260018825531006\n",
      "KL_weight:  0.0017799000000002132 teacher_forcing_ratio:  0.9998220099991056\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.12892301380634308\n",
      "KL_weight:  0.001784900000000216 teacher_forcing_ratio:  0.9998215099991031\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.13383078575134277\n",
      "KL_weight:  0.0017899000000002189 teacher_forcing_ratio:  0.9998210099991006\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  afdoundaled \tScore:  0.07176\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: awrestribing \tScore:  0.10419\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     begounts \tScore:  0.15620\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  exneradists \tScore:  0.05246\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   cressunges \tScore:  0.02985\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: rrespistiring \tScore:  0.11302\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    whisferge \tScore:  0.03156\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functionize \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functionced \tScore:  0.74194\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hollewards \tScore:  0.03156\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.13627177476882935\n",
      "KL_weight:  0.001798900000000224 teacher_forcing_ratio:  0.9998201099990961\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1399211287498474\n",
      "KL_weight:  0.0018039000000002268 teacher_forcing_ratio:  0.9998196099990936\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14138147234916687\n",
      "KL_weight:  0.0018089000000002296 teacher_forcing_ratio:  0.9998191099990911\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.13659842312335968\n",
      "KL_weight:  0.0018139000000002325 teacher_forcing_ratio:  0.9998186099990886\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14593525230884552\n",
      "KL_weight:  0.0018189000000002353 teacher_forcing_ratio:  0.999818109999086\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.13083501160144806\n",
      "KL_weight:  0.0018239000000002381 teacher_forcing_ratio:  0.9998176099990835\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.13158336281776428\n",
      "KL_weight:  0.001828900000000241 teacher_forcing_ratio:  0.999817109999081\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abakforded \tScore:  0.14287\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: dedippestimates \tScore:  0.03515\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  behimanders \tScore:  0.05013\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   develophes \tScore:  0.03156\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stesters \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: deplistering \tScore:  0.15235\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    thrullate \tScore:  0.06031\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   futtincone \tScore:  0.08926\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    funderted \tScore:  0.13977\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:  exhilarates \tScore:  0.02819\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.13921698927879333\n",
      "KL_weight:  0.001837900000000246 teacher_forcing_ratio:  0.9998162099990765\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.15029020607471466\n",
      "KL_weight:  0.001842900000000249 teacher_forcing_ratio:  0.999815709999074\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.13760100305080414\n",
      "KL_weight:  0.0018479000000002517 teacher_forcing_ratio:  0.9998152099990715\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1390916258096695\n",
      "KL_weight:  0.0018529000000002546 teacher_forcing_ratio:  0.999814709999069\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.145346000790596\n",
      "KL_weight:  0.0018579000000002574 teacher_forcing_ratio:  0.9998142099990664\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.13704954087734222\n",
      "KL_weight:  0.0018629000000002602 teacher_forcing_ratio:  0.9998137099990639\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.1427716612815857\n",
      "KL_weight:  0.001867900000000263 teacher_forcing_ratio:  0.9998132099990614\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     abounded \tScore:  0.09331\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: explittiting \tScore:  0.27902\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begelishes \tScore:  0.11868\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    despeales \tScore:  0.06377\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     despists \tScore:  0.03928\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: displevisting \tScore:  0.28918\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   wranklered \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     funtleim \tScore:  0.15620\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      exhorts \tScore:  0.04347\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1455419659614563\n",
      "KL_weight:  0.0018769000000002682 teacher_forcing_ratio:  0.9998123099990569\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.13589151203632355\n",
      "KL_weight:  0.001881900000000271 teacher_forcing_ratio:  0.9998118099990544\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.13928988575935364\n",
      "KL_weight:  0.0018869000000002738 teacher_forcing_ratio:  0.9998113099990519\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.13821503520011902\n",
      "KL_weight:  0.0018919000000002767 teacher_forcing_ratio:  0.9998108099990494\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14343656599521637\n",
      "KL_weight:  0.0018969000000002795 teacher_forcing_ratio:  0.9998103099990469\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.13427042961120605\n",
      "KL_weight:  0.0019019000000002823 teacher_forcing_ratio:  0.9998098099990443\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.13943156599998474\n",
      "KL_weight:  0.0019069000000002851 teacher_forcing_ratio:  0.9998093099990418\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     abhorned \tScore:  0.15966\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abakfelling \tScore:  0.12278\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      begetts \tScore:  0.17567\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    unventers \tScore:  0.06031\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   smeltesses \tScore:  0.04939\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  misplotting \tScore:  0.48327\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     flournow \tScore:  0.06501\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     functure \tScore:  0.51697\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     helieves \tScore:  0.06985\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.14971373975276947\n",
      "KL_weight:  0.0019159000000002902 teacher_forcing_ratio:  0.9998084099990373\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1449635624885559\n",
      "KL_weight:  0.001920900000000293 teacher_forcing_ratio:  0.9998079099990348\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14497114717960358\n",
      "KL_weight:  0.001925900000000296 teacher_forcing_ratio:  0.9998074099990323\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.13677839934825897\n",
      "KL_weight:  0.0019309000000002987 teacher_forcing_ratio:  0.9998069099990298\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14783820509910583\n",
      "KL_weight:  0.0019359000000003016 teacher_forcing_ratio:  0.9998064099990273\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14016728103160858\n",
      "KL_weight:  0.0019409000000003044 teacher_forcing_ratio:  0.9998059099990247\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.14518052339553833\n",
      "KL_weight:  0.0019459000000003072 teacher_forcing_ratio:  0.9998054099990222\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:  akontlicked \tScore:  0.05961\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  batterizing \tScore:  0.13194\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:  betellinges \tScore:  0.06239\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expescends \tScore:  0.50813\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    censteres \tScore:  0.06031\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: smittrimulating \tScore:  0.24601\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   flowercate \tScore:  0.05612\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   futtincing \tScore:  0.08034\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   hesholvers \tScore:  0.05308\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.14095181226730347\n",
      "KL_weight:  0.0019549000000003086 teacher_forcing_ratio:  0.9998045099990177\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.14575506746768951\n",
      "KL_weight:  0.0019599000000003006 teacher_forcing_ratio:  0.9998040099990152\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.13978160917758942\n",
      "KL_weight:  0.0019649000000002926 teacher_forcing_ratio:  0.9998035099990127\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15603007376194\n",
      "KL_weight:  0.0019699000000002846 teacher_forcing_ratio:  0.9998030099990102\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.17345404624938965\n",
      "KL_weight:  0.0019749000000002766 teacher_forcing_ratio:  0.9998025099990077\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.1399889439344406\n",
      "KL_weight:  0.0019799000000002686 teacher_forcing_ratio:  0.9998020099990051\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.15142717957496643\n",
      "KL_weight:  0.0019849000000002606 teacher_forcing_ratio:  0.9998015099990026\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    aphoucked \tScore:  0.06031\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   apeckiting \tScore:  0.29072\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   befestores \tScore:  0.04939\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: experestends \tScore:  0.41009\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict: despeftrates \tScore:  0.02409\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: prestristing \tScore:  0.25212\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:    flourishe \tScore:  0.06031\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   fulchioned \tScore:  0.46714\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      exhales \tScore:  0.08784\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.13669346272945404\n",
      "KL_weight:  0.001993900000000246 teacher_forcing_ratio:  0.9998006099989981\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.14562205970287323\n",
      "KL_weight:  0.001998900000000238 teacher_forcing_ratio:  0.9998001099989956\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.13685806095600128\n",
      "KL_weight:  0.00200390000000023 teacher_forcing_ratio:  0.9997996099989931\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1552344113588333\n",
      "KL_weight:  0.002008900000000222 teacher_forcing_ratio:  0.9997991099989906\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14578253030776978\n",
      "KL_weight:  0.002013900000000214 teacher_forcing_ratio:  0.9997986099989881\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.15561971068382263\n",
      "KL_weight:  0.002018900000000206 teacher_forcing_ratio:  0.9997981099989856\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.143730029463768\n",
      "KL_weight:  0.002023900000000198 teacher_forcing_ratio:  0.999797609998983\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     abaldeld \tScore:  0.14427\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abstructing \tScore:  0.28998\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    beginches \tScore:  0.46714\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   pejectares \tScore:  0.05308\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    knettests \tScore:  0.03391\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  spelliching \tScore:  0.13712\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       flaych \tScore:  0.20205\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     elelates \tScore:  0.03928\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1425515115261078\n",
      "KL_weight:  0.0020329000000001837 teacher_forcing_ratio:  0.9997967099989785\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1483536809682846\n",
      "KL_weight:  0.0020379000000001757 teacher_forcing_ratio:  0.999796209998976\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1417730450630188\n",
      "KL_weight:  0.0020429000000001677 teacher_forcing_ratio:  0.9997957099989735\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15027154982089996\n",
      "KL_weight:  0.0020479000000001597 teacher_forcing_ratio:  0.999795209998971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14161768555641174\n",
      "KL_weight:  0.0020529000000001517 teacher_forcing_ratio:  0.9997947099989685\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14085868000984192\n",
      "KL_weight:  0.0020579000000001436 teacher_forcing_ratio:  0.999794209998966\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.14943695068359375\n",
      "KL_weight:  0.0020629000000001356 teacher_forcing_ratio:  0.9997937099989634\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    acknowled \tScore:  0.06377\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   abettering \tScore:  0.52538\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     beguints \tScore:  0.18092\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: expenderates \tScore:  0.43362\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  stimulatens \tScore:  0.04741\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: struttelling \tScore:  0.12390\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      sharule \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     function \tScore:  1.00000\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  thinquinted \tScore:  0.05452\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      helouts \tScore:  0.08307\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.13933196663856506\n",
      "KL_weight:  0.002071900000000121 teacher_forcing_ratio:  0.9997928099989589\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1522427350282669\n",
      "KL_weight:  0.002076900000000113 teacher_forcing_ratio:  0.9997923099989564\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14893949031829834\n",
      "KL_weight:  0.002081900000000105 teacher_forcing_ratio:  0.9997918099989539\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.15650811791419983\n",
      "KL_weight:  0.002086900000000097 teacher_forcing_ratio:  0.9997913099989514\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.15002137422561646\n",
      "KL_weight:  0.002091900000000089 teacher_forcing_ratio:  0.9997908099989489\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.1515604555606842\n",
      "KL_weight:  0.002096900000000081 teacher_forcing_ratio:  0.9997903099989464\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.15543662011623383\n",
      "KL_weight:  0.002101900000000073 teacher_forcing_ratio:  0.9997898099989438\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abblocked \tScore:  0.07583\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: appermitting \tScore:  0.34484\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   begettells \tScore:  0.11224\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  explodesses \tScore:  0.11095\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      stwerms \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   strullling \tScore:  0.13747\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       flaure \tScore:  0.25407\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    minouncer \tScore:  0.14114\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    mundliced \tScore:  0.07102\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      heleads \tScore:  0.10446\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.14201730489730835\n",
      "KL_weight:  0.0021109000000000587 teacher_forcing_ratio:  0.9997889099989393\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.15190723538398743\n",
      "KL_weight:  0.0021159000000000507 teacher_forcing_ratio:  0.9997884099989368\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14706234633922577\n",
      "KL_weight:  0.0021209000000000427 teacher_forcing_ratio:  0.9997879099989343\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.16521799564361572\n",
      "KL_weight:  0.0021259000000000347 teacher_forcing_ratio:  0.9997874099989318\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.14780989289283752\n",
      "KL_weight:  0.0021309000000000267 teacher_forcing_ratio:  0.9997869099989293\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14819248020648956\n",
      "KL_weight:  0.0021359000000000187 teacher_forcing_ratio:  0.9997864099989268\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16205546259880066\n",
      "KL_weight:  0.0021409000000000107 teacher_forcing_ratio:  0.9997859099989242\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     amounded \tScore:  0.08113\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   buggesting \tScore:  0.29072\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     bulights \tScore:  0.03928\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict: experestends \tScore:  0.41009\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:    stretches \tScore:  0.03156\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  misplecting \tScore:  0.35084\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:     florewer \tScore:  0.08307\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    functione \tScore:  0.86334\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:    fortected \tScore:  0.07102\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      helades \tScore:  0.08784\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15077552199363708\n",
      "KL_weight:  0.0021498999999999963 teacher_forcing_ratio:  0.9997850099989197\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.14323347806930542\n",
      "KL_weight:  0.0021548999999999882 teacher_forcing_ratio:  0.9997845099989172\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14118592441082\n",
      "KL_weight:  0.0021598999999999802 teacher_forcing_ratio:  0.9997840099989147\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15871845185756683\n",
      "KL_weight:  0.0021648999999999722 teacher_forcing_ratio:  0.9997835099989122\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1576574444770813\n",
      "KL_weight:  0.0021698999999999642 teacher_forcing_ratio:  0.9997830099989097\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.15927231311798096\n",
      "KL_weight:  0.002174899999999956 teacher_forcing_ratio:  0.9997825099989072\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.14769262075424194\n",
      "KL_weight:  0.002179899999999948 teacher_forcing_ratio:  0.9997820099989047\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   abackented \tScore:  0.13747\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:    accepting \tScore:  0.33032\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    beferries \tScore:  0.06031\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   intercepts \tScore:  0.03156\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   detespinks \tScore:  0.03156\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   mesmecting \tScore:  0.27776\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       flount \tScore:  0.08633\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:  functioning \tScore:  0.67865\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functioningo \tScore:  0.61323\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    elebrates \tScore:  0.03391\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.14798088371753693\n",
      "KL_weight:  0.0021888999999999338 teacher_forcing_ratio:  0.9997811099989001\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.14784052968025208\n",
      "KL_weight:  0.0021938999999999258 teacher_forcing_ratio:  0.9997806099988976\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.16603539884090424\n",
      "KL_weight:  0.0021988999999999178 teacher_forcing_ratio:  0.9997801099988951\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15063345432281494\n",
      "KL_weight:  0.0022038999999999098 teacher_forcing_ratio:  0.9997796099988926\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.16150052845478058\n",
      "KL_weight:  0.0022088999999999017 teacher_forcing_ratio:  0.9997791099988901\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14977148175239563\n",
      "KL_weight:  0.0022138999999998937 teacher_forcing_ratio:  0.9997786099988876\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 350 char-loss:  0.1569172441959381\n",
      "KL_weight:  0.0022188999999998857 teacher_forcing_ratio:  0.9997781099988851\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    abounched \tScore:  0.07937\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   botholding \tScore:  0.11868\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    befittens \tScore:  0.07583\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    endoubles \tScore:  0.13485\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:   smenalizes \tScore:  0.05308\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    sluggling \tScore:  0.14924\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       forgus \tScore:  0.04855\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    functione \tScore:  0.86334\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     exhalens \tScore:  0.07386\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15179279446601868\n",
      "KL_weight:  0.0022278999999998713 teacher_forcing_ratio:  0.9997772099988805\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.155817449092865\n",
      "KL_weight:  0.0022328999999998633 teacher_forcing_ratio:  0.999776709998878\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.14989830553531647\n",
      "KL_weight:  0.0022378999999998553 teacher_forcing_ratio:  0.9997762099988755\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15836107730865479\n",
      "KL_weight:  0.0022428999999998473 teacher_forcing_ratio:  0.999775709998873\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1671900749206543\n",
      "KL_weight:  0.0022478999999998393 teacher_forcing_ratio:  0.9997752099988705\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14410904049873352\n",
      "KL_weight:  0.0022528999999998313 teacher_forcing_ratio:  0.999774709998868\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16076138615608215\n",
      "KL_weight:  0.0022578999999998232 teacher_forcing_ratio:  0.9997742099988655\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     aboubled \tScore:  0.07752\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   exexciting \tScore:  0.27776\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     folteels \tScore:  0.03303\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expectedes \tScore:  0.29072\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     flattens \tScore:  0.06501\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:    spermying \tScore:  0.14924\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       follow \tScore:  0.04855\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   mundercate \tScore:  0.05308\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:      buzzled \tScore:  0.05036\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      hollers \tScore:  0.04671\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15306296944618225\n",
      "KL_weight:  0.002266899999999809 teacher_forcing_ratio:  0.9997733099988609\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1585458517074585\n",
      "KL_weight:  0.002271899999999801 teacher_forcing_ratio:  0.9997728099988584\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.1541738510131836\n",
      "KL_weight:  0.002276899999999793 teacher_forcing_ratio:  0.9997723099988559\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.14702844619750977\n",
      "KL_weight:  0.002281899999999785 teacher_forcing_ratio:  0.9997718099988534\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.15343664586544037\n",
      "KL_weight:  0.002286899999999777 teacher_forcing_ratio:  0.9997713099988509\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.14853252470493317\n",
      "KL_weight:  0.0022918999999997688 teacher_forcing_ratio:  0.9997708099988484\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.15558241307735443\n",
      "KL_weight:  0.0022968999999997608 teacher_forcing_ratio:  0.9997703099988459\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    acknowled \tScore:  0.06377\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abfereating \tScore:  0.28998\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    begetters \tScore:  0.12753\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expercends \tScore:  0.50813\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     shatters \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  clawlinging \tScore:  0.11731\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       learch \tScore:  0.10267\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict: minafcherate \tScore:  0.02547\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: fnochewinked \tScore:  0.05094\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      heleads \tScore:  0.10446\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1545838713645935\n",
      "KL_weight:  0.0023058999999997463 teacher_forcing_ratio:  0.9997694099988413\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1643856018781662\n",
      "KL_weight:  0.0023108999999997383 teacher_forcing_ratio:  0.9997689099988388\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.15268127620220184\n",
      "KL_weight:  0.0023158999999997303 teacher_forcing_ratio:  0.9997684099988363\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.16775532066822052\n",
      "KL_weight:  0.0023208999999997223 teacher_forcing_ratio:  0.9997679099988338\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.15650445222854614\n",
      "KL_weight:  0.0023258999999997143 teacher_forcing_ratio:  0.9997674099988313\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.1528436839580536\n",
      "KL_weight:  0.0023308999999997063 teacher_forcing_ratio:  0.9997669099988288\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16394808888435364\n",
      "KL_weight:  0.0023358999999996983 teacher_forcing_ratio:  0.9997664099988263\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     amberfed \tScore:  0.06165\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  baffleching \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:   celebrates \tScore:  0.02778\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    despefers \tScore:  0.06377\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     blessens \tScore:  0.14772\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  cnesceeding \tScore:  0.10025\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:        flowl \tScore:  0.11362\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     function \tScore:  1.00000\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   functioned \tScore:  1.00000\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:     strealls \tScore:  0.16348\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 char-loss:  0.16068397462368011\n",
      "KL_weight:  0.002344899999999684 teacher_forcing_ratio:  0.9997655099988217\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.15070797502994537\n",
      "KL_weight:  0.002349899999999676 teacher_forcing_ratio:  0.9997650099988192\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.152724027633667\n",
      "KL_weight:  0.002354899999999668 teacher_forcing_ratio:  0.9997645099988167\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15660682320594788\n",
      "KL_weight:  0.00235989999999966 teacher_forcing_ratio:  0.9997640099988142\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.15678946673870087\n",
      "KL_weight:  0.002364899999999652 teacher_forcing_ratio:  0.9997635099988117\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.17554166913032532\n",
      "KL_weight:  0.002369899999999644 teacher_forcing_ratio:  0.9997630099988092\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16201528906822205\n",
      "KL_weight:  0.002374899999999636 teacher_forcing_ratio:  0.9997625099988067\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   admonished \tScore:  0.06985\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   followling \tScore:  0.10446\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      feggers \tScore:  0.07731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:  emprommaces \tScore:  0.02666\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:  stammerches \tScore:  0.02481\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: strillminating \tScore:  0.21142\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:      floware \tScore:  0.20557\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:    furnisher \tScore:  0.06031\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  fundergated \tScore:  0.12278\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      hesells \tScore:  0.09879\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15950323641300201\n",
      "KL_weight:  0.0023838999999996214 teacher_forcing_ratio:  0.9997616099988021\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.1587245762348175\n",
      "KL_weight:  0.0023888999999996134 teacher_forcing_ratio:  0.9997611099987996\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.16887858510017395\n",
      "KL_weight:  0.0023938999999996054 teacher_forcing_ratio:  0.9997606099987971\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1537078469991684\n",
      "KL_weight:  0.0023988999999995974 teacher_forcing_ratio:  0.9997601099987946\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.16213661432266235\n",
      "KL_weight:  0.0024038999999995894 teacher_forcing_ratio:  0.9997596099987921\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.17338848114013672\n",
      "KL_weight:  0.0024088999999995813 teacher_forcing_ratio:  0.9997591099987896\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.15151262283325195\n",
      "KL_weight:  0.0024138999999995733 teacher_forcing_ratio:  0.9997586099987871\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    affloaded \tScore:  0.06674\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: afformulting \tScore:  0.22417\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     becuties \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:    emphousts \tScore:  0.03156\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      designs \tScore:  0.04939\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  swithstring \tScore:  0.12761\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:   crefarrise \tScore:  0.06312\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     bullfoce \tScore:  0.03928\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: blackmaigned \tScore:  0.09578\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:   stillaphes \tScore:  0.05612\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.1622447818517685\n",
      "KL_weight:  0.002422899999999559 teacher_forcing_ratio:  0.9997577099987826\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.16226080060005188\n",
      "KL_weight:  0.002427899999999551 teacher_forcing_ratio:  0.99975720999878\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.16171938180923462\n",
      "KL_weight:  0.002432899999999543 teacher_forcing_ratio:  0.9997567099987775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.16375872492790222\n",
      "KL_weight:  0.002437899999999535 teacher_forcing_ratio:  0.999756209998775\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.16282038390636444\n",
      "KL_weight:  0.002442899999999527 teacher_forcing_ratio:  0.9997557099987725\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.16339559853076935\n",
      "KL_weight:  0.002447899999999519 teacher_forcing_ratio:  0.99975520999877\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16756337881088257\n",
      "KL_weight:  0.002452899999999511 teacher_forcing_ratio:  0.9997547099987675\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     abanched \tScore:  0.36282\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   alaffering \tScore:  0.11868\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    foretells \tScore:  0.02852\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expeciates \tScore:  0.27776\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     cretends \tScore:  0.34572\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:  swillmering \tScore:  0.11095\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       ahrack \tScore:  0.04855\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     unfoldid \tScore:  0.07386\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:  unfoundered \tScore:  0.06484\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      helears \tScore:  0.10446\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.16245681047439575\n",
      "KL_weight:  0.0024618999999994964 teacher_forcing_ratio:  0.999753809998763\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.15871194005012512\n",
      "KL_weight:  0.0024668999999994884 teacher_forcing_ratio:  0.9997533099987604\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.16885873675346375\n",
      "KL_weight:  0.0024718999999994804 teacher_forcing_ratio:  0.9997528099987579\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200 char-loss:  0.15597432851791382\n",
      "KL_weight:  0.0024768999999994724 teacher_forcing_ratio:  0.9997523099987554\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1599881947040558\n",
      "KL_weight:  0.0024818999999994644 teacher_forcing_ratio:  0.9997518099987529\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.16618743538856506\n",
      "KL_weight:  0.0024868999999994564 teacher_forcing_ratio:  0.9997513099987504\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.14972318708896637\n",
      "KL_weight:  0.0024918999999994484 teacher_forcing_ratio:  0.9997508099987479\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:   adnscented \tScore:  0.05874\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:  abettecking \tScore:  0.46925\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:     bhackens \tScore:  0.06985\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   encounters \tScore:  0.05308\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:     stammers \tScore:  0.03656\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict:   despicling \tScore:  0.15353\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:       flaunt \tScore:  0.20205\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:   unferciant \tScore:  0.06105\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict: functionalized \tScore:  0.56220\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:    helarates \tScore:  0.06377\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15977129340171814\n",
      "KL_weight:  0.002500899999999434 teacher_forcing_ratio:  0.9997499099987434\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.15900520980358124\n",
      "KL_weight:  0.002505899999999426 teacher_forcing_ratio:  0.9997494099987408\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.174429252743721\n",
      "KL_weight:  0.002510899999999418 teacher_forcing_ratio:  0.9997489099987383\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.15546151995658875\n",
      "KL_weight:  0.00251589999999941 teacher_forcing_ratio:  0.9997484099987358\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.16253742575645447\n",
      "KL_weight:  0.002520899999999402 teacher_forcing_ratio:  0.9997479099987333\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.16344565153121948\n",
      "KL_weight:  0.002525899999999394 teacher_forcing_ratio:  0.9997474099987308\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.16911929845809937\n",
      "KL_weight:  0.002530899999999386 teacher_forcing_ratio:  0.9997469099987283\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:    alloncont \tScore:  0.06031\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict:   emelciting \tScore:  0.27776\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:      befells \tScore:  0.07731\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   expecteats \tScore:  0.27776\n",
      "Src_true:         sent \tTrg_true:       sends \tPredict:      stalkes \tScore:  0.04347\n",
      "Src_true:        split \tTrg_true:   splitting \tPredict: specimitating \tScore:  0.26130\n",
      "Src_true:       flared \tTrg_true:       flare \tPredict:        flear \tScore:  0.16990\n",
      "Src_true:  functioning \tTrg_true:    function \tPredict:     function \tScore:  1.00000\n",
      "Src_true:  functioning \tTrg_true:  functioned \tPredict:   fintrolled \tScore:  0.06105\n",
      "Src_true:      healing \tTrg_true:       heals \tPredict:      estalls \tScore:  0.09879\n",
      "==========================================================================================\n",
      "\n",
      "Step: 50 char-loss:  0.15531869232654572\n",
      "KL_weight:  0.0025398999999993715 teacher_forcing_ratio:  0.9997460099987238\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 100 char-loss:  0.16122546792030334\n",
      "KL_weight:  0.0025448999999993635 teacher_forcing_ratio:  0.9997455099987212\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 150 char-loss:  0.15741537511348724\n",
      "KL_weight:  0.0025498999999993555 teacher_forcing_ratio:  0.9997450099987187\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 200 char-loss:  0.1556544452905655\n",
      "KL_weight:  0.0025548999999993474 teacher_forcing_ratio:  0.9997445099987162\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 250 char-loss:  0.1822674572467804\n",
      "KL_weight:  0.0025598999999993394 teacher_forcing_ratio:  0.9997440099987137\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 300 char-loss:  0.15489670634269714\n",
      "KL_weight:  0.0025648999999993314 teacher_forcing_ratio:  0.9997435099987112\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Step: 350 char-loss:  0.17047256231307983\n",
      "KL_weight:  0.0025698999999993234 teacher_forcing_ratio:  0.9997430099987087\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "Model has been saved as Lab4_seq2seq_vae_lstm_KL_condembedding_(word_dropout).pt.\n",
      "\n",
      "========================================Evaluating========================================\n",
      "Src_true:      abandon \tTrg_true:   abandoned \tPredict:     ackneded \tScore:  0.13784\n",
      "Src_true:         abet \tTrg_true:    abetting \tPredict: ememberaging \tScore:  0.11095\n",
      "Src_true:        begin \tTrg_true:      begins \tPredict:    peeceives \tScore:  0.03156\n",
      "Src_true:       expend \tTrg_true:     expends \tPredict:   overspects \tScore:  0.05308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ca0b48e40aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices_to_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrg_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices_to_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_trg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c_trg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Src_true: {:>12}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tTrg_true:{:>12}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tPredict: {:>12}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tScore: {:>8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-652d8782a105>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, words, src_label, trg_label)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# transform word to index-sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0meval_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdecoded_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoded_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-49b4fde6474e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, inputs, src_label, trg_label)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_logv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_logv\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# reparaterization trick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5b2745285288>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seqs, input_lengths, label, hidden, cell)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpacked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 585\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.notebook.tqdm(range(100)):\n",
    "    trainer.train(num_epochs=10, batch_size=128, pretrained=False)\n",
    "#     torch.save(seq2seq.state_dict(), \"Lab4_seq2seq_vae_lstm_KL_cond_(word_dropout)_{}epoch.pt\".format(epoch))\n",
    "\n",
    "    ## eval\n",
    "    print(\"========================================Evaluating========================================\")  \n",
    "    total_score = 0.0\n",
    "    for i in range(len(test_src)):\n",
    "        word = train_loader.vocab.indices_to_sequence(test_src[i])\n",
    "        trg_true = train_loader.vocab.indices_to_sequence(test_trg[i])\n",
    "        results = trainer.evaluate(word, test_c_src[i].view(1, -1), test_c_trg[i].view(1, -1))[0]\n",
    "        score = trainer.compute_bleu(results, trg_true)\n",
    "        print(\"Src_true: {:>12}\".format(word), \"\\tTrg_true:{:>12}\".format(trg_true), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "        total_score += score\n",
    "    total_score /= len(test_src)\n",
    "    trainer.score.append(total_score)\n",
    "    print(\"==========================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    acc = np.load(loss_file)\n",
    "    entropy = acc['entropy']\n",
    "    kld = acc['kld']\n",
    "    kl_weight = acc['kl_weight']\n",
    "    teacher_forcing_ratio = acc['teacher_forcing_ratio']\n",
    "    score = acc['score']\n",
    "    \n",
    "# plt.title(\"Activation Function comparision(EEGNet)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(entropy)+1)\n",
    "plt.plot(x, entropy, label=\"CrossEntropy\")\n",
    "plt.plot(x, kld, label=\"kld\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.ylabel(\"KL_weight & teacher_forcing_ratio\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.arange(1, len(kl_weight)+1)\n",
    "plt.plot(x, kl_weight, label=\"kl_weight\")\n",
    "plt.plot(x, teacher_forcing_ratio, label=\"teacher_forcing_ratio\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Step\")\n",
    "# print(test_loss)\n",
    "x = np.linspace(1, len(kl_weight)+1, len(score))\n",
    "plt.plot(x, score, label=\"score\")\n",
    "# plt.plot(x, test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparaterization_trick(mean, logv):\n",
    "        std = torch.exp(0.5*logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return  mean + eps * std\n",
    "    \n",
    "def Gaussian_score(words):\n",
    "    words_list = []\n",
    "    score = 0\n",
    "    yourpath = './train.txt'#should be your directory of train.txt\n",
    "    with open(yourpath,'r') as fp:\n",
    "        for line in fp:\n",
    "            word = line.split(' ')\n",
    "            word[3] = word[3].strip('\\n')\n",
    "            words_list.extend([word])\n",
    "        for t in words:\n",
    "            for i in words_list:\n",
    "                if t == i:\n",
    "                    score += 1\n",
    "    return score/len(words)\n",
    "\n",
    "    \n",
    "label = torch.LongTensor([[1, 0, 0, 0],\n",
    "                       [0, 1, 0, 0],\n",
    "                       [0, 0, 1, 0],\n",
    "                       [0, 0, 0, 1]]).to(device)\n",
    "\n",
    "decoder.eval()\n",
    "words = []\n",
    "for i in range(100):        \n",
    "\n",
    "    hidden_mean = torch.randn([1, 1, 32]).to(device)\n",
    "    hidden_logv = torch.randn([1, 1, 32]).to(device)\n",
    "    cell_mean = torch.randn([1, 1, 32]).to(device)\n",
    "    cell_logv = torch.randn([1, 1, 32]).to(device)\n",
    "\n",
    "    encoder_hidden = reparaterization_trick(hidden_mean, hidden_logv)\n",
    "    encoder_hidden = decoder.latent2hidden(encoder_hidden)\n",
    "    encoder_cell = reparaterization_trick(cell_mean, cell_logv)\n",
    "    encoder_cell = decoder.latent2hidden(encoder_cell)\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(4):\n",
    "        hidden = torch.cat([encoder_hidden, label[i].view(1, 1, 4)], dim=2)\n",
    "        cell = torch.cat([encoder_cell, label[i].view(1, 1, 4)], dim=2)\n",
    "        decoded_indices = decoder.evaluate(context_vector=hidden, decoder_cell=cell)\n",
    "        results = []\n",
    "        for indices in decoded_indices:\n",
    "            results.append(train_loader.vocab.indices_to_sequence(indices))\n",
    "        tmp.append(results[0])\n",
    "    words.append(tmp)\n",
    "print(words)\n",
    "print(Gaussian_score(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_score = 0.0\n",
    "for i in range(len(test_src)):\n",
    "    word = train_loader.vocab.indices_to_sequence(test_src[i])\n",
    "    trg_true = train_loader.vocab.indices_to_sequence(test_trg[i])\n",
    "    results = trainer.evaluate(word, test_c_src[i].view(1, -1), test_c_trg[i].view(1, -1))[0]\n",
    "    score = trainer.compute_bleu(results, trg_true)\n",
    "    print(\"Src_true: {:>12}\".format(word), \"\\tTrg_true:{:>12}\".format(trg_true), \"\\tPredict: {:>12}\".format(results), \"\\tScore: {:>8.5f}\".format(score))\n",
    "    total_score += score\n",
    "total_score /= len(test_src)\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder, \"lstm2_decoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
